{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>final_result</th>\n",
       "      <th>score</th>\n",
       "      <th>id_student</th>\n",
       "      <th>code_module</th>\n",
       "      <th>code_presentation</th>\n",
       "      <th>mean_sum_click</th>\n",
       "      <th>total_sum_click</th>\n",
       "      <th>days_logged</th>\n",
       "      <th>material_interactions</th>\n",
       "      <th>module_length</th>\n",
       "      <th>...</th>\n",
       "      <th>region</th>\n",
       "      <th>highest_education</th>\n",
       "      <th>imd_band</th>\n",
       "      <th>age_band</th>\n",
       "      <th>num_of_prev_attempts</th>\n",
       "      <th>studied_credits</th>\n",
       "      <th>disability</th>\n",
       "      <th>grade</th>\n",
       "      <th>studied_credits_binned</th>\n",
       "      <th>date_registration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pass</td>\n",
       "      <td>82.4</td>\n",
       "      <td>11391</td>\n",
       "      <td>AAA</td>\n",
       "      <td>2013J</td>\n",
       "      <td>4.765306</td>\n",
       "      <td>934</td>\n",
       "      <td>40</td>\n",
       "      <td>55</td>\n",
       "      <td>268</td>\n",
       "      <td>...</td>\n",
       "      <td>East Anglian Region</td>\n",
       "      <td>HE Qualification</td>\n",
       "      <td>90-100%</td>\n",
       "      <td>55&lt;=</td>\n",
       "      <td>0</td>\n",
       "      <td>240</td>\n",
       "      <td>N</td>\n",
       "      <td>A-</td>\n",
       "      <td>201+</td>\n",
       "      <td>-159.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pass</td>\n",
       "      <td>65.4</td>\n",
       "      <td>28400</td>\n",
       "      <td>AAA</td>\n",
       "      <td>2013J</td>\n",
       "      <td>3.337209</td>\n",
       "      <td>1435</td>\n",
       "      <td>80</td>\n",
       "      <td>84</td>\n",
       "      <td>268</td>\n",
       "      <td>...</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>HE Qualification</td>\n",
       "      <td>20-30%</td>\n",
       "      <td>35-55</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>N</td>\n",
       "      <td>C</td>\n",
       "      <td>30-60</td>\n",
       "      <td>-53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pass</td>\n",
       "      <td>76.3</td>\n",
       "      <td>31604</td>\n",
       "      <td>AAA</td>\n",
       "      <td>2013J</td>\n",
       "      <td>3.254902</td>\n",
       "      <td>2158</td>\n",
       "      <td>123</td>\n",
       "      <td>82</td>\n",
       "      <td>268</td>\n",
       "      <td>...</td>\n",
       "      <td>South East Region</td>\n",
       "      <td>A Level or Equivalent</td>\n",
       "      <td>50-60%</td>\n",
       "      <td>35-55</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>N</td>\n",
       "      <td>B</td>\n",
       "      <td>30-60</td>\n",
       "      <td>-52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pass</td>\n",
       "      <td>55.0</td>\n",
       "      <td>32885</td>\n",
       "      <td>AAA</td>\n",
       "      <td>2013J</td>\n",
       "      <td>2.937500</td>\n",
       "      <td>1034</td>\n",
       "      <td>70</td>\n",
       "      <td>66</td>\n",
       "      <td>268</td>\n",
       "      <td>...</td>\n",
       "      <td>West Midlands Region</td>\n",
       "      <td>Lower Than A Level</td>\n",
       "      <td>50-60%</td>\n",
       "      <td>0-35</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>N</td>\n",
       "      <td>D</td>\n",
       "      <td>30-60</td>\n",
       "      <td>-176.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pass</td>\n",
       "      <td>66.9</td>\n",
       "      <td>38053</td>\n",
       "      <td>AAA</td>\n",
       "      <td>2013J</td>\n",
       "      <td>3.381743</td>\n",
       "      <td>2445</td>\n",
       "      <td>143</td>\n",
       "      <td>88</td>\n",
       "      <td>268</td>\n",
       "      <td>...</td>\n",
       "      <td>Wales</td>\n",
       "      <td>A Level or Equivalent</td>\n",
       "      <td>80-90%</td>\n",
       "      <td>35-55</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>N</td>\n",
       "      <td>C</td>\n",
       "      <td>30-60</td>\n",
       "      <td>-110.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  final_result  score  id_student code_module code_presentation  \\\n",
       "0         Pass   82.4       11391         AAA             2013J   \n",
       "1         Pass   65.4       28400         AAA             2013J   \n",
       "2         Pass   76.3       31604         AAA             2013J   \n",
       "3         Pass   55.0       32885         AAA             2013J   \n",
       "4         Pass   66.9       38053         AAA             2013J   \n",
       "\n",
       "   mean_sum_click  total_sum_click  days_logged  material_interactions  \\\n",
       "0        4.765306              934           40                     55   \n",
       "1        3.337209             1435           80                     84   \n",
       "2        3.254902             2158          123                     82   \n",
       "3        2.937500             1034           70                     66   \n",
       "4        3.381743             2445          143                     88   \n",
       "\n",
       "   module_length  ...                region      highest_education  imd_band  \\\n",
       "0            268  ...   East Anglian Region       HE Qualification   90-100%   \n",
       "1            268  ...              Scotland       HE Qualification    20-30%   \n",
       "2            268  ...     South East Region  A Level or Equivalent    50-60%   \n",
       "3            268  ...  West Midlands Region     Lower Than A Level    50-60%   \n",
       "4            268  ...                 Wales  A Level or Equivalent    80-90%   \n",
       "\n",
       "   age_band  num_of_prev_attempts  studied_credits disability grade  \\\n",
       "0      55<=                     0              240          N    A-   \n",
       "1     35-55                     0               60          N     C   \n",
       "2     35-55                     0               60          N     B   \n",
       "3      0-35                     0               60          N     D   \n",
       "4     35-55                     0               60          N     C   \n",
       "\n",
       "  studied_credits_binned date_registration  \n",
       "0                   201+            -159.0  \n",
       "1                  30-60             -53.0  \n",
       "2                  30-60             -52.0  \n",
       "3                  30-60            -176.0  \n",
       "4                  30-60            -110.0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "student_info = pd.read_csv('data/student_info_cleaned.csv')\n",
    "\n",
    "assessments = pd.read_csv('data/assessments.csv')\n",
    "courses = pd.read_csv('data/courses.csv') # DONE\n",
    "student_assessments = pd.read_csv('data/studentAssessment.csv')\n",
    " # IDK how to use???\n",
    "# student_info = pd.read_csv('data/studentInfo.csv')\n",
    "registration = pd.read_csv('data/studentRegistration.csv')\n",
    "student_vle= pd.read_csv('data/studentVle.csv')\n",
    "vle = pd.read_csv('data/vle.csv')\n",
    "\n",
    "datasets = {\n",
    "    'assessments':assessments,\n",
    "    'courses':courses,\n",
    "    'student_assessments':student_assessments,\n",
    "    'student_info':student_info,\n",
    "    'registration':registration,\n",
    "    'student_vle':student_vle,\n",
    "    'vle':vle}\n",
    "\n",
    "student_df = student_info.merge(registration, how='inner', on=[\"code_module\", \"code_presentation\", \"id_student\"])\n",
    "student_df = student_df.drop(columns='date_unregistration')\n",
    "\n",
    "svle = student_vle.groupby(['code_module', 'code_presentation', 'id_student']).agg({'sum_click': ['mean', 'sum'], 'date': 'nunique', 'id_site': 'nunique'}).reset_index()\n",
    "svle.columns = ['code_module', 'code_presentation', 'id_student', 'mean_sum_click', 'total_sum_click', 'unique_date_count', 'unique_id_site_count']\n",
    "\n",
    "svle = pd.merge(svle, courses, on=['code_module', 'code_presentation'], how='left')\n",
    "svle['avg click/day'] =  svle['total_sum_click'] / svle['module_presentation_length']\n",
    "\n",
    "svle = svle.rename(columns={'unique_date_count': 'days_logged', 'unique_id_site_count': 'material_interactions', 'module_presentation_length': 'module_length'})\n",
    "\n",
    "vle_n = vle.groupby(['code_module', 'code_presentation'])['id_site'].nunique().reset_index()\n",
    "svle = pd.merge(svle, vle_n, on=['code_module', 'code_presentation'], how='left')\n",
    "svle['% material interaction'] =  100*svle['material_interactions'] / svle['id_site']\n",
    "\n",
    "assessment_counts = assessments.groupby(['code_module', 'code_presentation'])['assessment_type'].value_counts().reset_index(name='count')\n",
    "assessment_pivot = assessment_counts.pivot_table(index=['code_module', 'code_presentation'], columns='assessment_type', values='count', fill_value=0).reset_index()\n",
    "assessment_pivot.columns.name = None  \n",
    "assessment_pivot.columns = ['code_module', 'code_presentation', 'CMA', 'Exam', 'TMA']\n",
    "svle = pd.merge(svle, assessment_pivot, on=['code_module', 'code_presentation'], how='left')\n",
    "\n",
    "df_all = pd.merge(svle, student_df, on=['code_module', 'code_presentation', 'id_student'], how='inner')\n",
    "columns_to_move = ['final_result', 'score', 'id_student']\n",
    "df_all = df_all[columns_to_move + [col for col in df_all.columns if col not in columns_to_move]]\n",
    "\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23684, 27)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop withdrawn students\n",
    "df_all = df_all[df_all['final_result'] != 'Withdrawn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19120, 48)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "#order highest_education, imd_band, age_band, disability, studied_credits_binned, final_result\n",
    "highest_education = {\n",
    "    'No Formal quals': 0,\n",
    "    'Lower Than A Level': 1,\n",
    "    'A Level or Equivalent': 2,\n",
    "    'HE Qualification': 3,\n",
    "    'Post Graduate Qualification': 4\n",
    "}\n",
    "\n",
    "imd_band = {\n",
    "    np.nan: -1,\n",
    "    '0-10%': 0,\n",
    "    '10-20': 1,\n",
    "    '20-30%': 2,\n",
    "    '30-40%': 3,\n",
    "    '40-50%': 4,\n",
    "    '50-60%': 5,\n",
    "    '60-70%': 6,\n",
    "    '70-80%': 7,\n",
    "    '80-90%': 8,\n",
    "    '90-100%': 9\n",
    "}\n",
    "\n",
    "age_band = {\n",
    "    '0-35': 0,\n",
    "    '35-55': 1,\n",
    "    '55<=': 2\n",
    "}\n",
    "\n",
    "disability = {\n",
    "    'N': 0,\n",
    "    'Y': 1\n",
    "}\n",
    "\n",
    "studied_credits_binned = {\n",
    "    '30-60': 0,\n",
    "    '61-100': 1,\n",
    "    '101-200': 2,\n",
    "    '201+': 3\n",
    "}\n",
    "\n",
    "final_result = {\n",
    "    'Fail': 0,\n",
    "    'Pass': 1,\n",
    "    'Distinction': 1,\n",
    "    'Withdrawn': 0\n",
    "}\n",
    "\n",
    "data_dummies = pd.get_dummies(df_all, columns=['code_module', 'code_presentation', 'gender', 'region'])\n",
    "data_dummies['highest_education'] = data_dummies['highest_education'].map(highest_education)\n",
    "data_dummies['imd_band'] = data_dummies['imd_band'].map(imd_band)\n",
    "data_dummies['age_band'] = data_dummies['age_band'].map(age_band)\n",
    "data_dummies['disability'] = data_dummies['disability'].map(disability)\n",
    "data_dummies['studied_credits_binned'] = data_dummies['studied_credits_binned'].map(studied_credits_binned)\n",
    "data_dummies['final_result'] = data_dummies['final_result'].map(final_result)\n",
    "data_dummies.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dummies = data_dummies[~((data_dummies['score'] > 50) & (data_dummies['final_result'] == 0))]\n",
    "data_dummies = data_dummies[~((data_dummies['score'] < 50) & (data_dummies['final_result'] == 1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15359, 48)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dummies.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1z/_j8y7ndj06788g4f84n47dqm0000gn/T/ipykernel_95400/2502644455.py:20: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from imblearn.over_sampling import SMOTE#pip install imbalanced-learn\n",
    "\n",
    "\n",
    "\n",
    "X_dummy = data_dummies.drop(['final_result', 'studied_credits', 'id_student', 'score', 'grade'], axis=1)\n",
    "X_dummy_combined = X_dummy.copy()\n",
    "X_dummy_combined['score'] = data_dummies['score']\n",
    "# X_dummy_combined.loc[(X_dummy_combined['score'] < 50) & (y_dummy['final_result'] == 1), 'score'] = 76\n",
    "# X_dummy_combined.loc[y_dummy['final_result'] == 0, 'score'] = 35\n",
    "\n",
    "\n",
    "y_dummy = data_dummies[['final_result']]\n",
    "\n",
    "smote = SMOTE(sampling_strategy='minority', random_state=42)\n",
    "X_dummy_smote, y_dummy_smote = smote.fit_resample(X_dummy_combined, y_dummy)\n",
    "\n",
    "y_dummy_smote['score'] = X_dummy_smote['score']\n",
    "y_dummy['score'] = X_dummy_combined['score']\n",
    "X_dummy_smote = X_dummy_smote.drop(['score'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_result\n",
      "1    13788\n",
      "0     1571\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y_dummy['final_result'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27576, 43)\n",
      "(27576, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "final_result\n",
       "1    13788\n",
       "0    13788\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_dummy_smote.shape)\n",
    "print(y_dummy_smote.shape)\n",
    "y_dummy_smote['final_result'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18934 entries, 0 to 18933\n",
      "Data columns (total 42 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   mean_sum_click               18934 non-null  float64\n",
      " 1   total_sum_click              18934 non-null  float64\n",
      " 2   days_logged                  18934 non-null  int64  \n",
      " 3   material_interactions        18934 non-null  int64  \n",
      " 4   module_length                18934 non-null  int64  \n",
      " 5   avg click/day                18934 non-null  float64\n",
      " 6   id_site                      18934 non-null  int64  \n",
      " 7   % material interaction       18934 non-null  float64\n",
      " 8   CMA                          18934 non-null  int64  \n",
      " 9   Exam                         18934 non-null  int64  \n",
      " 10  TMA                          18934 non-null  int64  \n",
      " 11  highest_education            18934 non-null  int64  \n",
      " 12  imd_band                     18934 non-null  int64  \n",
      " 13  age_band                     18934 non-null  int64  \n",
      " 14  num_of_prev_attempts         18934 non-null  int64  \n",
      " 15  disability                   18934 non-null  int64  \n",
      " 16  studied_credits_binned       18934 non-null  int64  \n",
      " 17  date_registration            18934 non-null  float64\n",
      " 18  code_module_AAA              18934 non-null  uint8  \n",
      " 19  code_module_BBB              18934 non-null  uint8  \n",
      " 20  code_module_CCC              18934 non-null  uint8  \n",
      " 21  code_module_DDD              18934 non-null  uint8  \n",
      " 22  code_module_EEE              18934 non-null  uint8  \n",
      " 23  code_presentation_2013B      18934 non-null  uint8  \n",
      " 24  code_presentation_2013J      18934 non-null  uint8  \n",
      " 25  code_presentation_2014B      18934 non-null  uint8  \n",
      " 26  code_presentation_2014J      18934 non-null  uint8  \n",
      " 27  gender_F                     18934 non-null  uint8  \n",
      " 28  gender_M                     18934 non-null  uint8  \n",
      " 29  region_East Anglian Region   18934 non-null  uint8  \n",
      " 30  region_East Midlands Region  18934 non-null  uint8  \n",
      " 31  region_Ireland               18934 non-null  uint8  \n",
      " 32  region_London Region         18934 non-null  uint8  \n",
      " 33  region_North Region          18934 non-null  uint8  \n",
      " 34  region_North Western Region  18934 non-null  uint8  \n",
      " 35  region_Scotland              18934 non-null  uint8  \n",
      " 36  region_South East Region     18934 non-null  uint8  \n",
      " 37  region_South Region          18934 non-null  uint8  \n",
      " 38  region_South West Region     18934 non-null  uint8  \n",
      " 39  region_Wales                 18934 non-null  uint8  \n",
      " 40  region_West Midlands Region  18934 non-null  uint8  \n",
      " 41  region_Yorkshire Region      18934 non-null  uint8  \n",
      "dtypes: float64(5), int64(13), uint8(24)\n",
      "memory usage: 3.0 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(X_dummy_smote.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_result                   1.000000\n",
      "score                          0.708328\n",
      "% material interaction         0.280093\n",
      "days_logged                    0.278491\n",
      "material_interactions          0.205114\n",
      "total_sum_click                0.203590\n",
      "avg click/day                  0.202036\n",
      "mean_sum_click                 0.110693\n",
      "highest_education              0.094854\n",
      "code_module_EEE                0.089711\n",
      "code_module_BBB                0.071993\n",
      "imd_band                       0.066058\n",
      "module_length                  0.054956\n",
      "code_module_FFF                0.053709\n",
      "age_band                       0.049291\n",
      "code_presentation_2013J        0.035106\n",
      "code_module_AAA                0.034096\n",
      "gender_F                       0.028532\n",
      "region_Scotland                0.024944\n",
      "region_South East Region       0.023507\n",
      "region_South Region            0.019097\n",
      "code_presentation_2014J        0.016927\n",
      "region_North Region            0.016768\n",
      "region_Ireland                 0.012980\n",
      "region_East Midlands Region    0.011835\n",
      "region_West Midlands Region   -0.001238\n",
      "CMA                           -0.003839\n",
      "region_East Anglian Region    -0.004207\n",
      "region_South West Region      -0.006570\n",
      "date_registration             -0.006590\n",
      "region_Yorkshire Region       -0.011605\n",
      "region_Wales                  -0.021234\n",
      "TMA                           -0.028333\n",
      "gender_M                      -0.028532\n",
      "studied_credits_binned        -0.029204\n",
      "code_presentation_2014B       -0.030057\n",
      "code_presentation_2013B       -0.031803\n",
      "region_North Western Region   -0.032185\n",
      "region_London Region          -0.032843\n",
      "id_site                       -0.039277\n",
      "disability                    -0.039437\n",
      "num_of_prev_attempts          -0.088131\n",
      "code_module_CCC               -0.109282\n",
      "Exam                          -0.109282\n",
      "code_module_DDD               -0.129668\n",
      "Name: final_result, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Concatenate the features and the target variable\n",
    "data = pd.concat([X_dummy, y_dummy], axis=1)\n",
    "\n",
    "# Compute the correlation matrix\n",
    "corr_matrix = data.corr()\n",
    "\n",
    "# Get the correlation of each variable with the 'final_result' variable\n",
    "corr_with_target = corr_matrix['final_result']\n",
    "\n",
    "corr_with_target = corr_with_target.sort_values(ascending=False)\n",
    "\n",
    "# Print the result\n",
    "print(corr_with_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% material interaction         0.084356\n",
      "days_logged                    0.062633\n",
      "avg click/day                  0.056097\n",
      "total_sum_click                0.049623\n",
      "material_interactions          0.038930\n",
      "Exam                           0.016812\n",
      "mean_sum_click                 0.015557\n",
      "id_site                        0.015229\n",
      "date_registration              0.008490\n",
      "TMA                            0.008249\n",
      "code_presentation_2014J        0.006502\n",
      "region_London Region           0.005989\n",
      "CMA                            0.005904\n",
      "code_module_EEE                0.005630\n",
      "module_length                  0.004763\n",
      "num_of_prev_attempts           0.004628\n",
      "code_module_CCC                0.004372\n",
      "region_Yorkshire Region        0.004148\n",
      "code_module_DDD                0.004120\n",
      "age_band                       0.003938\n",
      "code_module_FFF                0.003831\n",
      "studied_credits_binned         0.003624\n",
      "region_North Region            0.003498\n",
      "code_presentation_2014B        0.003407\n",
      "region_Wales                   0.002920\n",
      "region_East Midlands Region    0.002802\n",
      "highest_education              0.002764\n",
      "gender_F                       0.002723\n",
      "gender_M                       0.002402\n",
      "region_South Region            0.001645\n",
      "region_Scotland                0.001016\n",
      "region_West Midlands Region    0.000000\n",
      "region_South West Region       0.000000\n",
      "region_North Western Region    0.000000\n",
      "region_South East Region       0.000000\n",
      "code_module_AAA                0.000000\n",
      "region_Ireland                 0.000000\n",
      "code_module_BBB                0.000000\n",
      "imd_band                       0.000000\n",
      "code_presentation_2013J        0.000000\n",
      "code_presentation_2013B        0.000000\n",
      "disability                     0.000000\n",
      "region_East Anglian Region     0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import mutual_info_regression\n",
    "\n",
    "# Compute the mutual information\n",
    "mi = mutual_info_regression(X_dummy, y_dummy['final_result'])\n",
    "\n",
    "# Create a Series with the results\n",
    "mi_series = pd.Series(mi, index=X_dummy.columns)\n",
    "mi_series = mi_series.sort_values(ascending=False)\n",
    "mi_series_above_zero = mi_series[mi_series > 0].index.tolist()\n",
    "\n",
    "# Print the result\n",
    "print(mi_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_dummy, X_test_dummy, y_train_dummy, y_test_dummy = train_test_split(X_dummy_smote, y_dummy_smote, test_size=0.2, random_state=42, stratify=y_dummy_smote['final_result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pca, X_test_pca, y_train_dummy, y_test_dummy = train_test_split(X_pca, y_dummy_smote, test_size=0.2, random_state=42, stratify=y_dummy_smote['final_result'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Logistic Regression: 0.9439811457577955\n",
      "Confusion Matrix:\n",
      "[[2519  239]\n",
      " [  70 2688]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_recall_curve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(max_iter=20000)\n",
    "logreg.fit(X_train_dummy, y_train_dummy['final_result'])\n",
    "\n",
    "y_pred = logreg.predict(X_test_dummy)\n",
    "acc = accuracy_score(y_test_dummy['final_result'], y_pred)\n",
    "print('Accuracy Logistic Regression:', acc)\n",
    "\n",
    "cm = confusion_matrix(y_test_dummy['final_result'], y_pred)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBoost\n",
    "from xgboost import XGBClassifier #pip install xgboost\n",
    "from skopt import BayesSearchCV\n",
    "\n",
    "# Define the parameter space\n",
    "param_space = {\n",
    "    'learning_rate': (0.01, 1.0, 'log-uniform'),\n",
    "    'min_child_weight': (1, 10),\n",
    "    'max_depth': (3, 50),\n",
    "    'max_delta_step': (1, 20),\n",
    "    'subsample': (0.01, 1.0, 'uniform'),\n",
    "    'colsample_bytree': (0.01, 1.0, 'uniform'),\n",
    "    'colsample_bylevel': (0.01, 1.0, 'uniform'),\n",
    "    'reg_lambda': (1e-9, 1000, 'log-uniform'),\n",
    "    'reg_alpha': (1e-9, 1.0, 'log-uniform'),\n",
    "    'gamma': (1e-9, 0.5, 'log-uniform'),\n",
    "    'n_estimators': (50, 200),\n",
    "    'scale_pos_weight': (1e-6, 500, 'log-uniform')\n",
    "}\n",
    "\n",
    "# Create a BayesSearchCV object\n",
    "opt_xgb = BayesSearchCV(\n",
    "    estimator=XGBClassifier(n_jobs=-1),\n",
    "    search_spaces=param_space,\n",
    "    scoring='roc_auc',\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    n_iter=150,\n",
    "    verbose=1,\n",
    "    refit=True,\n",
    ")\n",
    "\n",
    "# Run the optimization\n",
    "opt_xgb.fit(X_train_dummy, y_train_dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy XGBoost: 0.9384737259044098\n",
      "Confusion Matrix:\n",
      "[[1738  156]\n",
      " [  77 1816]]\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier #pip install xgboost\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(X_train_dummy, y_train_dummy['final_result'])\n",
    "\n",
    "y_pred = xgb.predict(X_test_dummy)\n",
    "acc = accuracy_score(y_test_dummy['final_result'], y_pred)\n",
    "print(\"Accuracy XGBoost:\", acc)\n",
    "\n",
    "cm = confusion_matrix(y_test_dummy['final_result'], y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.038606\n",
      "0:\tlearn: 0.6647269\ttotal: 13.2ms\tremaining: 13.2s\n",
      "1:\tlearn: 0.6280049\ttotal: 20.7ms\tremaining: 10.3s\n",
      "2:\tlearn: 0.6032085\ttotal: 26.2ms\tremaining: 8.72s\n",
      "3:\tlearn: 0.5804459\ttotal: 30.6ms\tremaining: 7.63s\n",
      "4:\tlearn: 0.5546039\ttotal: 35.2ms\tremaining: 7s\n",
      "5:\tlearn: 0.5360748\ttotal: 40.4ms\tremaining: 6.69s\n",
      "6:\tlearn: 0.5147305\ttotal: 45.2ms\tremaining: 6.42s\n",
      "7:\tlearn: 0.4968609\ttotal: 49.5ms\tremaining: 6.14s\n",
      "8:\tlearn: 0.4837403\ttotal: 54ms\tremaining: 5.95s\n",
      "9:\tlearn: 0.4724020\ttotal: 58.2ms\tremaining: 5.76s\n",
      "10:\tlearn: 0.4577563\ttotal: 62.3ms\tremaining: 5.6s\n",
      "11:\tlearn: 0.4475671\ttotal: 67.5ms\tremaining: 5.56s\n",
      "12:\tlearn: 0.4408909\ttotal: 71.7ms\tremaining: 5.44s\n",
      "13:\tlearn: 0.4304970\ttotal: 76.9ms\tremaining: 5.42s\n",
      "14:\tlearn: 0.4229562\ttotal: 80.9ms\tremaining: 5.31s\n",
      "15:\tlearn: 0.4122917\ttotal: 85.9ms\tremaining: 5.28s\n",
      "16:\tlearn: 0.4065334\ttotal: 90ms\tremaining: 5.21s\n",
      "17:\tlearn: 0.3999179\ttotal: 94.2ms\tremaining: 5.14s\n",
      "18:\tlearn: 0.3942399\ttotal: 98.3ms\tremaining: 5.07s\n",
      "19:\tlearn: 0.3836343\ttotal: 102ms\tremaining: 5s\n",
      "20:\tlearn: 0.3763114\ttotal: 107ms\tremaining: 4.97s\n",
      "21:\tlearn: 0.3720887\ttotal: 111ms\tremaining: 4.93s\n",
      "22:\tlearn: 0.3674638\ttotal: 115ms\tremaining: 4.89s\n",
      "23:\tlearn: 0.3626029\ttotal: 119ms\tremaining: 4.84s\n",
      "24:\tlearn: 0.3593995\ttotal: 123ms\tremaining: 4.79s\n",
      "25:\tlearn: 0.3537161\ttotal: 127ms\tremaining: 4.76s\n",
      "26:\tlearn: 0.3485256\ttotal: 131ms\tremaining: 4.72s\n",
      "27:\tlearn: 0.3458009\ttotal: 135ms\tremaining: 4.7s\n",
      "28:\tlearn: 0.3430160\ttotal: 139ms\tremaining: 4.67s\n",
      "29:\tlearn: 0.3393430\ttotal: 144ms\tremaining: 4.65s\n",
      "30:\tlearn: 0.3358643\ttotal: 148ms\tremaining: 4.62s\n",
      "31:\tlearn: 0.3285527\ttotal: 152ms\tremaining: 4.59s\n",
      "32:\tlearn: 0.3262769\ttotal: 157ms\tremaining: 4.59s\n",
      "33:\tlearn: 0.3240293\ttotal: 161ms\tremaining: 4.57s\n",
      "34:\tlearn: 0.3215335\ttotal: 165ms\tremaining: 4.56s\n",
      "35:\tlearn: 0.3190451\ttotal: 169ms\tremaining: 4.53s\n",
      "36:\tlearn: 0.3133674\ttotal: 174ms\tremaining: 4.52s\n",
      "37:\tlearn: 0.3109746\ttotal: 178ms\tremaining: 4.5s\n",
      "38:\tlearn: 0.3065968\ttotal: 182ms\tremaining: 4.49s\n",
      "39:\tlearn: 0.3048085\ttotal: 186ms\tremaining: 4.47s\n",
      "40:\tlearn: 0.3031068\ttotal: 191ms\tremaining: 4.46s\n",
      "41:\tlearn: 0.3012720\ttotal: 196ms\tremaining: 4.48s\n",
      "42:\tlearn: 0.2996568\ttotal: 202ms\tremaining: 4.5s\n",
      "43:\tlearn: 0.2962936\ttotal: 207ms\tremaining: 4.49s\n",
      "44:\tlearn: 0.2947051\ttotal: 210ms\tremaining: 4.46s\n",
      "45:\tlearn: 0.2929210\ttotal: 215ms\tremaining: 4.45s\n",
      "46:\tlearn: 0.2913311\ttotal: 219ms\tremaining: 4.43s\n",
      "47:\tlearn: 0.2899621\ttotal: 223ms\tremaining: 4.42s\n",
      "48:\tlearn: 0.2873624\ttotal: 227ms\tremaining: 4.4s\n",
      "49:\tlearn: 0.2860491\ttotal: 232ms\tremaining: 4.41s\n",
      "50:\tlearn: 0.2845226\ttotal: 237ms\tremaining: 4.41s\n",
      "51:\tlearn: 0.2832403\ttotal: 242ms\tremaining: 4.42s\n",
      "52:\tlearn: 0.2809552\ttotal: 249ms\tremaining: 4.45s\n",
      "53:\tlearn: 0.2766317\ttotal: 261ms\tremaining: 4.57s\n",
      "54:\tlearn: 0.2747258\ttotal: 266ms\tremaining: 4.56s\n",
      "55:\tlearn: 0.2731416\ttotal: 275ms\tremaining: 4.64s\n",
      "56:\tlearn: 0.2706176\ttotal: 281ms\tremaining: 4.65s\n",
      "57:\tlearn: 0.2688322\ttotal: 286ms\tremaining: 4.65s\n",
      "58:\tlearn: 0.2673672\ttotal: 292ms\tremaining: 4.66s\n",
      "59:\tlearn: 0.2665094\ttotal: 297ms\tremaining: 4.65s\n",
      "60:\tlearn: 0.2645495\ttotal: 302ms\tremaining: 4.65s\n",
      "61:\tlearn: 0.2628338\ttotal: 307ms\tremaining: 4.65s\n",
      "62:\tlearn: 0.2606047\ttotal: 312ms\tremaining: 4.64s\n",
      "63:\tlearn: 0.2594105\ttotal: 318ms\tremaining: 4.65s\n",
      "64:\tlearn: 0.2585965\ttotal: 323ms\tremaining: 4.64s\n",
      "65:\tlearn: 0.2573444\ttotal: 330ms\tremaining: 4.66s\n",
      "66:\tlearn: 0.2560967\ttotal: 334ms\tremaining: 4.66s\n",
      "67:\tlearn: 0.2550424\ttotal: 341ms\tremaining: 4.67s\n",
      "68:\tlearn: 0.2524085\ttotal: 347ms\tremaining: 4.68s\n",
      "69:\tlearn: 0.2492588\ttotal: 352ms\tremaining: 4.68s\n",
      "70:\tlearn: 0.2481746\ttotal: 357ms\tremaining: 4.67s\n",
      "71:\tlearn: 0.2463101\ttotal: 362ms\tremaining: 4.67s\n",
      "72:\tlearn: 0.2453012\ttotal: 369ms\tremaining: 4.69s\n",
      "73:\tlearn: 0.2445124\ttotal: 376ms\tremaining: 4.7s\n",
      "74:\tlearn: 0.2431026\ttotal: 381ms\tremaining: 4.7s\n",
      "75:\tlearn: 0.2422813\ttotal: 389ms\tremaining: 4.72s\n",
      "76:\tlearn: 0.2413379\ttotal: 397ms\tremaining: 4.75s\n",
      "77:\tlearn: 0.2402667\ttotal: 402ms\tremaining: 4.76s\n",
      "78:\tlearn: 0.2392639\ttotal: 409ms\tremaining: 4.76s\n",
      "79:\tlearn: 0.2380614\ttotal: 415ms\tremaining: 4.77s\n",
      "80:\tlearn: 0.2367420\ttotal: 419ms\tremaining: 4.75s\n",
      "81:\tlearn: 0.2361088\ttotal: 426ms\tremaining: 4.76s\n",
      "82:\tlearn: 0.2352806\ttotal: 431ms\tremaining: 4.76s\n",
      "83:\tlearn: 0.2346227\ttotal: 437ms\tremaining: 4.76s\n",
      "84:\tlearn: 0.2336796\ttotal: 441ms\tremaining: 4.75s\n",
      "85:\tlearn: 0.2329735\ttotal: 446ms\tremaining: 4.74s\n",
      "86:\tlearn: 0.2323954\ttotal: 450ms\tremaining: 4.73s\n",
      "87:\tlearn: 0.2313493\ttotal: 455ms\tremaining: 4.71s\n",
      "88:\tlearn: 0.2306521\ttotal: 459ms\tremaining: 4.7s\n",
      "89:\tlearn: 0.2293836\ttotal: 465ms\tremaining: 4.7s\n",
      "90:\tlearn: 0.2276917\ttotal: 469ms\tremaining: 4.68s\n",
      "91:\tlearn: 0.2268863\ttotal: 473ms\tremaining: 4.67s\n",
      "92:\tlearn: 0.2263136\ttotal: 477ms\tremaining: 4.65s\n",
      "93:\tlearn: 0.2252780\ttotal: 482ms\tremaining: 4.64s\n",
      "94:\tlearn: 0.2245679\ttotal: 486ms\tremaining: 4.63s\n",
      "95:\tlearn: 0.2234792\ttotal: 490ms\tremaining: 4.61s\n",
      "96:\tlearn: 0.2227920\ttotal: 494ms\tremaining: 4.6s\n",
      "97:\tlearn: 0.2218336\ttotal: 498ms\tremaining: 4.59s\n",
      "98:\tlearn: 0.2212594\ttotal: 503ms\tremaining: 4.58s\n",
      "99:\tlearn: 0.2196014\ttotal: 507ms\tremaining: 4.57s\n",
      "100:\tlearn: 0.2183369\ttotal: 512ms\tremaining: 4.56s\n",
      "101:\tlearn: 0.2166324\ttotal: 516ms\tremaining: 4.54s\n",
      "102:\tlearn: 0.2155593\ttotal: 521ms\tremaining: 4.54s\n",
      "103:\tlearn: 0.2146785\ttotal: 525ms\tremaining: 4.53s\n",
      "104:\tlearn: 0.2140785\ttotal: 529ms\tremaining: 4.51s\n",
      "105:\tlearn: 0.2133746\ttotal: 534ms\tremaining: 4.5s\n",
      "106:\tlearn: 0.2113558\ttotal: 538ms\tremaining: 4.49s\n",
      "107:\tlearn: 0.2109050\ttotal: 544ms\tremaining: 4.49s\n",
      "108:\tlearn: 0.2104712\ttotal: 548ms\tremaining: 4.48s\n",
      "109:\tlearn: 0.2098217\ttotal: 553ms\tremaining: 4.47s\n",
      "110:\tlearn: 0.2082517\ttotal: 557ms\tremaining: 4.46s\n",
      "111:\tlearn: 0.2073322\ttotal: 562ms\tremaining: 4.45s\n",
      "112:\tlearn: 0.2067132\ttotal: 566ms\tremaining: 4.44s\n",
      "113:\tlearn: 0.2055577\ttotal: 570ms\tremaining: 4.43s\n",
      "114:\tlearn: 0.2044774\ttotal: 574ms\tremaining: 4.42s\n",
      "115:\tlearn: 0.2037585\ttotal: 578ms\tremaining: 4.41s\n",
      "116:\tlearn: 0.2031555\ttotal: 583ms\tremaining: 4.4s\n",
      "117:\tlearn: 0.2025737\ttotal: 589ms\tremaining: 4.4s\n",
      "118:\tlearn: 0.2014274\ttotal: 594ms\tremaining: 4.4s\n",
      "119:\tlearn: 0.2010207\ttotal: 600ms\tremaining: 4.4s\n",
      "120:\tlearn: 0.2006209\ttotal: 606ms\tremaining: 4.4s\n",
      "121:\tlearn: 0.1993073\ttotal: 611ms\tremaining: 4.4s\n",
      "122:\tlearn: 0.1985417\ttotal: 616ms\tremaining: 4.39s\n",
      "123:\tlearn: 0.1980854\ttotal: 621ms\tremaining: 4.38s\n",
      "124:\tlearn: 0.1976236\ttotal: 625ms\tremaining: 4.37s\n",
      "125:\tlearn: 0.1971907\ttotal: 630ms\tremaining: 4.37s\n",
      "126:\tlearn: 0.1957557\ttotal: 635ms\tremaining: 4.36s\n",
      "127:\tlearn: 0.1949481\ttotal: 640ms\tremaining: 4.36s\n",
      "128:\tlearn: 0.1945759\ttotal: 646ms\tremaining: 4.36s\n",
      "129:\tlearn: 0.1942366\ttotal: 653ms\tremaining: 4.37s\n",
      "130:\tlearn: 0.1923629\ttotal: 660ms\tremaining: 4.38s\n",
      "131:\tlearn: 0.1915575\ttotal: 664ms\tremaining: 4.37s\n",
      "132:\tlearn: 0.1908529\ttotal: 669ms\tremaining: 4.36s\n",
      "133:\tlearn: 0.1902493\ttotal: 673ms\tremaining: 4.35s\n",
      "134:\tlearn: 0.1892928\ttotal: 678ms\tremaining: 4.34s\n",
      "135:\tlearn: 0.1887818\ttotal: 682ms\tremaining: 4.33s\n",
      "136:\tlearn: 0.1884173\ttotal: 687ms\tremaining: 4.33s\n",
      "137:\tlearn: 0.1877677\ttotal: 694ms\tremaining: 4.33s\n",
      "138:\tlearn: 0.1873718\ttotal: 700ms\tremaining: 4.33s\n",
      "139:\tlearn: 0.1869302\ttotal: 704ms\tremaining: 4.33s\n",
      "140:\tlearn: 0.1864305\ttotal: 709ms\tremaining: 4.32s\n",
      "141:\tlearn: 0.1853927\ttotal: 714ms\tremaining: 4.31s\n",
      "142:\tlearn: 0.1849592\ttotal: 718ms\tremaining: 4.3s\n",
      "143:\tlearn: 0.1846224\ttotal: 723ms\tremaining: 4.29s\n",
      "144:\tlearn: 0.1840378\ttotal: 727ms\tremaining: 4.29s\n",
      "145:\tlearn: 0.1836371\ttotal: 733ms\tremaining: 4.28s\n",
      "146:\tlearn: 0.1828836\ttotal: 737ms\tremaining: 4.28s\n",
      "147:\tlearn: 0.1824576\ttotal: 742ms\tremaining: 4.27s\n",
      "148:\tlearn: 0.1816875\ttotal: 747ms\tremaining: 4.27s\n",
      "149:\tlearn: 0.1813368\ttotal: 752ms\tremaining: 4.26s\n",
      "150:\tlearn: 0.1808431\ttotal: 758ms\tremaining: 4.26s\n",
      "151:\tlearn: 0.1804525\ttotal: 763ms\tremaining: 4.26s\n",
      "152:\tlearn: 0.1800732\ttotal: 771ms\tremaining: 4.27s\n",
      "153:\tlearn: 0.1796978\ttotal: 777ms\tremaining: 4.27s\n",
      "154:\tlearn: 0.1793357\ttotal: 784ms\tremaining: 4.27s\n",
      "155:\tlearn: 0.1788699\ttotal: 792ms\tremaining: 4.28s\n",
      "156:\tlearn: 0.1786249\ttotal: 799ms\tremaining: 4.29s\n",
      "157:\tlearn: 0.1783435\ttotal: 805ms\tremaining: 4.29s\n",
      "158:\tlearn: 0.1779136\ttotal: 809ms\tremaining: 4.28s\n",
      "159:\tlearn: 0.1773401\ttotal: 814ms\tremaining: 4.27s\n",
      "160:\tlearn: 0.1770125\ttotal: 820ms\tremaining: 4.27s\n",
      "161:\tlearn: 0.1766750\ttotal: 826ms\tremaining: 4.27s\n",
      "162:\tlearn: 0.1763014\ttotal: 832ms\tremaining: 4.27s\n",
      "163:\tlearn: 0.1758712\ttotal: 840ms\tremaining: 4.28s\n",
      "164:\tlearn: 0.1756066\ttotal: 848ms\tremaining: 4.29s\n",
      "165:\tlearn: 0.1752061\ttotal: 855ms\tremaining: 4.29s\n",
      "166:\tlearn: 0.1749045\ttotal: 862ms\tremaining: 4.3s\n",
      "167:\tlearn: 0.1746486\ttotal: 869ms\tremaining: 4.3s\n",
      "168:\tlearn: 0.1743547\ttotal: 877ms\tremaining: 4.31s\n",
      "169:\tlearn: 0.1740888\ttotal: 884ms\tremaining: 4.31s\n",
      "170:\tlearn: 0.1737115\ttotal: 892ms\tremaining: 4.32s\n",
      "171:\tlearn: 0.1732618\ttotal: 900ms\tremaining: 4.33s\n",
      "172:\tlearn: 0.1730423\ttotal: 907ms\tremaining: 4.33s\n",
      "173:\tlearn: 0.1726967\ttotal: 915ms\tremaining: 4.34s\n",
      "174:\tlearn: 0.1723998\ttotal: 922ms\tremaining: 4.35s\n",
      "175:\tlearn: 0.1721482\ttotal: 927ms\tremaining: 4.34s\n",
      "176:\tlearn: 0.1718311\ttotal: 933ms\tremaining: 4.34s\n",
      "177:\tlearn: 0.1715308\ttotal: 942ms\tremaining: 4.35s\n",
      "178:\tlearn: 0.1713233\ttotal: 953ms\tremaining: 4.37s\n",
      "179:\tlearn: 0.1711002\ttotal: 960ms\tremaining: 4.38s\n",
      "180:\tlearn: 0.1708500\ttotal: 967ms\tremaining: 4.37s\n",
      "181:\tlearn: 0.1705611\ttotal: 972ms\tremaining: 4.37s\n",
      "182:\tlearn: 0.1702402\ttotal: 978ms\tremaining: 4.37s\n",
      "183:\tlearn: 0.1700199\ttotal: 988ms\tremaining: 4.38s\n",
      "184:\tlearn: 0.1696037\ttotal: 999ms\tremaining: 4.4s\n",
      "185:\tlearn: 0.1690917\ttotal: 1s\tremaining: 4.4s\n",
      "186:\tlearn: 0.1688204\ttotal: 1.01s\tremaining: 4.39s\n",
      "187:\tlearn: 0.1686088\ttotal: 1.01s\tremaining: 4.38s\n",
      "188:\tlearn: 0.1684530\ttotal: 1.02s\tremaining: 4.38s\n",
      "189:\tlearn: 0.1681354\ttotal: 1.02s\tremaining: 4.37s\n",
      "190:\tlearn: 0.1679545\ttotal: 1.03s\tremaining: 4.36s\n",
      "191:\tlearn: 0.1675457\ttotal: 1.03s\tremaining: 4.36s\n",
      "192:\tlearn: 0.1668058\ttotal: 1.04s\tremaining: 4.35s\n",
      "193:\tlearn: 0.1665848\ttotal: 1.04s\tremaining: 4.34s\n",
      "194:\tlearn: 0.1663684\ttotal: 1.05s\tremaining: 4.33s\n",
      "195:\tlearn: 0.1660408\ttotal: 1.06s\tremaining: 4.34s\n",
      "196:\tlearn: 0.1658676\ttotal: 1.06s\tremaining: 4.34s\n",
      "197:\tlearn: 0.1656962\ttotal: 1.07s\tremaining: 4.35s\n",
      "198:\tlearn: 0.1652575\ttotal: 1.08s\tremaining: 4.34s\n",
      "199:\tlearn: 0.1649774\ttotal: 1.08s\tremaining: 4.34s\n",
      "200:\tlearn: 0.1647574\ttotal: 1.09s\tremaining: 4.34s\n",
      "201:\tlearn: 0.1645367\ttotal: 1.1s\tremaining: 4.34s\n",
      "202:\tlearn: 0.1643646\ttotal: 1.1s\tremaining: 4.34s\n",
      "203:\tlearn: 0.1641116\ttotal: 1.11s\tremaining: 4.33s\n",
      "204:\tlearn: 0.1639240\ttotal: 1.11s\tremaining: 4.32s\n",
      "205:\tlearn: 0.1636294\ttotal: 1.12s\tremaining: 4.32s\n",
      "206:\tlearn: 0.1633745\ttotal: 1.12s\tremaining: 4.31s\n",
      "207:\tlearn: 0.1631213\ttotal: 1.13s\tremaining: 4.3s\n",
      "208:\tlearn: 0.1628647\ttotal: 1.13s\tremaining: 4.29s\n",
      "209:\tlearn: 0.1626520\ttotal: 1.14s\tremaining: 4.29s\n",
      "210:\tlearn: 0.1624006\ttotal: 1.14s\tremaining: 4.28s\n",
      "211:\tlearn: 0.1619836\ttotal: 1.15s\tremaining: 4.27s\n",
      "212:\tlearn: 0.1617245\ttotal: 1.15s\tremaining: 4.26s\n",
      "213:\tlearn: 0.1614491\ttotal: 1.16s\tremaining: 4.26s\n",
      "214:\tlearn: 0.1612010\ttotal: 1.16s\tremaining: 4.25s\n",
      "215:\tlearn: 0.1610385\ttotal: 1.17s\tremaining: 4.25s\n",
      "216:\tlearn: 0.1608466\ttotal: 1.17s\tremaining: 4.24s\n",
      "217:\tlearn: 0.1605959\ttotal: 1.18s\tremaining: 4.23s\n",
      "218:\tlearn: 0.1604207\ttotal: 1.18s\tremaining: 4.22s\n",
      "219:\tlearn: 0.1602125\ttotal: 1.19s\tremaining: 4.22s\n",
      "220:\tlearn: 0.1598954\ttotal: 1.2s\tremaining: 4.22s\n",
      "221:\tlearn: 0.1596216\ttotal: 1.2s\tremaining: 4.21s\n",
      "222:\tlearn: 0.1594101\ttotal: 1.21s\tremaining: 4.21s\n",
      "223:\tlearn: 0.1592139\ttotal: 1.22s\tremaining: 4.23s\n",
      "224:\tlearn: 0.1590016\ttotal: 1.24s\tremaining: 4.26s\n",
      "225:\tlearn: 0.1588461\ttotal: 1.25s\tremaining: 4.29s\n",
      "226:\tlearn: 0.1586617\ttotal: 1.26s\tremaining: 4.3s\n",
      "227:\tlearn: 0.1584390\ttotal: 1.27s\tremaining: 4.3s\n",
      "228:\tlearn: 0.1580819\ttotal: 1.28s\tremaining: 4.31s\n",
      "229:\tlearn: 0.1579294\ttotal: 1.29s\tremaining: 4.31s\n",
      "230:\tlearn: 0.1577366\ttotal: 1.29s\tremaining: 4.3s\n",
      "231:\tlearn: 0.1575246\ttotal: 1.3s\tremaining: 4.3s\n",
      "232:\tlearn: 0.1570071\ttotal: 1.3s\tremaining: 4.29s\n",
      "233:\tlearn: 0.1568204\ttotal: 1.31s\tremaining: 4.29s\n",
      "234:\tlearn: 0.1566378\ttotal: 1.31s\tremaining: 4.28s\n",
      "235:\tlearn: 0.1562832\ttotal: 1.32s\tremaining: 4.27s\n",
      "236:\tlearn: 0.1561009\ttotal: 1.32s\tremaining: 4.27s\n",
      "237:\tlearn: 0.1558897\ttotal: 1.33s\tremaining: 4.26s\n",
      "238:\tlearn: 0.1556741\ttotal: 1.34s\tremaining: 4.26s\n",
      "239:\tlearn: 0.1550501\ttotal: 1.35s\tremaining: 4.26s\n",
      "240:\tlearn: 0.1547921\ttotal: 1.35s\tremaining: 4.26s\n",
      "241:\tlearn: 0.1546293\ttotal: 1.36s\tremaining: 4.25s\n",
      "242:\tlearn: 0.1544669\ttotal: 1.36s\tremaining: 4.25s\n",
      "243:\tlearn: 0.1543276\ttotal: 1.37s\tremaining: 4.25s\n",
      "244:\tlearn: 0.1541463\ttotal: 1.38s\tremaining: 4.24s\n",
      "245:\tlearn: 0.1539377\ttotal: 1.38s\tremaining: 4.24s\n",
      "246:\tlearn: 0.1536419\ttotal: 1.39s\tremaining: 4.24s\n",
      "247:\tlearn: 0.1534285\ttotal: 1.4s\tremaining: 4.23s\n",
      "248:\tlearn: 0.1532865\ttotal: 1.4s\tremaining: 4.23s\n",
      "249:\tlearn: 0.1529070\ttotal: 1.41s\tremaining: 4.22s\n",
      "250:\tlearn: 0.1525890\ttotal: 1.41s\tremaining: 4.22s\n",
      "251:\tlearn: 0.1522521\ttotal: 1.42s\tremaining: 4.21s\n",
      "252:\tlearn: 0.1520567\ttotal: 1.43s\tremaining: 4.21s\n",
      "253:\tlearn: 0.1518279\ttotal: 1.43s\tremaining: 4.2s\n",
      "254:\tlearn: 0.1516671\ttotal: 1.44s\tremaining: 4.2s\n",
      "255:\tlearn: 0.1515290\ttotal: 1.44s\tremaining: 4.19s\n",
      "256:\tlearn: 0.1513428\ttotal: 1.45s\tremaining: 4.18s\n",
      "257:\tlearn: 0.1510291\ttotal: 1.45s\tremaining: 4.18s\n",
      "258:\tlearn: 0.1508446\ttotal: 1.46s\tremaining: 4.17s\n",
      "259:\tlearn: 0.1505956\ttotal: 1.47s\tremaining: 4.17s\n",
      "260:\tlearn: 0.1501871\ttotal: 1.47s\tremaining: 4.16s\n",
      "261:\tlearn: 0.1500118\ttotal: 1.48s\tremaining: 4.16s\n",
      "262:\tlearn: 0.1497389\ttotal: 1.48s\tremaining: 4.15s\n",
      "263:\tlearn: 0.1495605\ttotal: 1.49s\tremaining: 4.14s\n",
      "264:\tlearn: 0.1494129\ttotal: 1.49s\tremaining: 4.14s\n",
      "265:\tlearn: 0.1489424\ttotal: 1.5s\tremaining: 4.13s\n",
      "266:\tlearn: 0.1487842\ttotal: 1.5s\tremaining: 4.13s\n",
      "267:\tlearn: 0.1486216\ttotal: 1.51s\tremaining: 4.12s\n",
      "268:\tlearn: 0.1484424\ttotal: 1.51s\tremaining: 4.11s\n",
      "269:\tlearn: 0.1481102\ttotal: 1.52s\tremaining: 4.11s\n",
      "270:\tlearn: 0.1479395\ttotal: 1.52s\tremaining: 4.1s\n",
      "271:\tlearn: 0.1477183\ttotal: 1.53s\tremaining: 4.1s\n",
      "272:\tlearn: 0.1475703\ttotal: 1.54s\tremaining: 4.09s\n",
      "273:\tlearn: 0.1472929\ttotal: 1.54s\tremaining: 4.09s\n",
      "274:\tlearn: 0.1471020\ttotal: 1.55s\tremaining: 4.08s\n",
      "275:\tlearn: 0.1469124\ttotal: 1.55s\tremaining: 4.08s\n",
      "276:\tlearn: 0.1466761\ttotal: 1.56s\tremaining: 4.07s\n",
      "277:\tlearn: 0.1464758\ttotal: 1.56s\tremaining: 4.06s\n",
      "278:\tlearn: 0.1463264\ttotal: 1.57s\tremaining: 4.06s\n",
      "279:\tlearn: 0.1462021\ttotal: 1.58s\tremaining: 4.05s\n",
      "280:\tlearn: 0.1459958\ttotal: 1.58s\tremaining: 4.05s\n",
      "281:\tlearn: 0.1455911\ttotal: 1.59s\tremaining: 4.05s\n",
      "282:\tlearn: 0.1454164\ttotal: 1.59s\tremaining: 4.04s\n",
      "283:\tlearn: 0.1449436\ttotal: 1.6s\tremaining: 4.04s\n",
      "284:\tlearn: 0.1447654\ttotal: 1.61s\tremaining: 4.04s\n",
      "285:\tlearn: 0.1446168\ttotal: 1.61s\tremaining: 4.03s\n",
      "286:\tlearn: 0.1443565\ttotal: 1.62s\tremaining: 4.02s\n",
      "287:\tlearn: 0.1442069\ttotal: 1.62s\tremaining: 4.02s\n",
      "288:\tlearn: 0.1440388\ttotal: 1.63s\tremaining: 4.01s\n",
      "289:\tlearn: 0.1439348\ttotal: 1.64s\tremaining: 4.01s\n",
      "290:\tlearn: 0.1437589\ttotal: 1.64s\tremaining: 4s\n",
      "291:\tlearn: 0.1435801\ttotal: 1.65s\tremaining: 4s\n",
      "292:\tlearn: 0.1434230\ttotal: 1.65s\tremaining: 3.99s\n",
      "293:\tlearn: 0.1432967\ttotal: 1.66s\tremaining: 3.98s\n",
      "294:\tlearn: 0.1430711\ttotal: 1.66s\tremaining: 3.97s\n",
      "295:\tlearn: 0.1429270\ttotal: 1.67s\tremaining: 3.97s\n",
      "296:\tlearn: 0.1427261\ttotal: 1.67s\tremaining: 3.96s\n",
      "297:\tlearn: 0.1425568\ttotal: 1.68s\tremaining: 3.96s\n",
      "298:\tlearn: 0.1423748\ttotal: 1.68s\tremaining: 3.95s\n",
      "299:\tlearn: 0.1421808\ttotal: 1.69s\tremaining: 3.94s\n",
      "300:\tlearn: 0.1419365\ttotal: 1.69s\tremaining: 3.93s\n",
      "301:\tlearn: 0.1418181\ttotal: 1.7s\tremaining: 3.93s\n",
      "302:\tlearn: 0.1416314\ttotal: 1.7s\tremaining: 3.92s\n",
      "303:\tlearn: 0.1414868\ttotal: 1.71s\tremaining: 3.92s\n",
      "304:\tlearn: 0.1412904\ttotal: 1.72s\tremaining: 3.91s\n",
      "305:\tlearn: 0.1411155\ttotal: 1.72s\tremaining: 3.9s\n",
      "306:\tlearn: 0.1409067\ttotal: 1.73s\tremaining: 3.9s\n",
      "307:\tlearn: 0.1408062\ttotal: 1.73s\tremaining: 3.89s\n",
      "308:\tlearn: 0.1405857\ttotal: 1.74s\tremaining: 3.89s\n",
      "309:\tlearn: 0.1404517\ttotal: 1.74s\tremaining: 3.88s\n",
      "310:\tlearn: 0.1402984\ttotal: 1.75s\tremaining: 3.87s\n",
      "311:\tlearn: 0.1401437\ttotal: 1.75s\tremaining: 3.86s\n",
      "312:\tlearn: 0.1399723\ttotal: 1.76s\tremaining: 3.86s\n",
      "313:\tlearn: 0.1398377\ttotal: 1.76s\tremaining: 3.85s\n",
      "314:\tlearn: 0.1396858\ttotal: 1.77s\tremaining: 3.85s\n",
      "315:\tlearn: 0.1395524\ttotal: 1.77s\tremaining: 3.84s\n",
      "316:\tlearn: 0.1393712\ttotal: 1.78s\tremaining: 3.83s\n",
      "317:\tlearn: 0.1391840\ttotal: 1.78s\tremaining: 3.83s\n",
      "318:\tlearn: 0.1390195\ttotal: 1.79s\tremaining: 3.82s\n",
      "319:\tlearn: 0.1388370\ttotal: 1.79s\tremaining: 3.81s\n",
      "320:\tlearn: 0.1386634\ttotal: 1.8s\tremaining: 3.81s\n",
      "321:\tlearn: 0.1385194\ttotal: 1.81s\tremaining: 3.8s\n",
      "322:\tlearn: 0.1383743\ttotal: 1.81s\tremaining: 3.8s\n",
      "323:\tlearn: 0.1382453\ttotal: 1.82s\tremaining: 3.79s\n",
      "324:\tlearn: 0.1381326\ttotal: 1.82s\tremaining: 3.79s\n",
      "325:\tlearn: 0.1380127\ttotal: 1.83s\tremaining: 3.78s\n",
      "326:\tlearn: 0.1378520\ttotal: 1.83s\tremaining: 3.77s\n",
      "327:\tlearn: 0.1377000\ttotal: 1.84s\tremaining: 3.77s\n",
      "328:\tlearn: 0.1375336\ttotal: 1.84s\tremaining: 3.76s\n",
      "329:\tlearn: 0.1373862\ttotal: 1.85s\tremaining: 3.75s\n",
      "330:\tlearn: 0.1372002\ttotal: 1.85s\tremaining: 3.75s\n",
      "331:\tlearn: 0.1370448\ttotal: 1.86s\tremaining: 3.74s\n",
      "332:\tlearn: 0.1368663\ttotal: 1.86s\tremaining: 3.73s\n",
      "333:\tlearn: 0.1366995\ttotal: 1.87s\tremaining: 3.72s\n",
      "334:\tlearn: 0.1365847\ttotal: 1.87s\tremaining: 3.72s\n",
      "335:\tlearn: 0.1363890\ttotal: 1.88s\tremaining: 3.71s\n",
      "336:\tlearn: 0.1362452\ttotal: 1.88s\tremaining: 3.7s\n",
      "337:\tlearn: 0.1361541\ttotal: 1.89s\tremaining: 3.69s\n",
      "338:\tlearn: 0.1360161\ttotal: 1.89s\tremaining: 3.69s\n",
      "339:\tlearn: 0.1358196\ttotal: 1.9s\tremaining: 3.68s\n",
      "340:\tlearn: 0.1356816\ttotal: 1.9s\tremaining: 3.67s\n",
      "341:\tlearn: 0.1355370\ttotal: 1.9s\tremaining: 3.66s\n",
      "342:\tlearn: 0.1354082\ttotal: 1.91s\tremaining: 3.66s\n",
      "343:\tlearn: 0.1352384\ttotal: 1.91s\tremaining: 3.65s\n",
      "344:\tlearn: 0.1351322\ttotal: 1.92s\tremaining: 3.64s\n",
      "345:\tlearn: 0.1350273\ttotal: 1.92s\tremaining: 3.64s\n",
      "346:\tlearn: 0.1348846\ttotal: 1.93s\tremaining: 3.63s\n",
      "347:\tlearn: 0.1346975\ttotal: 1.93s\tremaining: 3.62s\n",
      "348:\tlearn: 0.1345593\ttotal: 1.94s\tremaining: 3.61s\n",
      "349:\tlearn: 0.1344398\ttotal: 1.94s\tremaining: 3.61s\n",
      "350:\tlearn: 0.1343029\ttotal: 1.95s\tremaining: 3.6s\n",
      "351:\tlearn: 0.1341385\ttotal: 1.95s\tremaining: 3.59s\n",
      "352:\tlearn: 0.1338653\ttotal: 1.95s\tremaining: 3.58s\n",
      "353:\tlearn: 0.1337431\ttotal: 1.96s\tremaining: 3.58s\n",
      "354:\tlearn: 0.1336265\ttotal: 1.96s\tremaining: 3.57s\n",
      "355:\tlearn: 0.1334984\ttotal: 1.97s\tremaining: 3.56s\n",
      "356:\tlearn: 0.1333961\ttotal: 1.97s\tremaining: 3.55s\n",
      "357:\tlearn: 0.1332689\ttotal: 1.98s\tremaining: 3.55s\n",
      "358:\tlearn: 0.1330733\ttotal: 1.98s\tremaining: 3.54s\n",
      "359:\tlearn: 0.1329595\ttotal: 1.99s\tremaining: 3.54s\n",
      "360:\tlearn: 0.1327918\ttotal: 1.99s\tremaining: 3.53s\n",
      "361:\tlearn: 0.1326447\ttotal: 2s\tremaining: 3.52s\n",
      "362:\tlearn: 0.1324872\ttotal: 2s\tremaining: 3.52s\n",
      "363:\tlearn: 0.1323603\ttotal: 2.01s\tremaining: 3.51s\n",
      "364:\tlearn: 0.1322444\ttotal: 2.01s\tremaining: 3.5s\n",
      "365:\tlearn: 0.1321232\ttotal: 2.02s\tremaining: 3.49s\n",
      "366:\tlearn: 0.1319892\ttotal: 2.02s\tremaining: 3.48s\n",
      "367:\tlearn: 0.1318626\ttotal: 2.02s\tremaining: 3.48s\n",
      "368:\tlearn: 0.1317230\ttotal: 2.03s\tremaining: 3.47s\n",
      "369:\tlearn: 0.1316114\ttotal: 2.03s\tremaining: 3.46s\n",
      "370:\tlearn: 0.1315134\ttotal: 2.04s\tremaining: 3.46s\n",
      "371:\tlearn: 0.1314184\ttotal: 2.04s\tremaining: 3.45s\n",
      "372:\tlearn: 0.1312859\ttotal: 2.05s\tremaining: 3.44s\n",
      "373:\tlearn: 0.1311781\ttotal: 2.05s\tremaining: 3.43s\n",
      "374:\tlearn: 0.1310404\ttotal: 2.05s\tremaining: 3.42s\n",
      "375:\tlearn: 0.1309154\ttotal: 2.06s\tremaining: 3.42s\n",
      "376:\tlearn: 0.1307686\ttotal: 2.06s\tremaining: 3.41s\n",
      "377:\tlearn: 0.1306774\ttotal: 2.07s\tremaining: 3.4s\n",
      "378:\tlearn: 0.1305606\ttotal: 2.07s\tremaining: 3.39s\n",
      "379:\tlearn: 0.1304276\ttotal: 2.08s\tremaining: 3.39s\n",
      "380:\tlearn: 0.1303143\ttotal: 2.08s\tremaining: 3.38s\n",
      "381:\tlearn: 0.1301805\ttotal: 2.08s\tremaining: 3.37s\n",
      "382:\tlearn: 0.1300706\ttotal: 2.09s\tremaining: 3.36s\n",
      "383:\tlearn: 0.1299771\ttotal: 2.09s\tremaining: 3.35s\n",
      "384:\tlearn: 0.1298410\ttotal: 2.1s\tremaining: 3.35s\n",
      "385:\tlearn: 0.1297233\ttotal: 2.1s\tremaining: 3.34s\n",
      "386:\tlearn: 0.1295799\ttotal: 2.11s\tremaining: 3.34s\n",
      "387:\tlearn: 0.1294437\ttotal: 2.11s\tremaining: 3.33s\n",
      "388:\tlearn: 0.1293613\ttotal: 2.12s\tremaining: 3.32s\n",
      "389:\tlearn: 0.1292595\ttotal: 2.12s\tremaining: 3.32s\n",
      "390:\tlearn: 0.1291350\ttotal: 2.12s\tremaining: 3.31s\n",
      "391:\tlearn: 0.1290048\ttotal: 2.13s\tremaining: 3.3s\n",
      "392:\tlearn: 0.1289006\ttotal: 2.13s\tremaining: 3.29s\n",
      "393:\tlearn: 0.1287887\ttotal: 2.14s\tremaining: 3.29s\n",
      "394:\tlearn: 0.1286987\ttotal: 2.14s\tremaining: 3.28s\n",
      "395:\tlearn: 0.1286165\ttotal: 2.15s\tremaining: 3.27s\n",
      "396:\tlearn: 0.1285294\ttotal: 2.15s\tremaining: 3.26s\n",
      "397:\tlearn: 0.1283804\ttotal: 2.15s\tremaining: 3.26s\n",
      "398:\tlearn: 0.1282423\ttotal: 2.16s\tremaining: 3.25s\n",
      "399:\tlearn: 0.1281496\ttotal: 2.16s\tremaining: 3.24s\n",
      "400:\tlearn: 0.1280612\ttotal: 2.17s\tremaining: 3.23s\n",
      "401:\tlearn: 0.1279240\ttotal: 2.17s\tremaining: 3.23s\n",
      "402:\tlearn: 0.1278195\ttotal: 2.17s\tremaining: 3.22s\n",
      "403:\tlearn: 0.1277119\ttotal: 2.18s\tremaining: 3.21s\n",
      "404:\tlearn: 0.1276291\ttotal: 2.18s\tremaining: 3.21s\n",
      "405:\tlearn: 0.1275397\ttotal: 2.19s\tremaining: 3.2s\n",
      "406:\tlearn: 0.1274157\ttotal: 2.19s\tremaining: 3.2s\n",
      "407:\tlearn: 0.1273265\ttotal: 2.2s\tremaining: 3.19s\n",
      "408:\tlearn: 0.1272067\ttotal: 2.2s\tremaining: 3.18s\n",
      "409:\tlearn: 0.1270885\ttotal: 2.21s\tremaining: 3.18s\n",
      "410:\tlearn: 0.1269956\ttotal: 2.22s\tremaining: 3.17s\n",
      "411:\tlearn: 0.1268736\ttotal: 2.22s\tremaining: 3.17s\n",
      "412:\tlearn: 0.1267454\ttotal: 2.23s\tremaining: 3.16s\n",
      "413:\tlearn: 0.1266451\ttotal: 2.23s\tremaining: 3.16s\n",
      "414:\tlearn: 0.1265144\ttotal: 2.23s\tremaining: 3.15s\n",
      "415:\tlearn: 0.1263754\ttotal: 2.24s\tremaining: 3.14s\n",
      "416:\tlearn: 0.1262808\ttotal: 2.24s\tremaining: 3.14s\n",
      "417:\tlearn: 0.1261893\ttotal: 2.25s\tremaining: 3.13s\n",
      "418:\tlearn: 0.1260939\ttotal: 2.25s\tremaining: 3.12s\n",
      "419:\tlearn: 0.1259984\ttotal: 2.26s\tremaining: 3.12s\n",
      "420:\tlearn: 0.1258752\ttotal: 2.26s\tremaining: 3.11s\n",
      "421:\tlearn: 0.1257427\ttotal: 2.27s\tremaining: 3.1s\n",
      "422:\tlearn: 0.1256705\ttotal: 2.27s\tremaining: 3.1s\n",
      "423:\tlearn: 0.1255943\ttotal: 2.27s\tremaining: 3.09s\n",
      "424:\tlearn: 0.1255008\ttotal: 2.28s\tremaining: 3.08s\n",
      "425:\tlearn: 0.1254118\ttotal: 2.28s\tremaining: 3.08s\n",
      "426:\tlearn: 0.1252587\ttotal: 2.29s\tremaining: 3.07s\n",
      "427:\tlearn: 0.1251817\ttotal: 2.29s\tremaining: 3.06s\n",
      "428:\tlearn: 0.1250660\ttotal: 2.29s\tremaining: 3.06s\n",
      "429:\tlearn: 0.1249929\ttotal: 2.3s\tremaining: 3.05s\n",
      "430:\tlearn: 0.1248844\ttotal: 2.3s\tremaining: 3.04s\n",
      "431:\tlearn: 0.1248279\ttotal: 2.31s\tremaining: 3.03s\n",
      "432:\tlearn: 0.1247072\ttotal: 2.31s\tremaining: 3.03s\n",
      "433:\tlearn: 0.1246205\ttotal: 2.32s\tremaining: 3.02s\n",
      "434:\tlearn: 0.1245131\ttotal: 2.32s\tremaining: 3.02s\n",
      "435:\tlearn: 0.1244243\ttotal: 2.33s\tremaining: 3.01s\n",
      "436:\tlearn: 0.1243240\ttotal: 2.33s\tremaining: 3s\n",
      "437:\tlearn: 0.1241871\ttotal: 2.33s\tremaining: 3s\n",
      "438:\tlearn: 0.1240761\ttotal: 2.34s\tremaining: 2.99s\n",
      "439:\tlearn: 0.1238985\ttotal: 2.34s\tremaining: 2.98s\n",
      "440:\tlearn: 0.1238130\ttotal: 2.35s\tremaining: 2.98s\n",
      "441:\tlearn: 0.1236992\ttotal: 2.35s\tremaining: 2.97s\n",
      "442:\tlearn: 0.1235799\ttotal: 2.35s\tremaining: 2.96s\n",
      "443:\tlearn: 0.1234415\ttotal: 2.36s\tremaining: 2.95s\n",
      "444:\tlearn: 0.1233625\ttotal: 2.36s\tremaining: 2.95s\n",
      "445:\tlearn: 0.1232370\ttotal: 2.37s\tremaining: 2.94s\n",
      "446:\tlearn: 0.1231373\ttotal: 2.37s\tremaining: 2.93s\n",
      "447:\tlearn: 0.1230468\ttotal: 2.38s\tremaining: 2.93s\n",
      "448:\tlearn: 0.1229470\ttotal: 2.38s\tremaining: 2.92s\n",
      "449:\tlearn: 0.1228534\ttotal: 2.38s\tremaining: 2.91s\n",
      "450:\tlearn: 0.1227627\ttotal: 2.39s\tremaining: 2.91s\n",
      "451:\tlearn: 0.1226226\ttotal: 2.39s\tremaining: 2.9s\n",
      "452:\tlearn: 0.1225105\ttotal: 2.4s\tremaining: 2.9s\n",
      "453:\tlearn: 0.1224176\ttotal: 2.4s\tremaining: 2.89s\n",
      "454:\tlearn: 0.1222991\ttotal: 2.41s\tremaining: 2.88s\n",
      "455:\tlearn: 0.1221877\ttotal: 2.41s\tremaining: 2.88s\n",
      "456:\tlearn: 0.1220916\ttotal: 2.41s\tremaining: 2.87s\n",
      "457:\tlearn: 0.1219975\ttotal: 2.42s\tremaining: 2.86s\n",
      "458:\tlearn: 0.1219098\ttotal: 2.42s\tremaining: 2.85s\n",
      "459:\tlearn: 0.1218217\ttotal: 2.43s\tremaining: 2.85s\n",
      "460:\tlearn: 0.1217064\ttotal: 2.43s\tremaining: 2.84s\n",
      "461:\tlearn: 0.1216037\ttotal: 2.44s\tremaining: 2.83s\n",
      "462:\tlearn: 0.1214912\ttotal: 2.44s\tremaining: 2.83s\n",
      "463:\tlearn: 0.1213901\ttotal: 2.44s\tremaining: 2.82s\n",
      "464:\tlearn: 0.1212880\ttotal: 2.45s\tremaining: 2.82s\n",
      "465:\tlearn: 0.1211794\ttotal: 2.45s\tremaining: 2.81s\n",
      "466:\tlearn: 0.1211026\ttotal: 2.46s\tremaining: 2.8s\n",
      "467:\tlearn: 0.1210107\ttotal: 2.46s\tremaining: 2.8s\n",
      "468:\tlearn: 0.1209521\ttotal: 2.46s\tremaining: 2.79s\n",
      "469:\tlearn: 0.1208805\ttotal: 2.47s\tremaining: 2.78s\n",
      "470:\tlearn: 0.1207813\ttotal: 2.47s\tremaining: 2.78s\n",
      "471:\tlearn: 0.1206437\ttotal: 2.48s\tremaining: 2.77s\n",
      "472:\tlearn: 0.1205650\ttotal: 2.48s\tremaining: 2.76s\n",
      "473:\tlearn: 0.1204443\ttotal: 2.48s\tremaining: 2.76s\n",
      "474:\tlearn: 0.1203319\ttotal: 2.49s\tremaining: 2.75s\n",
      "475:\tlearn: 0.1202386\ttotal: 2.49s\tremaining: 2.74s\n",
      "476:\tlearn: 0.1201354\ttotal: 2.5s\tremaining: 2.74s\n",
      "477:\tlearn: 0.1200576\ttotal: 2.5s\tremaining: 2.73s\n",
      "478:\tlearn: 0.1199559\ttotal: 2.51s\tremaining: 2.73s\n",
      "479:\tlearn: 0.1198126\ttotal: 2.51s\tremaining: 2.72s\n",
      "480:\tlearn: 0.1197275\ttotal: 2.51s\tremaining: 2.71s\n",
      "481:\tlearn: 0.1196204\ttotal: 2.52s\tremaining: 2.71s\n",
      "482:\tlearn: 0.1194966\ttotal: 2.52s\tremaining: 2.7s\n",
      "483:\tlearn: 0.1194260\ttotal: 2.53s\tremaining: 2.69s\n",
      "484:\tlearn: 0.1193421\ttotal: 2.53s\tremaining: 2.69s\n",
      "485:\tlearn: 0.1192729\ttotal: 2.54s\tremaining: 2.68s\n",
      "486:\tlearn: 0.1191778\ttotal: 2.54s\tremaining: 2.67s\n",
      "487:\tlearn: 0.1191021\ttotal: 2.54s\tremaining: 2.67s\n",
      "488:\tlearn: 0.1190083\ttotal: 2.55s\tremaining: 2.66s\n",
      "489:\tlearn: 0.1189310\ttotal: 2.55s\tremaining: 2.65s\n",
      "490:\tlearn: 0.1188273\ttotal: 2.56s\tremaining: 2.65s\n",
      "491:\tlearn: 0.1187223\ttotal: 2.56s\tremaining: 2.64s\n",
      "492:\tlearn: 0.1186578\ttotal: 2.56s\tremaining: 2.64s\n",
      "493:\tlearn: 0.1185600\ttotal: 2.57s\tremaining: 2.63s\n",
      "494:\tlearn: 0.1184667\ttotal: 2.57s\tremaining: 2.62s\n",
      "495:\tlearn: 0.1183908\ttotal: 2.58s\tremaining: 2.62s\n",
      "496:\tlearn: 0.1183062\ttotal: 2.58s\tremaining: 2.61s\n",
      "497:\tlearn: 0.1182342\ttotal: 2.59s\tremaining: 2.61s\n",
      "498:\tlearn: 0.1181601\ttotal: 2.6s\tremaining: 2.61s\n",
      "499:\tlearn: 0.1180461\ttotal: 2.61s\tremaining: 2.61s\n",
      "500:\tlearn: 0.1179533\ttotal: 2.62s\tremaining: 2.61s\n",
      "501:\tlearn: 0.1178855\ttotal: 2.63s\tremaining: 2.6s\n",
      "502:\tlearn: 0.1177815\ttotal: 2.63s\tremaining: 2.6s\n",
      "503:\tlearn: 0.1176844\ttotal: 2.64s\tremaining: 2.6s\n",
      "504:\tlearn: 0.1176154\ttotal: 2.65s\tremaining: 2.59s\n",
      "505:\tlearn: 0.1175418\ttotal: 2.65s\tremaining: 2.59s\n",
      "506:\tlearn: 0.1174760\ttotal: 2.65s\tremaining: 2.58s\n",
      "507:\tlearn: 0.1173874\ttotal: 2.66s\tremaining: 2.58s\n",
      "508:\tlearn: 0.1173407\ttotal: 2.66s\tremaining: 2.57s\n",
      "509:\tlearn: 0.1172951\ttotal: 2.67s\tremaining: 2.56s\n",
      "510:\tlearn: 0.1172142\ttotal: 2.67s\tremaining: 2.56s\n",
      "511:\tlearn: 0.1170814\ttotal: 2.67s\tremaining: 2.55s\n",
      "512:\tlearn: 0.1169538\ttotal: 2.68s\tremaining: 2.54s\n",
      "513:\tlearn: 0.1168927\ttotal: 2.68s\tremaining: 2.54s\n",
      "514:\tlearn: 0.1168028\ttotal: 2.69s\tremaining: 2.53s\n",
      "515:\tlearn: 0.1167149\ttotal: 2.69s\tremaining: 2.52s\n",
      "516:\tlearn: 0.1166059\ttotal: 2.7s\tremaining: 2.52s\n",
      "517:\tlearn: 0.1165377\ttotal: 2.7s\tremaining: 2.51s\n",
      "518:\tlearn: 0.1164403\ttotal: 2.71s\tremaining: 2.51s\n",
      "519:\tlearn: 0.1163351\ttotal: 2.71s\tremaining: 2.5s\n",
      "520:\tlearn: 0.1162361\ttotal: 2.71s\tremaining: 2.49s\n",
      "521:\tlearn: 0.1161528\ttotal: 2.72s\tremaining: 2.49s\n",
      "522:\tlearn: 0.1160500\ttotal: 2.72s\tremaining: 2.48s\n",
      "523:\tlearn: 0.1159861\ttotal: 2.73s\tremaining: 2.48s\n",
      "524:\tlearn: 0.1158787\ttotal: 2.73s\tremaining: 2.47s\n",
      "525:\tlearn: 0.1158068\ttotal: 2.73s\tremaining: 2.46s\n",
      "526:\tlearn: 0.1157360\ttotal: 2.74s\tremaining: 2.46s\n",
      "527:\tlearn: 0.1156656\ttotal: 2.74s\tremaining: 2.45s\n",
      "528:\tlearn: 0.1155851\ttotal: 2.75s\tremaining: 2.44s\n",
      "529:\tlearn: 0.1155163\ttotal: 2.75s\tremaining: 2.44s\n",
      "530:\tlearn: 0.1153966\ttotal: 2.75s\tremaining: 2.43s\n",
      "531:\tlearn: 0.1153282\ttotal: 2.76s\tremaining: 2.43s\n",
      "532:\tlearn: 0.1152663\ttotal: 2.76s\tremaining: 2.42s\n",
      "533:\tlearn: 0.1151969\ttotal: 2.77s\tremaining: 2.41s\n",
      "534:\tlearn: 0.1151009\ttotal: 2.77s\tremaining: 2.41s\n",
      "535:\tlearn: 0.1150107\ttotal: 2.77s\tremaining: 2.4s\n",
      "536:\tlearn: 0.1149127\ttotal: 2.78s\tremaining: 2.4s\n",
      "537:\tlearn: 0.1147918\ttotal: 2.78s\tremaining: 2.39s\n",
      "538:\tlearn: 0.1147102\ttotal: 2.79s\tremaining: 2.38s\n",
      "539:\tlearn: 0.1146292\ttotal: 2.79s\tremaining: 2.38s\n",
      "540:\tlearn: 0.1145586\ttotal: 2.8s\tremaining: 2.37s\n",
      "541:\tlearn: 0.1144719\ttotal: 2.8s\tremaining: 2.37s\n",
      "542:\tlearn: 0.1143895\ttotal: 2.81s\tremaining: 2.36s\n",
      "543:\tlearn: 0.1143199\ttotal: 2.81s\tremaining: 2.35s\n",
      "544:\tlearn: 0.1142246\ttotal: 2.81s\tremaining: 2.35s\n",
      "545:\tlearn: 0.1141173\ttotal: 2.82s\tremaining: 2.34s\n",
      "546:\tlearn: 0.1140707\ttotal: 2.82s\tremaining: 2.34s\n",
      "547:\tlearn: 0.1140056\ttotal: 2.83s\tremaining: 2.33s\n",
      "548:\tlearn: 0.1139382\ttotal: 2.83s\tremaining: 2.33s\n",
      "549:\tlearn: 0.1138979\ttotal: 2.83s\tremaining: 2.32s\n",
      "550:\tlearn: 0.1138007\ttotal: 2.84s\tremaining: 2.31s\n",
      "551:\tlearn: 0.1136835\ttotal: 2.84s\tremaining: 2.31s\n",
      "552:\tlearn: 0.1135944\ttotal: 2.85s\tremaining: 2.3s\n",
      "553:\tlearn: 0.1135071\ttotal: 2.85s\tremaining: 2.29s\n",
      "554:\tlearn: 0.1134346\ttotal: 2.85s\tremaining: 2.29s\n",
      "555:\tlearn: 0.1133629\ttotal: 2.86s\tremaining: 2.28s\n",
      "556:\tlearn: 0.1132886\ttotal: 2.86s\tremaining: 2.28s\n",
      "557:\tlearn: 0.1132264\ttotal: 2.87s\tremaining: 2.27s\n",
      "558:\tlearn: 0.1131588\ttotal: 2.87s\tremaining: 2.27s\n",
      "559:\tlearn: 0.1130376\ttotal: 2.88s\tremaining: 2.26s\n",
      "560:\tlearn: 0.1129430\ttotal: 2.88s\tremaining: 2.25s\n",
      "561:\tlearn: 0.1128821\ttotal: 2.88s\tremaining: 2.25s\n",
      "562:\tlearn: 0.1128177\ttotal: 2.89s\tremaining: 2.24s\n",
      "563:\tlearn: 0.1127574\ttotal: 2.89s\tremaining: 2.24s\n",
      "564:\tlearn: 0.1126964\ttotal: 2.9s\tremaining: 2.23s\n",
      "565:\tlearn: 0.1126261\ttotal: 2.9s\tremaining: 2.22s\n",
      "566:\tlearn: 0.1125551\ttotal: 2.91s\tremaining: 2.22s\n",
      "567:\tlearn: 0.1124775\ttotal: 2.91s\tremaining: 2.21s\n",
      "568:\tlearn: 0.1123901\ttotal: 2.91s\tremaining: 2.21s\n",
      "569:\tlearn: 0.1123001\ttotal: 2.92s\tremaining: 2.2s\n",
      "570:\tlearn: 0.1122379\ttotal: 2.92s\tremaining: 2.2s\n",
      "571:\tlearn: 0.1121665\ttotal: 2.93s\tremaining: 2.19s\n",
      "572:\tlearn: 0.1120911\ttotal: 2.93s\tremaining: 2.18s\n",
      "573:\tlearn: 0.1120021\ttotal: 2.94s\tremaining: 2.18s\n",
      "574:\tlearn: 0.1119145\ttotal: 2.94s\tremaining: 2.17s\n",
      "575:\tlearn: 0.1118464\ttotal: 2.94s\tremaining: 2.17s\n",
      "576:\tlearn: 0.1117673\ttotal: 2.95s\tremaining: 2.16s\n",
      "577:\tlearn: 0.1116835\ttotal: 2.95s\tremaining: 2.16s\n",
      "578:\tlearn: 0.1115791\ttotal: 2.96s\tremaining: 2.15s\n",
      "579:\tlearn: 0.1115085\ttotal: 2.96s\tremaining: 2.15s\n",
      "580:\tlearn: 0.1114389\ttotal: 2.97s\tremaining: 2.14s\n",
      "581:\tlearn: 0.1113752\ttotal: 2.97s\tremaining: 2.13s\n",
      "582:\tlearn: 0.1112556\ttotal: 2.98s\tremaining: 2.13s\n",
      "583:\tlearn: 0.1111652\ttotal: 2.98s\tremaining: 2.13s\n",
      "584:\tlearn: 0.1110629\ttotal: 2.99s\tremaining: 2.12s\n",
      "585:\tlearn: 0.1109832\ttotal: 2.99s\tremaining: 2.11s\n",
      "586:\tlearn: 0.1108133\ttotal: 3s\tremaining: 2.11s\n",
      "587:\tlearn: 0.1107443\ttotal: 3s\tremaining: 2.1s\n",
      "588:\tlearn: 0.1106602\ttotal: 3.01s\tremaining: 2.1s\n",
      "589:\tlearn: 0.1105747\ttotal: 3.01s\tremaining: 2.09s\n",
      "590:\tlearn: 0.1104756\ttotal: 3.02s\tremaining: 2.09s\n",
      "591:\tlearn: 0.1104438\ttotal: 3.02s\tremaining: 2.08s\n",
      "592:\tlearn: 0.1103785\ttotal: 3.02s\tremaining: 2.08s\n",
      "593:\tlearn: 0.1102513\ttotal: 3.03s\tremaining: 2.07s\n",
      "594:\tlearn: 0.1101802\ttotal: 3.03s\tremaining: 2.06s\n",
      "595:\tlearn: 0.1100859\ttotal: 3.04s\tremaining: 2.06s\n",
      "596:\tlearn: 0.1100158\ttotal: 3.04s\tremaining: 2.05s\n",
      "597:\tlearn: 0.1099490\ttotal: 3.04s\tremaining: 2.05s\n",
      "598:\tlearn: 0.1098365\ttotal: 3.05s\tremaining: 2.04s\n",
      "599:\tlearn: 0.1097265\ttotal: 3.05s\tremaining: 2.04s\n",
      "600:\tlearn: 0.1096527\ttotal: 3.06s\tremaining: 2.03s\n",
      "601:\tlearn: 0.1095995\ttotal: 3.06s\tremaining: 2.02s\n",
      "602:\tlearn: 0.1095258\ttotal: 3.07s\tremaining: 2.02s\n",
      "603:\tlearn: 0.1094604\ttotal: 3.07s\tremaining: 2.01s\n",
      "604:\tlearn: 0.1094083\ttotal: 3.07s\tremaining: 2.01s\n",
      "605:\tlearn: 0.1093343\ttotal: 3.08s\tremaining: 2s\n",
      "606:\tlearn: 0.1092800\ttotal: 3.08s\tremaining: 2s\n",
      "607:\tlearn: 0.1092179\ttotal: 3.09s\tremaining: 1.99s\n",
      "608:\tlearn: 0.1091568\ttotal: 3.09s\tremaining: 1.98s\n",
      "609:\tlearn: 0.1090272\ttotal: 3.09s\tremaining: 1.98s\n",
      "610:\tlearn: 0.1089187\ttotal: 3.1s\tremaining: 1.97s\n",
      "611:\tlearn: 0.1088398\ttotal: 3.1s\tremaining: 1.97s\n",
      "612:\tlearn: 0.1087251\ttotal: 3.11s\tremaining: 1.96s\n",
      "613:\tlearn: 0.1086459\ttotal: 3.11s\tremaining: 1.96s\n",
      "614:\tlearn: 0.1085947\ttotal: 3.12s\tremaining: 1.95s\n",
      "615:\tlearn: 0.1085093\ttotal: 3.12s\tremaining: 1.94s\n",
      "616:\tlearn: 0.1084351\ttotal: 3.12s\tremaining: 1.94s\n",
      "617:\tlearn: 0.1083447\ttotal: 3.13s\tremaining: 1.93s\n",
      "618:\tlearn: 0.1082800\ttotal: 3.13s\tremaining: 1.93s\n",
      "619:\tlearn: 0.1081915\ttotal: 3.14s\tremaining: 1.92s\n",
      "620:\tlearn: 0.1081063\ttotal: 3.14s\tremaining: 1.92s\n",
      "621:\tlearn: 0.1080442\ttotal: 3.14s\tremaining: 1.91s\n",
      "622:\tlearn: 0.1079729\ttotal: 3.15s\tremaining: 1.91s\n",
      "623:\tlearn: 0.1079053\ttotal: 3.15s\tremaining: 1.9s\n",
      "624:\tlearn: 0.1078050\ttotal: 3.16s\tremaining: 1.89s\n",
      "625:\tlearn: 0.1077573\ttotal: 3.16s\tremaining: 1.89s\n",
      "626:\tlearn: 0.1076991\ttotal: 3.17s\tremaining: 1.88s\n",
      "627:\tlearn: 0.1075892\ttotal: 3.17s\tremaining: 1.88s\n",
      "628:\tlearn: 0.1075141\ttotal: 3.17s\tremaining: 1.87s\n",
      "629:\tlearn: 0.1074459\ttotal: 3.18s\tremaining: 1.87s\n",
      "630:\tlearn: 0.1073544\ttotal: 3.18s\tremaining: 1.86s\n",
      "631:\tlearn: 0.1072942\ttotal: 3.19s\tremaining: 1.86s\n",
      "632:\tlearn: 0.1071969\ttotal: 3.19s\tremaining: 1.85s\n",
      "633:\tlearn: 0.1071106\ttotal: 3.2s\tremaining: 1.84s\n",
      "634:\tlearn: 0.1070624\ttotal: 3.2s\tremaining: 1.84s\n",
      "635:\tlearn: 0.1069919\ttotal: 3.2s\tremaining: 1.83s\n",
      "636:\tlearn: 0.1069347\ttotal: 3.21s\tremaining: 1.83s\n",
      "637:\tlearn: 0.1068193\ttotal: 3.21s\tremaining: 1.82s\n",
      "638:\tlearn: 0.1067363\ttotal: 3.22s\tremaining: 1.82s\n",
      "639:\tlearn: 0.1066700\ttotal: 3.22s\tremaining: 1.81s\n",
      "640:\tlearn: 0.1065774\ttotal: 3.23s\tremaining: 1.81s\n",
      "641:\tlearn: 0.1065237\ttotal: 3.23s\tremaining: 1.8s\n",
      "642:\tlearn: 0.1064431\ttotal: 3.23s\tremaining: 1.79s\n",
      "643:\tlearn: 0.1064272\ttotal: 3.24s\tremaining: 1.79s\n",
      "644:\tlearn: 0.1063261\ttotal: 3.24s\tremaining: 1.78s\n",
      "645:\tlearn: 0.1062696\ttotal: 3.25s\tremaining: 1.78s\n",
      "646:\tlearn: 0.1062149\ttotal: 3.25s\tremaining: 1.77s\n",
      "647:\tlearn: 0.1061717\ttotal: 3.25s\tremaining: 1.77s\n",
      "648:\tlearn: 0.1061092\ttotal: 3.26s\tremaining: 1.76s\n",
      "649:\tlearn: 0.1060126\ttotal: 3.26s\tremaining: 1.76s\n",
      "650:\tlearn: 0.1059518\ttotal: 3.27s\tremaining: 1.75s\n",
      "651:\tlearn: 0.1058922\ttotal: 3.27s\tremaining: 1.75s\n",
      "652:\tlearn: 0.1058248\ttotal: 3.28s\tremaining: 1.74s\n",
      "653:\tlearn: 0.1057699\ttotal: 3.28s\tremaining: 1.74s\n",
      "654:\tlearn: 0.1057074\ttotal: 3.28s\tremaining: 1.73s\n",
      "655:\tlearn: 0.1056529\ttotal: 3.29s\tremaining: 1.72s\n",
      "656:\tlearn: 0.1056038\ttotal: 3.29s\tremaining: 1.72s\n",
      "657:\tlearn: 0.1055359\ttotal: 3.3s\tremaining: 1.71s\n",
      "658:\tlearn: 0.1054840\ttotal: 3.3s\tremaining: 1.71s\n",
      "659:\tlearn: 0.1053996\ttotal: 3.31s\tremaining: 1.7s\n",
      "660:\tlearn: 0.1053799\ttotal: 3.31s\tremaining: 1.7s\n",
      "661:\tlearn: 0.1052851\ttotal: 3.31s\tremaining: 1.69s\n",
      "662:\tlearn: 0.1051959\ttotal: 3.32s\tremaining: 1.69s\n",
      "663:\tlearn: 0.1050886\ttotal: 3.32s\tremaining: 1.68s\n",
      "664:\tlearn: 0.1050139\ttotal: 3.33s\tremaining: 1.68s\n",
      "665:\tlearn: 0.1049992\ttotal: 3.33s\tremaining: 1.67s\n",
      "666:\tlearn: 0.1049256\ttotal: 3.33s\tremaining: 1.67s\n",
      "667:\tlearn: 0.1048675\ttotal: 3.34s\tremaining: 1.66s\n",
      "668:\tlearn: 0.1048071\ttotal: 3.34s\tremaining: 1.65s\n",
      "669:\tlearn: 0.1047615\ttotal: 3.35s\tremaining: 1.65s\n",
      "670:\tlearn: 0.1046722\ttotal: 3.35s\tremaining: 1.64s\n",
      "671:\tlearn: 0.1046143\ttotal: 3.36s\tremaining: 1.64s\n",
      "672:\tlearn: 0.1045615\ttotal: 3.36s\tremaining: 1.63s\n",
      "673:\tlearn: 0.1045109\ttotal: 3.37s\tremaining: 1.63s\n",
      "674:\tlearn: 0.1044108\ttotal: 3.37s\tremaining: 1.62s\n",
      "675:\tlearn: 0.1043295\ttotal: 3.37s\tremaining: 1.62s\n",
      "676:\tlearn: 0.1042994\ttotal: 3.38s\tremaining: 1.61s\n",
      "677:\tlearn: 0.1042176\ttotal: 3.38s\tremaining: 1.61s\n",
      "678:\tlearn: 0.1041423\ttotal: 3.39s\tremaining: 1.6s\n",
      "679:\tlearn: 0.1040972\ttotal: 3.39s\tremaining: 1.6s\n",
      "680:\tlearn: 0.1040246\ttotal: 3.4s\tremaining: 1.59s\n",
      "681:\tlearn: 0.1039642\ttotal: 3.4s\tremaining: 1.58s\n",
      "682:\tlearn: 0.1039187\ttotal: 3.4s\tremaining: 1.58s\n",
      "683:\tlearn: 0.1038311\ttotal: 3.41s\tremaining: 1.57s\n",
      "684:\tlearn: 0.1037442\ttotal: 3.41s\tremaining: 1.57s\n",
      "685:\tlearn: 0.1036225\ttotal: 3.42s\tremaining: 1.56s\n",
      "686:\tlearn: 0.1035641\ttotal: 3.42s\tremaining: 1.56s\n",
      "687:\tlearn: 0.1035331\ttotal: 3.42s\tremaining: 1.55s\n",
      "688:\tlearn: 0.1034395\ttotal: 3.43s\tremaining: 1.55s\n",
      "689:\tlearn: 0.1033564\ttotal: 3.43s\tremaining: 1.54s\n",
      "690:\tlearn: 0.1032550\ttotal: 3.44s\tremaining: 1.54s\n",
      "691:\tlearn: 0.1032143\ttotal: 3.44s\tremaining: 1.53s\n",
      "692:\tlearn: 0.1031155\ttotal: 3.45s\tremaining: 1.53s\n",
      "693:\tlearn: 0.1030365\ttotal: 3.45s\tremaining: 1.52s\n",
      "694:\tlearn: 0.1029540\ttotal: 3.46s\tremaining: 1.52s\n",
      "695:\tlearn: 0.1028772\ttotal: 3.46s\tremaining: 1.51s\n",
      "696:\tlearn: 0.1028088\ttotal: 3.46s\tremaining: 1.5s\n",
      "697:\tlearn: 0.1027956\ttotal: 3.47s\tremaining: 1.5s\n",
      "698:\tlearn: 0.1027305\ttotal: 3.47s\tremaining: 1.49s\n",
      "699:\tlearn: 0.1026370\ttotal: 3.48s\tremaining: 1.49s\n",
      "700:\tlearn: 0.1025731\ttotal: 3.48s\tremaining: 1.48s\n",
      "701:\tlearn: 0.1025268\ttotal: 3.48s\tremaining: 1.48s\n",
      "702:\tlearn: 0.1024555\ttotal: 3.49s\tremaining: 1.47s\n",
      "703:\tlearn: 0.1024181\ttotal: 3.49s\tremaining: 1.47s\n",
      "704:\tlearn: 0.1023512\ttotal: 3.5s\tremaining: 1.46s\n",
      "705:\tlearn: 0.1022799\ttotal: 3.5s\tremaining: 1.46s\n",
      "706:\tlearn: 0.1022247\ttotal: 3.5s\tremaining: 1.45s\n",
      "707:\tlearn: 0.1021913\ttotal: 3.51s\tremaining: 1.45s\n",
      "708:\tlearn: 0.1021349\ttotal: 3.51s\tremaining: 1.44s\n",
      "709:\tlearn: 0.1020665\ttotal: 3.52s\tremaining: 1.44s\n",
      "710:\tlearn: 0.1020031\ttotal: 3.52s\tremaining: 1.43s\n",
      "711:\tlearn: 0.1019015\ttotal: 3.52s\tremaining: 1.43s\n",
      "712:\tlearn: 0.1018059\ttotal: 3.53s\tremaining: 1.42s\n",
      "713:\tlearn: 0.1017462\ttotal: 3.53s\tremaining: 1.42s\n",
      "714:\tlearn: 0.1016531\ttotal: 3.54s\tremaining: 1.41s\n",
      "715:\tlearn: 0.1015724\ttotal: 3.54s\tremaining: 1.4s\n",
      "716:\tlearn: 0.1015372\ttotal: 3.55s\tremaining: 1.4s\n",
      "717:\tlearn: 0.1014697\ttotal: 3.55s\tremaining: 1.39s\n",
      "718:\tlearn: 0.1013896\ttotal: 3.55s\tremaining: 1.39s\n",
      "719:\tlearn: 0.1013774\ttotal: 3.56s\tremaining: 1.38s\n",
      "720:\tlearn: 0.1012879\ttotal: 3.56s\tremaining: 1.38s\n",
      "721:\tlearn: 0.1011837\ttotal: 3.57s\tremaining: 1.37s\n",
      "722:\tlearn: 0.1011194\ttotal: 3.57s\tremaining: 1.37s\n",
      "723:\tlearn: 0.1010556\ttotal: 3.58s\tremaining: 1.36s\n",
      "724:\tlearn: 0.1010215\ttotal: 3.58s\tremaining: 1.36s\n",
      "725:\tlearn: 0.1009745\ttotal: 3.58s\tremaining: 1.35s\n",
      "726:\tlearn: 0.1008903\ttotal: 3.59s\tremaining: 1.35s\n",
      "727:\tlearn: 0.1008366\ttotal: 3.59s\tremaining: 1.34s\n",
      "728:\tlearn: 0.1007409\ttotal: 3.6s\tremaining: 1.34s\n",
      "729:\tlearn: 0.1006837\ttotal: 3.6s\tremaining: 1.33s\n",
      "730:\tlearn: 0.1006452\ttotal: 3.6s\tremaining: 1.33s\n",
      "731:\tlearn: 0.1005882\ttotal: 3.61s\tremaining: 1.32s\n",
      "732:\tlearn: 0.1005144\ttotal: 3.61s\tremaining: 1.32s\n",
      "733:\tlearn: 0.1004417\ttotal: 3.62s\tremaining: 1.31s\n",
      "734:\tlearn: 0.1003447\ttotal: 3.62s\tremaining: 1.3s\n",
      "735:\tlearn: 0.1003007\ttotal: 3.63s\tremaining: 1.3s\n",
      "736:\tlearn: 0.1002076\ttotal: 3.63s\tremaining: 1.29s\n",
      "737:\tlearn: 0.1001339\ttotal: 3.63s\tremaining: 1.29s\n",
      "738:\tlearn: 0.1000720\ttotal: 3.64s\tremaining: 1.28s\n",
      "739:\tlearn: 0.1000100\ttotal: 3.64s\tremaining: 1.28s\n",
      "740:\tlearn: 0.0999654\ttotal: 3.65s\tremaining: 1.27s\n",
      "741:\tlearn: 0.0998925\ttotal: 3.65s\tremaining: 1.27s\n",
      "742:\tlearn: 0.0998550\ttotal: 3.65s\tremaining: 1.26s\n",
      "743:\tlearn: 0.0997908\ttotal: 3.66s\tremaining: 1.26s\n",
      "744:\tlearn: 0.0996984\ttotal: 3.66s\tremaining: 1.25s\n",
      "745:\tlearn: 0.0996259\ttotal: 3.67s\tremaining: 1.25s\n",
      "746:\tlearn: 0.0995568\ttotal: 3.67s\tremaining: 1.24s\n",
      "747:\tlearn: 0.0994971\ttotal: 3.67s\tremaining: 1.24s\n",
      "748:\tlearn: 0.0994287\ttotal: 3.68s\tremaining: 1.23s\n",
      "749:\tlearn: 0.0993511\ttotal: 3.68s\tremaining: 1.23s\n",
      "750:\tlearn: 0.0992789\ttotal: 3.69s\tremaining: 1.22s\n",
      "751:\tlearn: 0.0992341\ttotal: 3.69s\tremaining: 1.22s\n",
      "752:\tlearn: 0.0991641\ttotal: 3.7s\tremaining: 1.21s\n",
      "753:\tlearn: 0.0991138\ttotal: 3.7s\tremaining: 1.21s\n",
      "754:\tlearn: 0.0990829\ttotal: 3.71s\tremaining: 1.2s\n",
      "755:\tlearn: 0.0989885\ttotal: 3.71s\tremaining: 1.2s\n",
      "756:\tlearn: 0.0989143\ttotal: 3.71s\tremaining: 1.19s\n",
      "757:\tlearn: 0.0988225\ttotal: 3.72s\tremaining: 1.19s\n",
      "758:\tlearn: 0.0987718\ttotal: 3.72s\tremaining: 1.18s\n",
      "759:\tlearn: 0.0987128\ttotal: 3.73s\tremaining: 1.18s\n",
      "760:\tlearn: 0.0986398\ttotal: 3.73s\tremaining: 1.17s\n",
      "761:\tlearn: 0.0985839\ttotal: 3.74s\tremaining: 1.17s\n",
      "762:\tlearn: 0.0985205\ttotal: 3.74s\tremaining: 1.16s\n",
      "763:\tlearn: 0.0984327\ttotal: 3.74s\tremaining: 1.16s\n",
      "764:\tlearn: 0.0983762\ttotal: 3.75s\tremaining: 1.15s\n",
      "765:\tlearn: 0.0982710\ttotal: 3.75s\tremaining: 1.15s\n",
      "766:\tlearn: 0.0982356\ttotal: 3.76s\tremaining: 1.14s\n",
      "767:\tlearn: 0.0981893\ttotal: 3.76s\tremaining: 1.14s\n",
      "768:\tlearn: 0.0981079\ttotal: 3.77s\tremaining: 1.13s\n",
      "769:\tlearn: 0.0980558\ttotal: 3.77s\tremaining: 1.13s\n",
      "770:\tlearn: 0.0979649\ttotal: 3.77s\tremaining: 1.12s\n",
      "771:\tlearn: 0.0979014\ttotal: 3.78s\tremaining: 1.12s\n",
      "772:\tlearn: 0.0978698\ttotal: 3.78s\tremaining: 1.11s\n",
      "773:\tlearn: 0.0978168\ttotal: 3.79s\tremaining: 1.11s\n",
      "774:\tlearn: 0.0977394\ttotal: 3.79s\tremaining: 1.1s\n",
      "775:\tlearn: 0.0976464\ttotal: 3.8s\tremaining: 1.1s\n",
      "776:\tlearn: 0.0976025\ttotal: 3.8s\tremaining: 1.09s\n",
      "777:\tlearn: 0.0975121\ttotal: 3.81s\tremaining: 1.08s\n",
      "778:\tlearn: 0.0974530\ttotal: 3.81s\tremaining: 1.08s\n",
      "779:\tlearn: 0.0973996\ttotal: 3.81s\tremaining: 1.07s\n",
      "780:\tlearn: 0.0973313\ttotal: 3.82s\tremaining: 1.07s\n",
      "781:\tlearn: 0.0972654\ttotal: 3.82s\tremaining: 1.06s\n",
      "782:\tlearn: 0.0972245\ttotal: 3.83s\tremaining: 1.06s\n",
      "783:\tlearn: 0.0971640\ttotal: 3.83s\tremaining: 1.05s\n",
      "784:\tlearn: 0.0971153\ttotal: 3.83s\tremaining: 1.05s\n",
      "785:\tlearn: 0.0970627\ttotal: 3.84s\tremaining: 1.04s\n",
      "786:\tlearn: 0.0970010\ttotal: 3.84s\tremaining: 1.04s\n",
      "787:\tlearn: 0.0969022\ttotal: 3.85s\tremaining: 1.03s\n",
      "788:\tlearn: 0.0968578\ttotal: 3.85s\tremaining: 1.03s\n",
      "789:\tlearn: 0.0968177\ttotal: 3.86s\tremaining: 1.02s\n",
      "790:\tlearn: 0.0967717\ttotal: 3.86s\tremaining: 1.02s\n",
      "791:\tlearn: 0.0966960\ttotal: 3.87s\tremaining: 1.01s\n",
      "792:\tlearn: 0.0966171\ttotal: 3.87s\tremaining: 1.01s\n",
      "793:\tlearn: 0.0965519\ttotal: 3.87s\tremaining: 1s\n",
      "794:\tlearn: 0.0964733\ttotal: 3.88s\tremaining: 1000ms\n",
      "795:\tlearn: 0.0964267\ttotal: 3.88s\tremaining: 995ms\n",
      "796:\tlearn: 0.0963525\ttotal: 3.89s\tremaining: 990ms\n",
      "797:\tlearn: 0.0963157\ttotal: 3.89s\tremaining: 985ms\n",
      "798:\tlearn: 0.0962649\ttotal: 3.89s\tremaining: 980ms\n",
      "799:\tlearn: 0.0962133\ttotal: 3.9s\tremaining: 975ms\n",
      "800:\tlearn: 0.0961354\ttotal: 3.9s\tremaining: 970ms\n",
      "801:\tlearn: 0.0960657\ttotal: 3.91s\tremaining: 964ms\n",
      "802:\tlearn: 0.0960048\ttotal: 3.91s\tremaining: 959ms\n",
      "803:\tlearn: 0.0959193\ttotal: 3.92s\tremaining: 955ms\n",
      "804:\tlearn: 0.0958862\ttotal: 3.92s\tremaining: 950ms\n",
      "805:\tlearn: 0.0958181\ttotal: 3.92s\tremaining: 945ms\n",
      "806:\tlearn: 0.0957552\ttotal: 3.93s\tremaining: 940ms\n",
      "807:\tlearn: 0.0957004\ttotal: 3.93s\tremaining: 934ms\n",
      "808:\tlearn: 0.0956312\ttotal: 3.94s\tremaining: 930ms\n",
      "809:\tlearn: 0.0955660\ttotal: 3.94s\tremaining: 924ms\n",
      "810:\tlearn: 0.0955044\ttotal: 3.94s\tremaining: 919ms\n",
      "811:\tlearn: 0.0954212\ttotal: 3.95s\tremaining: 914ms\n",
      "812:\tlearn: 0.0954036\ttotal: 3.95s\tremaining: 909ms\n",
      "813:\tlearn: 0.0953640\ttotal: 3.96s\tremaining: 904ms\n",
      "814:\tlearn: 0.0953183\ttotal: 3.96s\tremaining: 899ms\n",
      "815:\tlearn: 0.0952790\ttotal: 3.96s\tremaining: 894ms\n",
      "816:\tlearn: 0.0952335\ttotal: 3.97s\tremaining: 889ms\n",
      "817:\tlearn: 0.0951891\ttotal: 3.98s\tremaining: 884ms\n",
      "818:\tlearn: 0.0951295\ttotal: 3.98s\tremaining: 879ms\n",
      "819:\tlearn: 0.0950454\ttotal: 3.98s\tremaining: 874ms\n",
      "820:\tlearn: 0.0949561\ttotal: 3.99s\tremaining: 869ms\n",
      "821:\tlearn: 0.0948678\ttotal: 3.99s\tremaining: 864ms\n",
      "822:\tlearn: 0.0947980\ttotal: 4s\tremaining: 859ms\n",
      "823:\tlearn: 0.0947590\ttotal: 4s\tremaining: 854ms\n",
      "824:\tlearn: 0.0946949\ttotal: 4s\tremaining: 849ms\n",
      "825:\tlearn: 0.0946593\ttotal: 4.01s\tremaining: 844ms\n",
      "826:\tlearn: 0.0945982\ttotal: 4.01s\tremaining: 839ms\n",
      "827:\tlearn: 0.0945609\ttotal: 4.01s\tremaining: 834ms\n",
      "828:\tlearn: 0.0945121\ttotal: 4.02s\tremaining: 829ms\n",
      "829:\tlearn: 0.0944427\ttotal: 4.02s\tremaining: 824ms\n",
      "830:\tlearn: 0.0943966\ttotal: 4.03s\tremaining: 819ms\n",
      "831:\tlearn: 0.0943257\ttotal: 4.03s\tremaining: 814ms\n",
      "832:\tlearn: 0.0942948\ttotal: 4.04s\tremaining: 809ms\n",
      "833:\tlearn: 0.0942414\ttotal: 4.04s\tremaining: 804ms\n",
      "834:\tlearn: 0.0941719\ttotal: 4.04s\tremaining: 799ms\n",
      "835:\tlearn: 0.0941312\ttotal: 4.05s\tremaining: 794ms\n",
      "836:\tlearn: 0.0940900\ttotal: 4.05s\tremaining: 789ms\n",
      "837:\tlearn: 0.0940092\ttotal: 4.06s\tremaining: 784ms\n",
      "838:\tlearn: 0.0939589\ttotal: 4.06s\tremaining: 779ms\n",
      "839:\tlearn: 0.0939012\ttotal: 4.06s\tremaining: 774ms\n",
      "840:\tlearn: 0.0938444\ttotal: 4.07s\tremaining: 769ms\n",
      "841:\tlearn: 0.0938005\ttotal: 4.07s\tremaining: 764ms\n",
      "842:\tlearn: 0.0937390\ttotal: 4.08s\tremaining: 759ms\n",
      "843:\tlearn: 0.0936750\ttotal: 4.08s\tremaining: 755ms\n",
      "844:\tlearn: 0.0935986\ttotal: 4.09s\tremaining: 750ms\n",
      "845:\tlearn: 0.0935408\ttotal: 4.09s\tremaining: 745ms\n",
      "846:\tlearn: 0.0934967\ttotal: 4.09s\tremaining: 740ms\n",
      "847:\tlearn: 0.0934510\ttotal: 4.1s\tremaining: 735ms\n",
      "848:\tlearn: 0.0933613\ttotal: 4.1s\tremaining: 730ms\n",
      "849:\tlearn: 0.0932994\ttotal: 4.11s\tremaining: 725ms\n",
      "850:\tlearn: 0.0932582\ttotal: 4.11s\tremaining: 720ms\n",
      "851:\tlearn: 0.0931829\ttotal: 4.12s\tremaining: 715ms\n",
      "852:\tlearn: 0.0931554\ttotal: 4.12s\tremaining: 710ms\n",
      "853:\tlearn: 0.0930759\ttotal: 4.12s\tremaining: 705ms\n",
      "854:\tlearn: 0.0930235\ttotal: 4.13s\tremaining: 700ms\n",
      "855:\tlearn: 0.0929664\ttotal: 4.13s\tremaining: 695ms\n",
      "856:\tlearn: 0.0929010\ttotal: 4.13s\tremaining: 690ms\n",
      "857:\tlearn: 0.0928436\ttotal: 4.14s\tremaining: 685ms\n",
      "858:\tlearn: 0.0927627\ttotal: 4.14s\tremaining: 680ms\n",
      "859:\tlearn: 0.0926936\ttotal: 4.15s\tremaining: 675ms\n",
      "860:\tlearn: 0.0926628\ttotal: 4.15s\tremaining: 670ms\n",
      "861:\tlearn: 0.0925868\ttotal: 4.16s\tremaining: 666ms\n",
      "862:\tlearn: 0.0925422\ttotal: 4.16s\tremaining: 661ms\n",
      "863:\tlearn: 0.0925098\ttotal: 4.17s\tremaining: 656ms\n",
      "864:\tlearn: 0.0924238\ttotal: 4.17s\tremaining: 651ms\n",
      "865:\tlearn: 0.0923588\ttotal: 4.18s\tremaining: 646ms\n",
      "866:\tlearn: 0.0922821\ttotal: 4.18s\tremaining: 641ms\n",
      "867:\tlearn: 0.0922184\ttotal: 4.18s\tremaining: 636ms\n",
      "868:\tlearn: 0.0921467\ttotal: 4.19s\tremaining: 632ms\n",
      "869:\tlearn: 0.0921155\ttotal: 4.19s\tremaining: 627ms\n",
      "870:\tlearn: 0.0920555\ttotal: 4.2s\tremaining: 622ms\n",
      "871:\tlearn: 0.0920174\ttotal: 4.2s\tremaining: 617ms\n",
      "872:\tlearn: 0.0919710\ttotal: 4.21s\tremaining: 612ms\n",
      "873:\tlearn: 0.0918928\ttotal: 4.21s\tremaining: 607ms\n",
      "874:\tlearn: 0.0918587\ttotal: 4.21s\tremaining: 602ms\n",
      "875:\tlearn: 0.0918125\ttotal: 4.22s\tremaining: 597ms\n",
      "876:\tlearn: 0.0917353\ttotal: 4.22s\tremaining: 592ms\n",
      "877:\tlearn: 0.0916908\ttotal: 4.23s\tremaining: 587ms\n",
      "878:\tlearn: 0.0916148\ttotal: 4.23s\tremaining: 582ms\n",
      "879:\tlearn: 0.0915590\ttotal: 4.23s\tremaining: 577ms\n",
      "880:\tlearn: 0.0915084\ttotal: 4.24s\tremaining: 573ms\n",
      "881:\tlearn: 0.0914453\ttotal: 4.24s\tremaining: 568ms\n",
      "882:\tlearn: 0.0913923\ttotal: 4.25s\tremaining: 563ms\n",
      "883:\tlearn: 0.0913710\ttotal: 4.25s\tremaining: 558ms\n",
      "884:\tlearn: 0.0913338\ttotal: 4.25s\tremaining: 553ms\n",
      "885:\tlearn: 0.0912499\ttotal: 4.26s\tremaining: 548ms\n",
      "886:\tlearn: 0.0911782\ttotal: 4.26s\tremaining: 543ms\n",
      "887:\tlearn: 0.0911288\ttotal: 4.27s\tremaining: 538ms\n",
      "888:\tlearn: 0.0910683\ttotal: 4.27s\tremaining: 534ms\n",
      "889:\tlearn: 0.0910418\ttotal: 4.28s\tremaining: 529ms\n",
      "890:\tlearn: 0.0910030\ttotal: 4.28s\tremaining: 524ms\n",
      "891:\tlearn: 0.0909652\ttotal: 4.29s\tremaining: 519ms\n",
      "892:\tlearn: 0.0908888\ttotal: 4.29s\tremaining: 514ms\n",
      "893:\tlearn: 0.0908358\ttotal: 4.29s\tremaining: 509ms\n",
      "894:\tlearn: 0.0907921\ttotal: 4.3s\tremaining: 504ms\n",
      "895:\tlearn: 0.0907110\ttotal: 4.3s\tremaining: 499ms\n",
      "896:\tlearn: 0.0906313\ttotal: 4.31s\tremaining: 495ms\n",
      "897:\tlearn: 0.0905845\ttotal: 4.31s\tremaining: 490ms\n",
      "898:\tlearn: 0.0905122\ttotal: 4.32s\tremaining: 485ms\n",
      "899:\tlearn: 0.0904384\ttotal: 4.32s\tremaining: 480ms\n",
      "900:\tlearn: 0.0903609\ttotal: 4.33s\tremaining: 475ms\n",
      "901:\tlearn: 0.0903361\ttotal: 4.33s\tremaining: 470ms\n",
      "902:\tlearn: 0.0902947\ttotal: 4.33s\tremaining: 465ms\n",
      "903:\tlearn: 0.0902392\ttotal: 4.34s\tremaining: 461ms\n",
      "904:\tlearn: 0.0901950\ttotal: 4.34s\tremaining: 456ms\n",
      "905:\tlearn: 0.0901632\ttotal: 4.35s\tremaining: 451ms\n",
      "906:\tlearn: 0.0901023\ttotal: 4.35s\tremaining: 446ms\n",
      "907:\tlearn: 0.0900329\ttotal: 4.36s\tremaining: 441ms\n",
      "908:\tlearn: 0.0899721\ttotal: 4.36s\tremaining: 436ms\n",
      "909:\tlearn: 0.0899266\ttotal: 4.36s\tremaining: 432ms\n",
      "910:\tlearn: 0.0898540\ttotal: 4.37s\tremaining: 427ms\n",
      "911:\tlearn: 0.0898145\ttotal: 4.37s\tremaining: 422ms\n",
      "912:\tlearn: 0.0897671\ttotal: 4.38s\tremaining: 417ms\n",
      "913:\tlearn: 0.0897145\ttotal: 4.38s\tremaining: 412ms\n",
      "914:\tlearn: 0.0896748\ttotal: 4.39s\tremaining: 408ms\n",
      "915:\tlearn: 0.0895848\ttotal: 4.39s\tremaining: 403ms\n",
      "916:\tlearn: 0.0895303\ttotal: 4.39s\tremaining: 398ms\n",
      "917:\tlearn: 0.0894375\ttotal: 4.4s\tremaining: 393ms\n",
      "918:\tlearn: 0.0893475\ttotal: 4.4s\tremaining: 388ms\n",
      "919:\tlearn: 0.0893100\ttotal: 4.41s\tremaining: 383ms\n",
      "920:\tlearn: 0.0892752\ttotal: 4.41s\tremaining: 379ms\n",
      "921:\tlearn: 0.0892300\ttotal: 4.42s\tremaining: 374ms\n",
      "922:\tlearn: 0.0891981\ttotal: 4.42s\tremaining: 369ms\n",
      "923:\tlearn: 0.0891569\ttotal: 4.42s\tremaining: 364ms\n",
      "924:\tlearn: 0.0891299\ttotal: 4.43s\tremaining: 359ms\n",
      "925:\tlearn: 0.0890954\ttotal: 4.43s\tremaining: 354ms\n",
      "926:\tlearn: 0.0890245\ttotal: 4.44s\tremaining: 349ms\n",
      "927:\tlearn: 0.0889722\ttotal: 4.44s\tremaining: 345ms\n",
      "928:\tlearn: 0.0889196\ttotal: 4.44s\tremaining: 340ms\n",
      "929:\tlearn: 0.0888568\ttotal: 4.45s\tremaining: 335ms\n",
      "930:\tlearn: 0.0888190\ttotal: 4.45s\tremaining: 330ms\n",
      "931:\tlearn: 0.0887532\ttotal: 4.46s\tremaining: 325ms\n",
      "932:\tlearn: 0.0886849\ttotal: 4.46s\tremaining: 320ms\n",
      "933:\tlearn: 0.0886302\ttotal: 4.46s\tremaining: 316ms\n",
      "934:\tlearn: 0.0885684\ttotal: 4.47s\tremaining: 311ms\n",
      "935:\tlearn: 0.0885165\ttotal: 4.47s\tremaining: 306ms\n",
      "936:\tlearn: 0.0884819\ttotal: 4.48s\tremaining: 301ms\n",
      "937:\tlearn: 0.0884086\ttotal: 4.48s\tremaining: 296ms\n",
      "938:\tlearn: 0.0883756\ttotal: 4.49s\tremaining: 291ms\n",
      "939:\tlearn: 0.0882808\ttotal: 4.49s\tremaining: 287ms\n",
      "940:\tlearn: 0.0882399\ttotal: 4.5s\tremaining: 282ms\n",
      "941:\tlearn: 0.0881487\ttotal: 4.5s\tremaining: 277ms\n",
      "942:\tlearn: 0.0880874\ttotal: 4.5s\tremaining: 272ms\n",
      "943:\tlearn: 0.0879743\ttotal: 4.51s\tremaining: 267ms\n",
      "944:\tlearn: 0.0879369\ttotal: 4.51s\tremaining: 263ms\n",
      "945:\tlearn: 0.0878902\ttotal: 4.51s\tremaining: 258ms\n",
      "946:\tlearn: 0.0878195\ttotal: 4.52s\tremaining: 253ms\n",
      "947:\tlearn: 0.0877608\ttotal: 4.52s\tremaining: 248ms\n",
      "948:\tlearn: 0.0877538\ttotal: 4.53s\tremaining: 243ms\n",
      "949:\tlearn: 0.0877115\ttotal: 4.53s\tremaining: 239ms\n",
      "950:\tlearn: 0.0876938\ttotal: 4.54s\tremaining: 234ms\n",
      "951:\tlearn: 0.0876423\ttotal: 4.54s\tremaining: 229ms\n",
      "952:\tlearn: 0.0875906\ttotal: 4.54s\tremaining: 224ms\n",
      "953:\tlearn: 0.0875522\ttotal: 4.55s\tremaining: 219ms\n",
      "954:\tlearn: 0.0875369\ttotal: 4.55s\tremaining: 215ms\n",
      "955:\tlearn: 0.0874866\ttotal: 4.56s\tremaining: 210ms\n",
      "956:\tlearn: 0.0874356\ttotal: 4.56s\tremaining: 205ms\n",
      "957:\tlearn: 0.0873936\ttotal: 4.57s\tremaining: 200ms\n",
      "958:\tlearn: 0.0873200\ttotal: 4.57s\tremaining: 195ms\n",
      "959:\tlearn: 0.0872561\ttotal: 4.57s\tremaining: 191ms\n",
      "960:\tlearn: 0.0871870\ttotal: 4.58s\tremaining: 186ms\n",
      "961:\tlearn: 0.0871189\ttotal: 4.58s\tremaining: 181ms\n",
      "962:\tlearn: 0.0870877\ttotal: 4.59s\tremaining: 176ms\n",
      "963:\tlearn: 0.0870446\ttotal: 4.59s\tremaining: 171ms\n",
      "964:\tlearn: 0.0870077\ttotal: 4.59s\tremaining: 167ms\n",
      "965:\tlearn: 0.0869393\ttotal: 4.6s\tremaining: 162ms\n",
      "966:\tlearn: 0.0869024\ttotal: 4.6s\tremaining: 157ms\n",
      "967:\tlearn: 0.0868283\ttotal: 4.61s\tremaining: 152ms\n",
      "968:\tlearn: 0.0867857\ttotal: 4.61s\tremaining: 148ms\n",
      "969:\tlearn: 0.0867349\ttotal: 4.62s\tremaining: 143ms\n",
      "970:\tlearn: 0.0866902\ttotal: 4.62s\tremaining: 138ms\n",
      "971:\tlearn: 0.0866310\ttotal: 4.62s\tremaining: 133ms\n",
      "972:\tlearn: 0.0865612\ttotal: 4.63s\tremaining: 128ms\n",
      "973:\tlearn: 0.0865036\ttotal: 4.63s\tremaining: 124ms\n",
      "974:\tlearn: 0.0864354\ttotal: 4.64s\tremaining: 119ms\n",
      "975:\tlearn: 0.0863854\ttotal: 4.64s\tremaining: 114ms\n",
      "976:\tlearn: 0.0863660\ttotal: 4.64s\tremaining: 109ms\n",
      "977:\tlearn: 0.0863172\ttotal: 4.65s\tremaining: 105ms\n",
      "978:\tlearn: 0.0862589\ttotal: 4.65s\tremaining: 99.8ms\n",
      "979:\tlearn: 0.0862198\ttotal: 4.66s\tremaining: 95ms\n",
      "980:\tlearn: 0.0861840\ttotal: 4.66s\tremaining: 90.3ms\n",
      "981:\tlearn: 0.0861142\ttotal: 4.67s\tremaining: 85.5ms\n",
      "982:\tlearn: 0.0860788\ttotal: 4.67s\tremaining: 80.8ms\n",
      "983:\tlearn: 0.0860007\ttotal: 4.67s\tremaining: 76ms\n",
      "984:\tlearn: 0.0859331\ttotal: 4.68s\tremaining: 71.3ms\n",
      "985:\tlearn: 0.0858908\ttotal: 4.68s\tremaining: 66.5ms\n",
      "986:\tlearn: 0.0858492\ttotal: 4.69s\tremaining: 61.7ms\n",
      "987:\tlearn: 0.0858004\ttotal: 4.69s\tremaining: 57ms\n",
      "988:\tlearn: 0.0857471\ttotal: 4.7s\tremaining: 52.2ms\n",
      "989:\tlearn: 0.0856875\ttotal: 4.7s\tremaining: 47.5ms\n",
      "990:\tlearn: 0.0856202\ttotal: 4.7s\tremaining: 42.7ms\n",
      "991:\tlearn: 0.0855729\ttotal: 4.71s\tremaining: 38ms\n",
      "992:\tlearn: 0.0855336\ttotal: 4.71s\tremaining: 33.2ms\n",
      "993:\tlearn: 0.0854978\ttotal: 4.72s\tremaining: 28.5ms\n",
      "994:\tlearn: 0.0854374\ttotal: 4.72s\tremaining: 23.7ms\n",
      "995:\tlearn: 0.0853665\ttotal: 4.72s\tremaining: 19ms\n",
      "996:\tlearn: 0.0853301\ttotal: 4.73s\tremaining: 14.2ms\n",
      "997:\tlearn: 0.0852911\ttotal: 4.73s\tremaining: 9.49ms\n",
      "998:\tlearn: 0.0852646\ttotal: 4.74s\tremaining: 4.74ms\n",
      "999:\tlearn: 0.0851950\ttotal: 4.74s\tremaining: 0us\n",
      "Accuracy CatBoost: 0.9501450326323423\n",
      "Confusion Matrix:\n",
      "[[2556  202]\n",
      " [  73 2685]]\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cb = CatBoostClassifier()\n",
    "cb.fit(X_train_dummy, y_train_dummy['final_result'])\n",
    "\n",
    "y_pred = cb.predict(X_test_dummy)\n",
    "acc = accuracy_score(y_test_dummy['final_result'], y_pred)\n",
    "print('Accuracy CatBoost:', acc)\n",
    "cm = confusion_matrix(y_test_dummy['final_result'], y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 100\n",
      "Completed iteration 1\n",
      "Completed iteration 2\n",
      "Completed iteration 3\n",
      "Completed iteration 4\n",
      "Completed iteration 5\n",
      "Completed iteration 6\n",
      "Completed iteration 7\n",
      "Completed iteration 8\n",
      "Completed iteration 9\n",
      "Completed iteration 10\n",
      "Completed iteration 11\n",
      "Completed iteration 12\n",
      "Completed iteration 13\n",
      "Completed iteration 14\n",
      "Completed iteration 15\n",
      "Completed iteration 16\n",
      "Completed iteration 17\n",
      "Completed iteration 18\n",
      "Completed iteration 19\n",
      "Completed iteration 20\n",
      "Completed iteration 21\n",
      "Completed iteration 22\n",
      "Completed iteration 23\n",
      "Completed iteration 24\n",
      "Completed iteration 25\n",
      "Completed iteration 26\n",
      "Completed iteration 27\n",
      "Completed iteration 28\n",
      "Completed iteration 29\n",
      "Completed iteration 30\n",
      "Completed iteration 31\n",
      "Completed iteration 32\n",
      "Completed iteration 33\n",
      "Completed iteration 34\n",
      "Completed iteration 35\n",
      "Completed iteration 36\n",
      "Completed iteration 37\n",
      "Completed iteration 38\n",
      "Completed iteration 42\n",
      "Completed iteration 44\n",
      "Completed iteration 45\n",
      "Completed iteration 46\n",
      "Completed iteration 47\n",
      "Completed iteration 48\n",
      "Completed iteration 49\n",
      "Completed iteration 50\n",
      "Completed iteration 51\n",
      "Completed iteration 52\n",
      "Completed iteration 53\n",
      "Completed iteration 54\n",
      "Completed iteration 55\n",
      "Completed iteration 56\n",
      "Completed iteration 57\n",
      "Completed iteration 58\n",
      "Completed iteration 59\n",
      "Completed iteration 60\n",
      "Completed iteration 61\n",
      "Completed iteration 62\n",
      "Completed iteration 63\n",
      "Completed iteration 64\n",
      "Completed iteration 65\n",
      "Completed iteration 66\n",
      "Completed iteration 67\n",
      "Completed iteration 68\n",
      "Completed iteration 69\n",
      "Completed iteration 70\n",
      "Completed iteration 71\n",
      "Completed iteration 72\n",
      "Completed iteration 73\n",
      "Completed iteration 74\n",
      "Completed iteration 75\n",
      "Completed iteration 76\n",
      "Completed iteration 77\n",
      "Completed iteration 78\n",
      "Completed iteration 79\n",
      "Completed iteration 80\n",
      "Completed iteration 81\n",
      "Completed iteration 82\n",
      "Completed iteration 83\n",
      "Completed iteration 84\n",
      "Completed iteration 85\n",
      "Completed iteration 86\n",
      "Completed iteration 87\n",
      "Completed iteration 88\n",
      "Completed iteration 89\n",
      "Completed iteration 90\n",
      "Completed iteration 91\n",
      "Completed iteration 92\n",
      "Completed iteration 93\n",
      "Completed iteration 94\n",
      "Completed iteration 95\n",
      "Completed iteration 96\n",
      "Completed iteration 97\n",
      "Completed iteration 98\n",
      "Completed iteration 99\n",
      "Completed iteration 100\n",
      "Completed iteration 101\n",
      "Completed iteration 102\n",
      "Completed iteration 103\n",
      "Completed iteration 104\n",
      "Completed iteration 105\n",
      "Completed iteration 106\n",
      "Completed iteration 107\n",
      "Completed iteration 108\n",
      "Completed iteration 109\n",
      "Completed iteration 110\n",
      "Completed iteration 111\n",
      "Completed iteration 112\n",
      "Completed iteration 113\n",
      "Completed iteration 114\n",
      "Completed iteration 115\n",
      "Completed iteration 116\n",
      "Completed iteration 117\n",
      "Completed iteration 118\n",
      "Completed iteration 119\n",
      "Completed iteration 120\n",
      "Completed iteration 121\n",
      "Completed iteration 122\n",
      "Completed iteration 123\n",
      "Completed iteration 124\n",
      "Completed iteration 125\n",
      "Completed iteration 126\n",
      "Completed iteration 127\n",
      "Completed iteration 128\n",
      "Completed iteration 129\n",
      "Completed iteration 130\n",
      "Completed iteration 131\n",
      "Completed iteration 132\n",
      "Completed iteration 133\n",
      "Completed iteration 134\n",
      "Completed iteration 135\n",
      "Completed iteration 136\n",
      "Completed iteration 137\n",
      "Completed iteration 138\n",
      "Completed iteration 139\n",
      "Completed iteration 140\n",
      "Completed iteration 141\n",
      "Completed iteration 142\n",
      "Completed iteration 143\n",
      "Completed iteration 144\n",
      "Completed iteration 145\n",
      "Completed iteration 146\n",
      "Completed iteration 147\n",
      "Completed iteration 148\n",
      "Completed iteration 149\n",
      "Completed iteration 150\n",
      "Best parameters: OrderedDict([('bagging_temperature', 1.0), ('border_count', 86), ('depth', 16), ('iterations', 868), ('l2_leaf_reg', 2), ('learning_rate', 0.06598200301644333), ('random_strength', 10.0), ('scale_pos_weight', 0.8384915263866678)])\n",
      "Best score: 0.945071830392019\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from skopt import BayesSearchCV\n",
    "\n",
    "counter = [0]\n",
    "\n",
    "def on_step(optim_result):\n",
    "    # Increment the counter\n",
    "    counter[0] += 1\n",
    "    print(f\"Completed iteration {counter[0]}\")\n",
    "    \n",
    "cb = CatBoostClassifier(verbose=False)\n",
    "\n",
    "# Define search spaces\n",
    "param_space = {\n",
    "    'iterations': (50, 1000),\n",
    "    'depth': (1, 16),\n",
    "    'learning_rate': (0.01, 1.0, 'log-uniform'),\n",
    "    'random_strength': (1e-9, 10, 'log-uniform'),\n",
    "    'bagging_temperature': (0.0, 1.0),\n",
    "    'border_count': (1, 255),\n",
    "    'l2_leaf_reg': (2, 30),\n",
    "    'scale_pos_weight':(0.01, 1.0, 'uniform')\n",
    "}\n",
    "\n",
    "# Initialize BayesSearchCV\n",
    "opt_cb = BayesSearchCV(\n",
    "    estimator=cb,\n",
    "    search_spaces=param_space,\n",
    "    scoring='accuracy',\n",
    "    n_iter=150,\n",
    "    n_jobs=-1,\n",
    "    return_train_score=False,\n",
    "    refit=True,\n",
    "    optimizer_kwargs={'base_estimator': 'GP'},\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "opt_cb.fit(X_train_dummy, y_train_dummy['final_result'], callback=on_step)\n",
    "\n",
    "# Print best parameters and score\n",
    "print(f'Best parameters: {opt_cb.best_params_}')\n",
    "print(f'Best score: {opt_cb.best_score_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6198528\ttotal: 2.95s\tremaining: 49m 3s\n",
      "1:\tlearn: 0.5658979\ttotal: 4.84s\tremaining: 40m 16s\n",
      "2:\tlearn: 0.5310979\ttotal: 4.91s\tremaining: 27m 11s\n",
      "3:\tlearn: 0.4920655\ttotal: 6.76s\tremaining: 28m 2s\n",
      "4:\tlearn: 0.4590550\ttotal: 8.65s\tremaining: 28m 41s\n",
      "5:\tlearn: 0.4320212\ttotal: 10.5s\tremaining: 28m 52s\n",
      "6:\tlearn: 0.4027444\ttotal: 12.2s\tremaining: 28m 52s\n",
      "7:\tlearn: 0.3992206\ttotal: 12.2s\tremaining: 25m 15s\n",
      "8:\tlearn: 0.3811747\ttotal: 14.7s\tremaining: 26m 53s\n",
      "9:\tlearn: 0.3666077\ttotal: 17.7s\tremaining: 29m 9s\n",
      "10:\tlearn: 0.3483203\ttotal: 19.7s\tremaining: 29m 29s\n",
      "11:\tlearn: 0.3355512\ttotal: 22.7s\tremaining: 31m 11s\n",
      "12:\tlearn: 0.3222862\ttotal: 25.4s\tremaining: 32m 10s\n",
      "13:\tlearn: 0.3098346\ttotal: 28.1s\tremaining: 33m 1s\n",
      "14:\tlearn: 0.2951219\ttotal: 30.8s\tremaining: 33m 41s\n",
      "15:\tlearn: 0.2887105\ttotal: 32.2s\tremaining: 32m 59s\n",
      "16:\tlearn: 0.2778510\ttotal: 34.4s\tremaining: 33m 10s\n",
      "17:\tlearn: 0.2691599\ttotal: 36.3s\tremaining: 33m\n",
      "18:\tlearn: 0.2628512\ttotal: 38s\tremaining: 32m 44s\n",
      "19:\tlearn: 0.2619781\ttotal: 38s\tremaining: 31m 4s\n",
      "20:\tlearn: 0.2535345\ttotal: 39.7s\tremaining: 30m 52s\n",
      "21:\tlearn: 0.2455156\ttotal: 41.8s\tremaining: 30m 56s\n",
      "22:\tlearn: 0.2357499\ttotal: 43.6s\tremaining: 30m 50s\n",
      "23:\tlearn: 0.2302021\ttotal: 44.1s\tremaining: 29m 53s\n",
      "24:\tlearn: 0.2223698\ttotal: 45.8s\tremaining: 29m 48s\n",
      "25:\tlearn: 0.2152088\ttotal: 47.7s\tremaining: 29m 47s\n",
      "26:\tlearn: 0.2123292\ttotal: 49.6s\tremaining: 29m 46s\n",
      "27:\tlearn: 0.2074274\ttotal: 51.4s\tremaining: 29m 44s\n",
      "28:\tlearn: 0.2038539\ttotal: 53.3s\tremaining: 29m 44s\n",
      "29:\tlearn: 0.1994206\ttotal: 53.3s\tremaining: 28m 44s\n",
      "30:\tlearn: 0.1957686\ttotal: 53.4s\tremaining: 27m 48s\n",
      "31:\tlearn: 0.1946291\ttotal: 53.4s\tremaining: 26m 55s\n",
      "32:\tlearn: 0.1917134\ttotal: 54.1s\tremaining: 26m 25s\n",
      "33:\tlearn: 0.1871063\ttotal: 56.3s\tremaining: 26m 39s\n",
      "34:\tlearn: 0.1829500\ttotal: 59.2s\tremaining: 27m 10s\n",
      "35:\tlearn: 0.1795514\ttotal: 1m 1s\tremaining: 27m 36s\n",
      "36:\tlearn: 0.1760531\ttotal: 1m 4s\tremaining: 28m 3s\n",
      "37:\tlearn: 0.1735932\ttotal: 1m 7s\tremaining: 28m 21s\n",
      "38:\tlearn: 0.1715830\ttotal: 1m 9s\tremaining: 28m 31s\n",
      "39:\tlearn: 0.1676611\ttotal: 1m 12s\tremaining: 28m 48s\n",
      "40:\tlearn: 0.1667004\ttotal: 1m 12s\tremaining: 28m 6s\n",
      "41:\tlearn: 0.1645346\ttotal: 1m 14s\tremaining: 28m 14s\n",
      "42:\tlearn: 0.1604934\ttotal: 1m 16s\tremaining: 28m 30s\n",
      "43:\tlearn: 0.1580634\ttotal: 1m 19s\tremaining: 28m 44s\n",
      "44:\tlearn: 0.1577131\ttotal: 1m 19s\tremaining: 28m 4s\n",
      "45:\tlearn: 0.1575429\ttotal: 1m 19s\tremaining: 27m 26s\n",
      "46:\tlearn: 0.1551872\ttotal: 1m 21s\tremaining: 27m 34s\n",
      "47:\tlearn: 0.1520169\ttotal: 1m 23s\tremaining: 27m 41s\n",
      "48:\tlearn: 0.1508382\ttotal: 1m 23s\tremaining: 27m 5s\n",
      "49:\tlearn: 0.1480878\ttotal: 1m 25s\tremaining: 27m 8s\n",
      "50:\tlearn: 0.1474147\ttotal: 1m 25s\tremaining: 26m 35s\n",
      "51:\tlearn: 0.1452504\ttotal: 1m 27s\tremaining: 26m 37s\n",
      "52:\tlearn: 0.1422215\ttotal: 1m 29s\tremaining: 26m 36s\n",
      "53:\tlearn: 0.1414307\ttotal: 1m 29s\tremaining: 26m 5s\n",
      "54:\tlearn: 0.1411379\ttotal: 1m 29s\tremaining: 25m 36s\n",
      "55:\tlearn: 0.1389322\ttotal: 1m 31s\tremaining: 25m 39s\n",
      "56:\tlearn: 0.1384105\ttotal: 1m 31s\tremaining: 25m 12s\n",
      "57:\tlearn: 0.1371976\ttotal: 1m 32s\tremaining: 25m 4s\n",
      "58:\tlearn: 0.1347886\ttotal: 1m 35s\tremaining: 25m 17s\n",
      "59:\tlearn: 0.1330866\ttotal: 1m 37s\tremaining: 25m 26s\n",
      "60:\tlearn: 0.1327532\ttotal: 1m 37s\tremaining: 25m\n",
      "61:\tlearn: 0.1307944\ttotal: 1m 39s\tremaining: 25m 2s\n",
      "62:\tlearn: 0.1298650\ttotal: 1m 41s\tremaining: 25m 2s\n",
      "63:\tlearn: 0.1282669\ttotal: 1m 42s\tremaining: 25m 4s\n",
      "64:\tlearn: 0.1268777\ttotal: 1m 45s\tremaining: 25m 16s\n",
      "65:\tlearn: 0.1255907\ttotal: 1m 47s\tremaining: 25m 24s\n",
      "66:\tlearn: 0.1235810\ttotal: 1m 49s\tremaining: 25m 31s\n",
      "67:\tlearn: 0.1217927\ttotal: 1m 52s\tremaining: 25m 40s\n",
      "68:\tlearn: 0.1197965\ttotal: 1m 54s\tremaining: 25m 44s\n",
      "69:\tlearn: 0.1181454\ttotal: 1m 56s\tremaining: 25m 49s\n",
      "70:\tlearn: 0.1167197\ttotal: 1m 59s\tremaining: 25m 57s\n",
      "71:\tlearn: 0.1166603\ttotal: 1m 59s\tremaining: 25m 34s\n",
      "72:\tlearn: 0.1166012\ttotal: 1m 59s\tremaining: 25m 11s\n",
      "73:\tlearn: 0.1162938\ttotal: 1m 59s\tremaining: 24m 50s\n",
      "74:\tlearn: 0.1147458\ttotal: 2m 1s\tremaining: 24m 59s\n",
      "75:\tlearn: 0.1147044\ttotal: 2m 1s\tremaining: 24m 38s\n",
      "76:\tlearn: 0.1127152\ttotal: 2m 3s\tremaining: 24m 42s\n",
      "77:\tlearn: 0.1126303\ttotal: 2m 3s\tremaining: 24m 21s\n",
      "78:\tlearn: 0.1124366\ttotal: 2m 3s\tremaining: 24m 1s\n",
      "79:\tlearn: 0.1116555\ttotal: 2m 5s\tremaining: 24m 8s\n",
      "80:\tlearn: 0.1102638\ttotal: 2m 8s\tremaining: 24m 13s\n",
      "81:\tlearn: 0.1090489\ttotal: 2m 10s\tremaining: 24m 17s\n",
      "82:\tlearn: 0.1075613\ttotal: 2m 12s\tremaining: 24m 24s\n",
      "83:\tlearn: 0.1066566\ttotal: 2m 14s\tremaining: 24m 29s\n",
      "84:\tlearn: 0.1047424\ttotal: 2m 16s\tremaining: 24m 32s\n",
      "85:\tlearn: 0.1026084\ttotal: 2m 18s\tremaining: 24m 32s\n",
      "86:\tlearn: 0.1017943\ttotal: 2m 20s\tremaining: 24m 31s\n",
      "87:\tlearn: 0.1008065\ttotal: 2m 22s\tremaining: 24m 34s\n",
      "88:\tlearn: 0.0993846\ttotal: 2m 24s\tremaining: 24m 34s\n",
      "89:\tlearn: 0.0977742\ttotal: 2m 25s\tremaining: 24m 33s\n",
      "90:\tlearn: 0.0969319\ttotal: 2m 27s\tremaining: 24m 36s\n",
      "91:\tlearn: 0.0966420\ttotal: 2m 27s\tremaining: 24m 19s\n",
      "92:\tlearn: 0.0958038\ttotal: 2m 30s\tremaining: 24m 26s\n",
      "93:\tlearn: 0.0946355\ttotal: 2m 32s\tremaining: 24m 28s\n",
      "94:\tlearn: 0.0935638\ttotal: 2m 34s\tremaining: 24m 30s\n",
      "95:\tlearn: 0.0913752\ttotal: 2m 36s\tremaining: 24m 31s\n",
      "96:\tlearn: 0.0904921\ttotal: 2m 38s\tremaining: 24m 31s\n",
      "97:\tlearn: 0.0898512\ttotal: 2m 39s\tremaining: 24m 30s\n",
      "98:\tlearn: 0.0889153\ttotal: 2m 41s\tremaining: 24m 29s\n",
      "99:\tlearn: 0.0883841\ttotal: 2m 42s\tremaining: 24m 24s\n",
      "100:\tlearn: 0.0878311\ttotal: 2m 42s\tremaining: 24m 8s\n",
      "101:\tlearn: 0.0865967\ttotal: 2m 45s\tremaining: 24m 13s\n",
      "102:\tlearn: 0.0856922\ttotal: 2m 47s\tremaining: 24m 17s\n",
      "103:\tlearn: 0.0848097\ttotal: 2m 49s\tremaining: 24m 20s\n",
      "104:\tlearn: 0.0831616\ttotal: 2m 51s\tremaining: 24m 19s\n",
      "105:\tlearn: 0.0820961\ttotal: 2m 53s\tremaining: 24m 19s\n",
      "106:\tlearn: 0.0812290\ttotal: 2m 54s\tremaining: 24m 18s\n",
      "107:\tlearn: 0.0801488\ttotal: 2m 56s\tremaining: 24m 16s\n",
      "108:\tlearn: 0.0793363\ttotal: 2m 57s\tremaining: 24m 14s\n",
      "109:\tlearn: 0.0792108\ttotal: 2m 57s\tremaining: 23m 59s\n",
      "110:\tlearn: 0.0791430\ttotal: 2m 57s\tremaining: 23m 45s\n",
      "111:\tlearn: 0.0788165\ttotal: 2m 59s\tremaining: 23m 44s\n",
      "112:\tlearn: 0.0786479\ttotal: 2m 59s\tremaining: 23m 30s\n",
      "113:\tlearn: 0.0779424\ttotal: 3m 1s\tremaining: 23m 28s\n",
      "114:\tlearn: 0.0772054\ttotal: 3m 2s\tremaining: 23m 27s\n",
      "115:\tlearn: 0.0764409\ttotal: 3m 4s\tremaining: 23m 26s\n",
      "116:\tlearn: 0.0754672\ttotal: 3m 6s\tremaining: 23m 25s\n",
      "117:\tlearn: 0.0749818\ttotal: 3m 8s\tremaining: 23m 26s\n",
      "118:\tlearn: 0.0740892\ttotal: 3m 10s\tremaining: 23m 27s\n",
      "119:\tlearn: 0.0735826\ttotal: 3m 11s\tremaining: 23m 26s\n",
      "120:\tlearn: 0.0735628\ttotal: 3m 11s\tremaining: 23m 13s\n",
      "121:\tlearn: 0.0728008\ttotal: 3m 13s\tremaining: 23m 12s\n",
      "122:\tlearn: 0.0724300\ttotal: 3m 13s\tremaining: 22m 59s\n",
      "123:\tlearn: 0.0714353\ttotal: 3m 15s\tremaining: 23m\n",
      "124:\tlearn: 0.0703959\ttotal: 3m 17s\tremaining: 23m 1s\n",
      "125:\tlearn: 0.0699849\ttotal: 3m 17s\tremaining: 22m 52s\n",
      "126:\tlearn: 0.0699579\ttotal: 3m 17s\tremaining: 22m 39s\n",
      "127:\tlearn: 0.0693540\ttotal: 3m 19s\tremaining: 22m 37s\n",
      "128:\tlearn: 0.0687270\ttotal: 3m 20s\tremaining: 22m 36s\n",
      "129:\tlearn: 0.0680651\ttotal: 3m 22s\tremaining: 22m 34s\n",
      "130:\tlearn: 0.0669677\ttotal: 3m 24s\tremaining: 22m 33s\n",
      "131:\tlearn: 0.0660437\ttotal: 3m 25s\tremaining: 22m 32s\n",
      "132:\tlearn: 0.0651903\ttotal: 3m 27s\tremaining: 22m 30s\n",
      "133:\tlearn: 0.0645101\ttotal: 3m 28s\tremaining: 22m 29s\n",
      "134:\tlearn: 0.0641006\ttotal: 3m 30s\tremaining: 22m 29s\n",
      "135:\tlearn: 0.0634106\ttotal: 3m 32s\tremaining: 22m 28s\n",
      "136:\tlearn: 0.0631336\ttotal: 3m 32s\tremaining: 22m 18s\n",
      "137:\tlearn: 0.0625099\ttotal: 3m 34s\tremaining: 22m 18s\n",
      "138:\tlearn: 0.0618882\ttotal: 3m 36s\tremaining: 22m 18s\n",
      "139:\tlearn: 0.0614834\ttotal: 3m 37s\tremaining: 22m 17s\n",
      "140:\tlearn: 0.0608835\ttotal: 3m 38s\tremaining: 22m 13s\n",
      "141:\tlearn: 0.0604800\ttotal: 3m 40s\tremaining: 22m 12s\n",
      "142:\tlearn: 0.0602112\ttotal: 3m 42s\tremaining: 22m 11s\n",
      "143:\tlearn: 0.0600238\ttotal: 3m 42s\tremaining: 22m 1s\n",
      "144:\tlearn: 0.0599724\ttotal: 3m 42s\tremaining: 21m 50s\n",
      "145:\tlearn: 0.0599381\ttotal: 3m 42s\tremaining: 21m 39s\n",
      "146:\tlearn: 0.0593440\ttotal: 3m 43s\tremaining: 21m 38s\n",
      "147:\tlearn: 0.0592728\ttotal: 3m 43s\tremaining: 21m 28s\n",
      "148:\tlearn: 0.0589535\ttotal: 3m 45s\tremaining: 21m 27s\n",
      "149:\tlearn: 0.0582615\ttotal: 3m 47s\tremaining: 21m 26s\n",
      "150:\tlearn: 0.0574893\ttotal: 3m 48s\tremaining: 21m 26s\n",
      "151:\tlearn: 0.0564410\ttotal: 3m 50s\tremaining: 21m 25s\n",
      "152:\tlearn: 0.0558353\ttotal: 3m 52s\tremaining: 21m 24s\n",
      "153:\tlearn: 0.0552929\ttotal: 3m 52s\tremaining: 21m 16s\n",
      "154:\tlearn: 0.0552928\ttotal: 3m 52s\tremaining: 21m 6s\n",
      "155:\tlearn: 0.0545958\ttotal: 3m 54s\tremaining: 21m 7s\n",
      "156:\tlearn: 0.0541437\ttotal: 3m 56s\tremaining: 21m 7s\n",
      "157:\tlearn: 0.0536113\ttotal: 3m 57s\tremaining: 21m 6s\n",
      "158:\tlearn: 0.0531016\ttotal: 3m 59s\tremaining: 21m 5s\n",
      "159:\tlearn: 0.0525859\ttotal: 4m\tremaining: 21m 5s\n",
      "160:\tlearn: 0.0516808\ttotal: 4m 2s\tremaining: 21m 4s\n",
      "161:\tlearn: 0.0510161\ttotal: 4m 4s\tremaining: 21m 3s\n",
      "162:\tlearn: 0.0502902\ttotal: 4m 5s\tremaining: 21m 2s\n",
      "163:\tlearn: 0.0497583\ttotal: 4m 7s\tremaining: 21m 1s\n",
      "164:\tlearn: 0.0491571\ttotal: 4m 8s\tremaining: 21m\n",
      "165:\tlearn: 0.0483775\ttotal: 4m 10s\tremaining: 20m 58s\n",
      "166:\tlearn: 0.0475093\ttotal: 4m 12s\tremaining: 20m 58s\n",
      "167:\tlearn: 0.0468525\ttotal: 4m 14s\tremaining: 20m 58s\n",
      "168:\tlearn: 0.0459435\ttotal: 4m 15s\tremaining: 20m 58s\n",
      "169:\tlearn: 0.0454190\ttotal: 4m 17s\tremaining: 20m 57s\n",
      "170:\tlearn: 0.0447220\ttotal: 4m 19s\tremaining: 20m 56s\n",
      "171:\tlearn: 0.0439565\ttotal: 4m 20s\tremaining: 20m 55s\n",
      "172:\tlearn: 0.0433515\ttotal: 4m 22s\tremaining: 20m 54s\n",
      "173:\tlearn: 0.0427098\ttotal: 4m 24s\tremaining: 20m 53s\n",
      "174:\tlearn: 0.0418793\ttotal: 4m 25s\tremaining: 20m 52s\n",
      "175:\tlearn: 0.0413554\ttotal: 4m 27s\tremaining: 20m 51s\n",
      "176:\tlearn: 0.0406601\ttotal: 4m 28s\tremaining: 20m 49s\n",
      "177:\tlearn: 0.0398884\ttotal: 4m 30s\tremaining: 20m 48s\n",
      "178:\tlearn: 0.0393103\ttotal: 4m 32s\tremaining: 20m 50s\n",
      "179:\tlearn: 0.0386458\ttotal: 4m 34s\tremaining: 20m 49s\n",
      "180:\tlearn: 0.0380672\ttotal: 4m 36s\tremaining: 20m 49s\n",
      "181:\tlearn: 0.0375945\ttotal: 4m 37s\tremaining: 20m 48s\n",
      "182:\tlearn: 0.0369094\ttotal: 4m 39s\tremaining: 20m 48s\n",
      "183:\tlearn: 0.0362960\ttotal: 4m 41s\tremaining: 20m 48s\n",
      "184:\tlearn: 0.0357419\ttotal: 4m 43s\tremaining: 20m 47s\n",
      "185:\tlearn: 0.0352346\ttotal: 4m 45s\tremaining: 20m 48s\n",
      "186:\tlearn: 0.0347439\ttotal: 4m 47s\tremaining: 20m 47s\n",
      "187:\tlearn: 0.0343728\ttotal: 4m 49s\tremaining: 20m 50s\n",
      "188:\tlearn: 0.0337608\ttotal: 4m 51s\tremaining: 20m 51s\n",
      "189:\tlearn: 0.0332906\ttotal: 4m 53s\tremaining: 20m 50s\n",
      "190:\tlearn: 0.0328481\ttotal: 4m 55s\tremaining: 20m 50s\n",
      "191:\tlearn: 0.0323768\ttotal: 4m 57s\tremaining: 20m 51s\n",
      "192:\tlearn: 0.0318817\ttotal: 4m 59s\tremaining: 20m 51s\n",
      "193:\tlearn: 0.0314530\ttotal: 5m 1s\tremaining: 20m 51s\n",
      "194:\tlearn: 0.0310685\ttotal: 5m 2s\tremaining: 20m 50s\n",
      "195:\tlearn: 0.0306384\ttotal: 5m 5s\tremaining: 20m 51s\n",
      "196:\tlearn: 0.0299590\ttotal: 5m 7s\tremaining: 20m 52s\n",
      "197:\tlearn: 0.0294887\ttotal: 5m 9s\tremaining: 20m 53s\n",
      "198:\tlearn: 0.0291629\ttotal: 5m 11s\tremaining: 20m 53s\n",
      "199:\tlearn: 0.0287699\ttotal: 5m 13s\tremaining: 20m 52s\n",
      "200:\tlearn: 0.0283556\ttotal: 5m 14s\tremaining: 20m 50s\n",
      "201:\tlearn: 0.0277928\ttotal: 5m 16s\tremaining: 20m 51s\n",
      "202:\tlearn: 0.0272850\ttotal: 5m 18s\tremaining: 20m 50s\n",
      "203:\tlearn: 0.0270242\ttotal: 5m 20s\tremaining: 20m 49s\n",
      "204:\tlearn: 0.0264974\ttotal: 5m 21s\tremaining: 20m 48s\n",
      "205:\tlearn: 0.0261871\ttotal: 5m 23s\tremaining: 20m 48s\n",
      "206:\tlearn: 0.0259461\ttotal: 5m 25s\tremaining: 20m 47s\n",
      "207:\tlearn: 0.0257045\ttotal: 5m 27s\tremaining: 20m 46s\n",
      "208:\tlearn: 0.0254956\ttotal: 5m 29s\tremaining: 20m 46s\n",
      "209:\tlearn: 0.0251497\ttotal: 5m 31s\tremaining: 20m 47s\n",
      "210:\tlearn: 0.0248483\ttotal: 5m 33s\tremaining: 20m 47s\n",
      "211:\tlearn: 0.0245301\ttotal: 5m 35s\tremaining: 20m 47s\n",
      "212:\tlearn: 0.0242976\ttotal: 5m 37s\tremaining: 20m 46s\n",
      "213:\tlearn: 0.0240983\ttotal: 5m 39s\tremaining: 20m 45s\n",
      "214:\tlearn: 0.0238637\ttotal: 5m 40s\tremaining: 20m 43s\n",
      "215:\tlearn: 0.0236113\ttotal: 5m 42s\tremaining: 20m 43s\n",
      "216:\tlearn: 0.0232722\ttotal: 5m 44s\tremaining: 20m 42s\n",
      "217:\tlearn: 0.0231220\ttotal: 5m 45s\tremaining: 20m 40s\n",
      "218:\tlearn: 0.0227968\ttotal: 5m 47s\tremaining: 20m 39s\n",
      "219:\tlearn: 0.0224958\ttotal: 5m 49s\tremaining: 20m 38s\n",
      "220:\tlearn: 0.0223022\ttotal: 5m 51s\tremaining: 20m 37s\n",
      "221:\tlearn: 0.0221523\ttotal: 5m 53s\tremaining: 20m 38s\n",
      "222:\tlearn: 0.0217872\ttotal: 5m 55s\tremaining: 20m 38s\n",
      "223:\tlearn: 0.0215662\ttotal: 5m 57s\tremaining: 20m 37s\n",
      "224:\tlearn: 0.0214200\ttotal: 5m 59s\tremaining: 20m 37s\n",
      "225:\tlearn: 0.0211731\ttotal: 6m 1s\tremaining: 20m 38s\n",
      "226:\tlearn: 0.0209970\ttotal: 6m 3s\tremaining: 20m 37s\n",
      "227:\tlearn: 0.0207685\ttotal: 6m 5s\tremaining: 20m 37s\n",
      "228:\tlearn: 0.0205563\ttotal: 6m 7s\tremaining: 20m 38s\n",
      "229:\tlearn: 0.0203699\ttotal: 6m 9s\tremaining: 20m 36s\n",
      "230:\tlearn: 0.0201190\ttotal: 6m 11s\tremaining: 20m 36s\n",
      "231:\tlearn: 0.0199041\ttotal: 6m 13s\tremaining: 20m 35s\n",
      "232:\tlearn: 0.0196992\ttotal: 6m 14s\tremaining: 20m 34s\n",
      "233:\tlearn: 0.0194525\ttotal: 6m 16s\tremaining: 20m 32s\n",
      "234:\tlearn: 0.0192256\ttotal: 6m 17s\tremaining: 20m 30s\n",
      "235:\tlearn: 0.0189854\ttotal: 6m 19s\tremaining: 20m 28s\n",
      "236:\tlearn: 0.0188075\ttotal: 6m 21s\tremaining: 20m 27s\n",
      "237:\tlearn: 0.0185696\ttotal: 6m 22s\tremaining: 20m 25s\n",
      "238:\tlearn: 0.0184296\ttotal: 6m 24s\tremaining: 20m 23s\n",
      "239:\tlearn: 0.0182716\ttotal: 6m 25s\tremaining: 20m 22s\n",
      "240:\tlearn: 0.0181406\ttotal: 6m 27s\tremaining: 20m 21s\n",
      "241:\tlearn: 0.0179368\ttotal: 6m 29s\tremaining: 20m 19s\n",
      "242:\tlearn: 0.0178177\ttotal: 6m 30s\tremaining: 20m 18s\n",
      "243:\tlearn: 0.0176686\ttotal: 6m 32s\tremaining: 20m 16s\n",
      "244:\tlearn: 0.0174508\ttotal: 6m 34s\tremaining: 20m 16s\n",
      "245:\tlearn: 0.0172971\ttotal: 6m 36s\tremaining: 20m 15s\n",
      "246:\tlearn: 0.0171453\ttotal: 6m 38s\tremaining: 20m 13s\n",
      "247:\tlearn: 0.0169605\ttotal: 6m 39s\tremaining: 20m 12s\n",
      "248:\tlearn: 0.0167714\ttotal: 6m 41s\tremaining: 20m 11s\n",
      "249:\tlearn: 0.0166473\ttotal: 6m 43s\tremaining: 20m 10s\n",
      "250:\tlearn: 0.0165400\ttotal: 6m 45s\tremaining: 20m 10s\n",
      "251:\tlearn: 0.0163816\ttotal: 6m 47s\tremaining: 20m 10s\n",
      "252:\tlearn: 0.0162632\ttotal: 6m 50s\tremaining: 20m 10s\n",
      "253:\tlearn: 0.0160881\ttotal: 6m 52s\tremaining: 20m 10s\n",
      "254:\tlearn: 0.0159282\ttotal: 6m 53s\tremaining: 20m 9s\n",
      "255:\tlearn: 0.0157675\ttotal: 6m 55s\tremaining: 20m 8s\n",
      "256:\tlearn: 0.0156276\ttotal: 6m 57s\tremaining: 20m 7s\n",
      "257:\tlearn: 0.0154985\ttotal: 6m 59s\tremaining: 20m 5s\n",
      "258:\tlearn: 0.0153199\ttotal: 7m 1s\tremaining: 20m 4s\n",
      "259:\tlearn: 0.0152048\ttotal: 7m 3s\tremaining: 20m 4s\n",
      "260:\tlearn: 0.0150871\ttotal: 7m 5s\tremaining: 20m 4s\n",
      "261:\tlearn: 0.0149908\ttotal: 7m 7s\tremaining: 20m 4s\n",
      "262:\tlearn: 0.0148517\ttotal: 7m 10s\tremaining: 20m 5s\n",
      "263:\tlearn: 0.0147403\ttotal: 7m 12s\tremaining: 20m 4s\n",
      "264:\tlearn: 0.0145865\ttotal: 7m 14s\tremaining: 20m 5s\n",
      "265:\tlearn: 0.0144181\ttotal: 7m 16s\tremaining: 20m 5s\n",
      "266:\tlearn: 0.0142845\ttotal: 7m 18s\tremaining: 20m 3s\n",
      "267:\tlearn: 0.0142044\ttotal: 7m 20s\tremaining: 20m 1s\n",
      "268:\tlearn: 0.0140732\ttotal: 7m 21s\tremaining: 20m\n",
      "269:\tlearn: 0.0139738\ttotal: 7m 23s\tremaining: 19m 58s\n",
      "270:\tlearn: 0.0138696\ttotal: 7m 25s\tremaining: 19m 57s\n",
      "271:\tlearn: 0.0137472\ttotal: 7m 27s\tremaining: 19m 57s\n",
      "272:\tlearn: 0.0136361\ttotal: 7m 29s\tremaining: 19m 58s\n",
      "273:\tlearn: 0.0135135\ttotal: 7m 32s\tremaining: 19m 57s\n",
      "274:\tlearn: 0.0134112\ttotal: 7m 33s\tremaining: 19m 56s\n",
      "275:\tlearn: 0.0132769\ttotal: 7m 35s\tremaining: 19m 55s\n",
      "276:\tlearn: 0.0131355\ttotal: 7m 37s\tremaining: 19m 53s\n",
      "277:\tlearn: 0.0130218\ttotal: 7m 39s\tremaining: 19m 52s\n",
      "278:\tlearn: 0.0129187\ttotal: 7m 40s\tremaining: 19m 51s\n",
      "279:\tlearn: 0.0127908\ttotal: 7m 42s\tremaining: 19m 50s\n",
      "280:\tlearn: 0.0126868\ttotal: 7m 45s\tremaining: 19m 49s\n",
      "281:\tlearn: 0.0125787\ttotal: 7m 47s\tremaining: 19m 49s\n",
      "282:\tlearn: 0.0124862\ttotal: 7m 48s\tremaining: 19m 47s\n",
      "283:\tlearn: 0.0123613\ttotal: 7m 50s\tremaining: 19m 46s\n",
      "284:\tlearn: 0.0122740\ttotal: 7m 52s\tremaining: 19m 44s\n",
      "285:\tlearn: 0.0122018\ttotal: 7m 53s\tremaining: 19m 42s\n",
      "286:\tlearn: 0.0120901\ttotal: 7m 55s\tremaining: 19m 42s\n",
      "287:\tlearn: 0.0119885\ttotal: 7m 57s\tremaining: 19m 41s\n",
      "288:\tlearn: 0.0118894\ttotal: 7m 59s\tremaining: 19m 40s\n",
      "289:\tlearn: 0.0117895\ttotal: 8m 1s\tremaining: 19m 39s\n",
      "290:\tlearn: 0.0116979\ttotal: 8m 3s\tremaining: 19m 38s\n",
      "291:\tlearn: 0.0116210\ttotal: 8m 5s\tremaining: 19m 36s\n",
      "292:\tlearn: 0.0115489\ttotal: 8m 7s\tremaining: 19m 35s\n",
      "293:\tlearn: 0.0114730\ttotal: 8m 8s\tremaining: 19m 33s\n",
      "294:\tlearn: 0.0113848\ttotal: 8m 10s\tremaining: 19m 31s\n",
      "295:\tlearn: 0.0112715\ttotal: 8m 11s\tremaining: 19m 30s\n",
      "296:\tlearn: 0.0111846\ttotal: 8m 13s\tremaining: 19m 28s\n",
      "297:\tlearn: 0.0110850\ttotal: 8m 15s\tremaining: 19m 26s\n",
      "298:\tlearn: 0.0110293\ttotal: 8m 16s\tremaining: 19m 24s\n",
      "299:\tlearn: 0.0109756\ttotal: 8m 18s\tremaining: 19m 22s\n",
      "300:\tlearn: 0.0108738\ttotal: 8m 19s\tremaining: 19m 20s\n",
      "301:\tlearn: 0.0107850\ttotal: 8m 21s\tremaining: 19m 18s\n",
      "302:\tlearn: 0.0107006\ttotal: 8m 22s\tremaining: 19m 16s\n",
      "303:\tlearn: 0.0106172\ttotal: 8m 24s\tremaining: 19m 14s\n",
      "304:\tlearn: 0.0105690\ttotal: 8m 25s\tremaining: 19m 12s\n",
      "305:\tlearn: 0.0104930\ttotal: 8m 27s\tremaining: 19m 11s\n",
      "306:\tlearn: 0.0104344\ttotal: 8m 29s\tremaining: 19m 9s\n",
      "307:\tlearn: 0.0103612\ttotal: 8m 30s\tremaining: 19m 7s\n",
      "308:\tlearn: 0.0102686\ttotal: 8m 32s\tremaining: 19m 5s\n",
      "309:\tlearn: 0.0101791\ttotal: 8m 34s\tremaining: 19m 4s\n",
      "310:\tlearn: 0.0101056\ttotal: 8m 35s\tremaining: 19m 2s\n",
      "311:\tlearn: 0.0100363\ttotal: 8m 37s\tremaining: 19m 1s\n",
      "312:\tlearn: 0.0099647\ttotal: 8m 39s\tremaining: 18m 59s\n",
      "313:\tlearn: 0.0098906\ttotal: 8m 40s\tremaining: 18m 58s\n",
      "314:\tlearn: 0.0098221\ttotal: 8m 42s\tremaining: 18m 56s\n",
      "315:\tlearn: 0.0097566\ttotal: 8m 44s\tremaining: 18m 55s\n",
      "316:\tlearn: 0.0096968\ttotal: 8m 45s\tremaining: 18m 53s\n",
      "317:\tlearn: 0.0096276\ttotal: 8m 47s\tremaining: 18m 51s\n",
      "318:\tlearn: 0.0095620\ttotal: 8m 49s\tremaining: 18m 49s\n",
      "319:\tlearn: 0.0094928\ttotal: 8m 50s\tremaining: 18m 48s\n",
      "320:\tlearn: 0.0094288\ttotal: 8m 52s\tremaining: 18m 46s\n",
      "321:\tlearn: 0.0093826\ttotal: 8m 54s\tremaining: 18m 44s\n",
      "322:\tlearn: 0.0093211\ttotal: 8m 55s\tremaining: 18m 43s\n",
      "323:\tlearn: 0.0092637\ttotal: 8m 57s\tremaining: 18m 42s\n",
      "324:\tlearn: 0.0092030\ttotal: 9m\tremaining: 18m 41s\n",
      "325:\tlearn: 0.0091290\ttotal: 9m 1s\tremaining: 18m 40s\n",
      "326:\tlearn: 0.0090762\ttotal: 9m 3s\tremaining: 18m 39s\n",
      "327:\tlearn: 0.0090062\ttotal: 9m 5s\tremaining: 18m 38s\n",
      "328:\tlearn: 0.0089524\ttotal: 9m 7s\tremaining: 18m 36s\n",
      "329:\tlearn: 0.0089013\ttotal: 9m 9s\tremaining: 18m 35s\n",
      "330:\tlearn: 0.0088546\ttotal: 9m 11s\tremaining: 18m 34s\n",
      "331:\tlearn: 0.0088207\ttotal: 9m 13s\tremaining: 18m 34s\n",
      "332:\tlearn: 0.0087647\ttotal: 9m 15s\tremaining: 18m 32s\n",
      "333:\tlearn: 0.0087251\ttotal: 9m 17s\tremaining: 18m 31s\n",
      "334:\tlearn: 0.0086676\ttotal: 9m 19s\tremaining: 18m 30s\n",
      "335:\tlearn: 0.0086142\ttotal: 9m 21s\tremaining: 18m 29s\n",
      "336:\tlearn: 0.0085686\ttotal: 9m 22s\tremaining: 18m 27s\n",
      "337:\tlearn: 0.0085144\ttotal: 9m 24s\tremaining: 18m 25s\n",
      "338:\tlearn: 0.0084600\ttotal: 9m 26s\tremaining: 18m 23s\n",
      "339:\tlearn: 0.0084070\ttotal: 9m 27s\tremaining: 18m 22s\n",
      "340:\tlearn: 0.0083512\ttotal: 9m 29s\tremaining: 18m 20s\n",
      "341:\tlearn: 0.0082995\ttotal: 9m 31s\tremaining: 18m 18s\n",
      "342:\tlearn: 0.0082507\ttotal: 9m 32s\tremaining: 18m 17s\n",
      "343:\tlearn: 0.0081996\ttotal: 9m 34s\tremaining: 18m 15s\n",
      "344:\tlearn: 0.0081706\ttotal: 9m 36s\tremaining: 18m 14s\n",
      "345:\tlearn: 0.0081177\ttotal: 9m 38s\tremaining: 18m 12s\n",
      "346:\tlearn: 0.0080732\ttotal: 9m 40s\tremaining: 18m 11s\n",
      "347:\tlearn: 0.0080287\ttotal: 9m 41s\tremaining: 18m 10s\n",
      "348:\tlearn: 0.0079890\ttotal: 9m 43s\tremaining: 18m 8s\n",
      "349:\tlearn: 0.0079563\ttotal: 9m 45s\tremaining: 18m 7s\n",
      "350:\tlearn: 0.0079254\ttotal: 9m 47s\tremaining: 18m 6s\n",
      "351:\tlearn: 0.0078816\ttotal: 9m 49s\tremaining: 18m 4s\n",
      "352:\tlearn: 0.0078250\ttotal: 9m 51s\tremaining: 18m 3s\n",
      "353:\tlearn: 0.0077838\ttotal: 9m 53s\tremaining: 18m 2s\n",
      "354:\tlearn: 0.0077325\ttotal: 9m 54s\tremaining: 18m\n",
      "355:\tlearn: 0.0076968\ttotal: 9m 56s\tremaining: 17m 59s\n",
      "356:\tlearn: 0.0076566\ttotal: 9m 58s\tremaining: 17m 58s\n",
      "357:\tlearn: 0.0076057\ttotal: 10m\tremaining: 17m 57s\n",
      "358:\tlearn: 0.0075834\ttotal: 10m 2s\tremaining: 17m 56s\n",
      "359:\tlearn: 0.0075448\ttotal: 10m 4s\tremaining: 17m 55s\n",
      "360:\tlearn: 0.0075139\ttotal: 10m 6s\tremaining: 17m 54s\n",
      "361:\tlearn: 0.0074642\ttotal: 10m 8s\tremaining: 17m 52s\n",
      "362:\tlearn: 0.0074151\ttotal: 10m 10s\tremaining: 17m 51s\n",
      "363:\tlearn: 0.0073726\ttotal: 10m 12s\tremaining: 17m 50s\n",
      "364:\tlearn: 0.0073281\ttotal: 10m 14s\tremaining: 17m 48s\n",
      "365:\tlearn: 0.0072938\ttotal: 10m 16s\tremaining: 17m 47s\n",
      "366:\tlearn: 0.0072641\ttotal: 10m 18s\tremaining: 17m 45s\n",
      "367:\tlearn: 0.0072325\ttotal: 10m 19s\tremaining: 17m 44s\n",
      "368:\tlearn: 0.0072065\ttotal: 10m 21s\tremaining: 17m 42s\n",
      "369:\tlearn: 0.0071814\ttotal: 10m 23s\tremaining: 17m 41s\n",
      "370:\tlearn: 0.0071516\ttotal: 10m 25s\tremaining: 17m 40s\n",
      "371:\tlearn: 0.0071231\ttotal: 10m 27s\tremaining: 17m 38s\n",
      "372:\tlearn: 0.0070820\ttotal: 10m 28s\tremaining: 17m 37s\n",
      "373:\tlearn: 0.0070443\ttotal: 10m 30s\tremaining: 17m 35s\n",
      "374:\tlearn: 0.0070043\ttotal: 10m 32s\tremaining: 17m 34s\n",
      "375:\tlearn: 0.0069810\ttotal: 10m 34s\tremaining: 17m 32s\n",
      "376:\tlearn: 0.0069367\ttotal: 10m 36s\tremaining: 17m 31s\n",
      "377:\tlearn: 0.0068841\ttotal: 10m 38s\tremaining: 17m 30s\n",
      "378:\tlearn: 0.0068458\ttotal: 10m 40s\tremaining: 17m 28s\n",
      "379:\tlearn: 0.0068114\ttotal: 10m 41s\tremaining: 17m 27s\n",
      "380:\tlearn: 0.0067734\ttotal: 10m 43s\tremaining: 17m 26s\n",
      "381:\tlearn: 0.0067458\ttotal: 10m 46s\tremaining: 17m 25s\n",
      "382:\tlearn: 0.0067115\ttotal: 10m 48s\tremaining: 17m 24s\n",
      "383:\tlearn: 0.0066804\ttotal: 10m 50s\tremaining: 17m 23s\n",
      "384:\tlearn: 0.0066572\ttotal: 10m 52s\tremaining: 17m 21s\n",
      "385:\tlearn: 0.0066287\ttotal: 10m 53s\tremaining: 17m 20s\n",
      "386:\tlearn: 0.0065903\ttotal: 10m 55s\tremaining: 17m 18s\n",
      "387:\tlearn: 0.0065489\ttotal: 10m 57s\tremaining: 17m 17s\n",
      "388:\tlearn: 0.0065138\ttotal: 10m 59s\tremaining: 17m 15s\n",
      "389:\tlearn: 0.0064737\ttotal: 11m 1s\tremaining: 17m 14s\n",
      "390:\tlearn: 0.0064490\ttotal: 11m 3s\tremaining: 17m 12s\n",
      "391:\tlearn: 0.0064060\ttotal: 11m 5s\tremaining: 17m 11s\n",
      "392:\tlearn: 0.0063681\ttotal: 11m 6s\tremaining: 17m 9s\n",
      "393:\tlearn: 0.0063329\ttotal: 11m 8s\tremaining: 17m 8s\n",
      "394:\tlearn: 0.0063031\ttotal: 11m 10s\tremaining: 17m 6s\n",
      "395:\tlearn: 0.0062811\ttotal: 11m 11s\tremaining: 17m 4s\n",
      "396:\tlearn: 0.0062465\ttotal: 11m 13s\tremaining: 17m 3s\n",
      "397:\tlearn: 0.0062200\ttotal: 11m 15s\tremaining: 17m 1s\n",
      "398:\tlearn: 0.0061916\ttotal: 11m 17s\tremaining: 16m 59s\n",
      "399:\tlearn: 0.0061692\ttotal: 11m 18s\tremaining: 16m 58s\n",
      "400:\tlearn: 0.0061393\ttotal: 11m 20s\tremaining: 16m 57s\n",
      "401:\tlearn: 0.0061089\ttotal: 11m 22s\tremaining: 16m 55s\n",
      "402:\tlearn: 0.0060886\ttotal: 11m 24s\tremaining: 16m 54s\n",
      "403:\tlearn: 0.0060563\ttotal: 11m 26s\tremaining: 16m 52s\n",
      "404:\tlearn: 0.0060216\ttotal: 11m 28s\tremaining: 16m 51s\n",
      "405:\tlearn: 0.0059989\ttotal: 11m 30s\tremaining: 16m 49s\n",
      "406:\tlearn: 0.0059621\ttotal: 11m 31s\tremaining: 16m 48s\n",
      "407:\tlearn: 0.0059259\ttotal: 11m 33s\tremaining: 16m 46s\n",
      "408:\tlearn: 0.0058990\ttotal: 11m 35s\tremaining: 16m 45s\n",
      "409:\tlearn: 0.0058670\ttotal: 11m 37s\tremaining: 16m 43s\n",
      "410:\tlearn: 0.0058455\ttotal: 11m 39s\tremaining: 16m 41s\n",
      "411:\tlearn: 0.0058189\ttotal: 11m 40s\tremaining: 16m 40s\n",
      "412:\tlearn: 0.0057961\ttotal: 11m 42s\tremaining: 16m 38s\n",
      "413:\tlearn: 0.0057681\ttotal: 11m 44s\tremaining: 16m 37s\n",
      "414:\tlearn: 0.0057513\ttotal: 11m 46s\tremaining: 16m 35s\n",
      "415:\tlearn: 0.0057111\ttotal: 11m 47s\tremaining: 16m 33s\n",
      "416:\tlearn: 0.0056784\ttotal: 11m 49s\tremaining: 16m 32s\n",
      "417:\tlearn: 0.0056466\ttotal: 11m 51s\tremaining: 16m 30s\n",
      "418:\tlearn: 0.0056125\ttotal: 11m 53s\tremaining: 16m 28s\n",
      "419:\tlearn: 0.0055887\ttotal: 11m 54s\tremaining: 16m 27s\n",
      "420:\tlearn: 0.0055662\ttotal: 11m 56s\tremaining: 16m 25s\n",
      "421:\tlearn: 0.0055414\ttotal: 11m 58s\tremaining: 16m 23s\n",
      "422:\tlearn: 0.0055214\ttotal: 11m 59s\tremaining: 16m 22s\n",
      "423:\tlearn: 0.0054994\ttotal: 12m 1s\tremaining: 16m 20s\n",
      "424:\tlearn: 0.0054750\ttotal: 12m 3s\tremaining: 16m 18s\n",
      "425:\tlearn: 0.0054493\ttotal: 12m 5s\tremaining: 16m 17s\n",
      "426:\tlearn: 0.0054317\ttotal: 12m 7s\tremaining: 16m 15s\n",
      "427:\tlearn: 0.0054165\ttotal: 12m 8s\tremaining: 16m 13s\n",
      "428:\tlearn: 0.0054006\ttotal: 12m 10s\tremaining: 16m 12s\n",
      "429:\tlearn: 0.0053719\ttotal: 12m 12s\tremaining: 16m 10s\n",
      "430:\tlearn: 0.0053575\ttotal: 12m 14s\tremaining: 16m 9s\n",
      "431:\tlearn: 0.0053289\ttotal: 12m 16s\tremaining: 16m 7s\n",
      "432:\tlearn: 0.0053035\ttotal: 12m 17s\tremaining: 16m 5s\n",
      "433:\tlearn: 0.0052769\ttotal: 12m 19s\tremaining: 16m 4s\n",
      "434:\tlearn: 0.0052632\ttotal: 12m 21s\tremaining: 16m 2s\n",
      "435:\tlearn: 0.0052363\ttotal: 12m 22s\tremaining: 16m\n",
      "436:\tlearn: 0.0052148\ttotal: 12m 24s\tremaining: 15m 59s\n",
      "437:\tlearn: 0.0051909\ttotal: 12m 26s\tremaining: 15m 57s\n",
      "438:\tlearn: 0.0051548\ttotal: 12m 28s\tremaining: 15m 55s\n",
      "439:\tlearn: 0.0051281\ttotal: 12m 29s\tremaining: 15m 54s\n",
      "440:\tlearn: 0.0051040\ttotal: 12m 31s\tremaining: 15m 52s\n",
      "441:\tlearn: 0.0050798\ttotal: 12m 33s\tremaining: 15m 50s\n",
      "442:\tlearn: 0.0050581\ttotal: 12m 34s\tremaining: 15m 49s\n",
      "443:\tlearn: 0.0050354\ttotal: 12m 37s\tremaining: 15m 48s\n",
      "444:\tlearn: 0.0050150\ttotal: 12m 40s\tremaining: 15m 47s\n",
      "445:\tlearn: 0.0049998\ttotal: 12m 41s\tremaining: 15m 46s\n",
      "446:\tlearn: 0.0049858\ttotal: 12m 43s\tremaining: 15m 44s\n",
      "447:\tlearn: 0.0049624\ttotal: 12m 45s\tremaining: 15m 43s\n",
      "448:\tlearn: 0.0049470\ttotal: 12m 47s\tremaining: 15m 41s\n",
      "449:\tlearn: 0.0049305\ttotal: 12m 49s\tremaining: 15m 39s\n",
      "450:\tlearn: 0.0049108\ttotal: 12m 50s\tremaining: 15m 38s\n",
      "451:\tlearn: 0.0048963\ttotal: 12m 52s\tremaining: 15m 37s\n",
      "452:\tlearn: 0.0048778\ttotal: 12m 55s\tremaining: 15m 36s\n",
      "453:\tlearn: 0.0048610\ttotal: 12m 57s\tremaining: 15m 35s\n",
      "454:\tlearn: 0.0048375\ttotal: 12m 59s\tremaining: 15m 33s\n",
      "455:\tlearn: 0.0048145\ttotal: 13m 1s\tremaining: 15m 32s\n",
      "456:\tlearn: 0.0047987\ttotal: 13m 3s\tremaining: 15m 30s\n",
      "457:\tlearn: 0.0047643\ttotal: 13m 5s\tremaining: 15m 29s\n",
      "458:\tlearn: 0.0047447\ttotal: 13m 7s\tremaining: 15m 28s\n",
      "459:\tlearn: 0.0047236\ttotal: 13m 9s\tremaining: 15m 26s\n",
      "460:\tlearn: 0.0047064\ttotal: 13m 11s\tremaining: 15m 25s\n",
      "461:\tlearn: 0.0046829\ttotal: 13m 13s\tremaining: 15m 24s\n",
      "462:\tlearn: 0.0046666\ttotal: 13m 15s\tremaining: 15m 22s\n",
      "463:\tlearn: 0.0046468\ttotal: 13m 17s\tremaining: 15m 21s\n",
      "464:\tlearn: 0.0046263\ttotal: 13m 19s\tremaining: 15m 19s\n",
      "465:\tlearn: 0.0046107\ttotal: 13m 20s\tremaining: 15m 17s\n",
      "466:\tlearn: 0.0045995\ttotal: 13m 22s\tremaining: 15m 15s\n",
      "467:\tlearn: 0.0045828\ttotal: 13m 24s\tremaining: 15m 14s\n",
      "468:\tlearn: 0.0045707\ttotal: 13m 25s\tremaining: 15m 12s\n",
      "469:\tlearn: 0.0045536\ttotal: 13m 27s\tremaining: 15m 10s\n",
      "470:\tlearn: 0.0045400\ttotal: 13m 29s\tremaining: 15m 9s\n",
      "471:\tlearn: 0.0045256\ttotal: 13m 31s\tremaining: 15m 7s\n",
      "472:\tlearn: 0.0045057\ttotal: 13m 33s\tremaining: 15m 5s\n",
      "473:\tlearn: 0.0044888\ttotal: 13m 34s\tremaining: 15m 4s\n",
      "474:\tlearn: 0.0044724\ttotal: 13m 36s\tremaining: 15m 2s\n",
      "475:\tlearn: 0.0044604\ttotal: 13m 38s\tremaining: 15m\n",
      "476:\tlearn: 0.0044445\ttotal: 13m 39s\tremaining: 14m 59s\n",
      "477:\tlearn: 0.0044276\ttotal: 13m 41s\tremaining: 14m 57s\n",
      "478:\tlearn: 0.0044113\ttotal: 13m 43s\tremaining: 14m 55s\n",
      "479:\tlearn: 0.0043964\ttotal: 13m 44s\tremaining: 14m 53s\n",
      "480:\tlearn: 0.0043772\ttotal: 13m 46s\tremaining: 14m 51s\n",
      "481:\tlearn: 0.0043616\ttotal: 13m 48s\tremaining: 14m 50s\n",
      "482:\tlearn: 0.0043457\ttotal: 13m 50s\tremaining: 14m 49s\n",
      "483:\tlearn: 0.0043299\ttotal: 13m 52s\tremaining: 14m 47s\n",
      "484:\tlearn: 0.0043149\ttotal: 13m 53s\tremaining: 14m 45s\n",
      "485:\tlearn: 0.0042941\ttotal: 13m 55s\tremaining: 14m 43s\n",
      "486:\tlearn: 0.0042787\ttotal: 13m 57s\tremaining: 14m 41s\n",
      "487:\tlearn: 0.0042631\ttotal: 13m 58s\tremaining: 14m 40s\n",
      "488:\tlearn: 0.0042475\ttotal: 14m\tremaining: 14m 38s\n",
      "489:\tlearn: 0.0042352\ttotal: 14m 2s\tremaining: 14m 36s\n",
      "490:\tlearn: 0.0042224\ttotal: 14m 4s\tremaining: 14m 35s\n",
      "491:\tlearn: 0.0042086\ttotal: 14m 5s\tremaining: 14m 33s\n",
      "492:\tlearn: 0.0041934\ttotal: 14m 7s\tremaining: 14m 31s\n",
      "493:\tlearn: 0.0041787\ttotal: 14m 9s\tremaining: 14m 30s\n",
      "494:\tlearn: 0.0041674\ttotal: 14m 11s\tremaining: 14m 28s\n",
      "495:\tlearn: 0.0041531\ttotal: 14m 12s\tremaining: 14m 26s\n",
      "496:\tlearn: 0.0041432\ttotal: 14m 14s\tremaining: 14m 24s\n",
      "497:\tlearn: 0.0041299\ttotal: 14m 16s\tremaining: 14m 23s\n",
      "498:\tlearn: 0.0041160\ttotal: 14m 18s\tremaining: 14m 21s\n",
      "499:\tlearn: 0.0041010\ttotal: 14m 19s\tremaining: 14m 19s\n",
      "500:\tlearn: 0.0040727\ttotal: 14m 21s\tremaining: 14m 18s\n",
      "501:\tlearn: 0.0040574\ttotal: 14m 23s\tremaining: 14m 16s\n",
      "502:\tlearn: 0.0040420\ttotal: 14m 24s\tremaining: 14m 14s\n",
      "503:\tlearn: 0.0040294\ttotal: 14m 26s\tremaining: 14m 12s\n",
      "504:\tlearn: 0.0040173\ttotal: 14m 28s\tremaining: 14m 11s\n",
      "505:\tlearn: 0.0040066\ttotal: 14m 30s\tremaining: 14m 9s\n",
      "506:\tlearn: 0.0039920\ttotal: 14m 31s\tremaining: 14m 7s\n",
      "507:\tlearn: 0.0039760\ttotal: 14m 33s\tremaining: 14m 6s\n",
      "508:\tlearn: 0.0039621\ttotal: 14m 35s\tremaining: 14m 4s\n",
      "509:\tlearn: 0.0039509\ttotal: 14m 38s\tremaining: 14m 3s\n",
      "510:\tlearn: 0.0039401\ttotal: 14m 39s\tremaining: 14m 1s\n",
      "511:\tlearn: 0.0039285\ttotal: 14m 41s\tremaining: 14m\n",
      "512:\tlearn: 0.0039157\ttotal: 14m 43s\tremaining: 13m 58s\n",
      "513:\tlearn: 0.0039020\ttotal: 14m 45s\tremaining: 13m 56s\n",
      "514:\tlearn: 0.0038864\ttotal: 14m 46s\tremaining: 13m 55s\n",
      "515:\tlearn: 0.0038748\ttotal: 14m 48s\tremaining: 13m 53s\n",
      "516:\tlearn: 0.0038667\ttotal: 14m 50s\tremaining: 13m 51s\n",
      "517:\tlearn: 0.0038509\ttotal: 14m 51s\tremaining: 13m 49s\n",
      "518:\tlearn: 0.0038371\ttotal: 14m 53s\tremaining: 13m 48s\n",
      "519:\tlearn: 0.0038293\ttotal: 14m 55s\tremaining: 13m 46s\n",
      "520:\tlearn: 0.0038172\ttotal: 14m 56s\tremaining: 13m 44s\n",
      "521:\tlearn: 0.0038088\ttotal: 14m 58s\tremaining: 13m 42s\n",
      "522:\tlearn: 0.0037955\ttotal: 15m\tremaining: 13m 41s\n",
      "523:\tlearn: 0.0037838\ttotal: 15m 1s\tremaining: 13m 39s\n",
      "524:\tlearn: 0.0037720\ttotal: 15m 3s\tremaining: 13m 37s\n",
      "525:\tlearn: 0.0037601\ttotal: 15m 5s\tremaining: 13m 35s\n",
      "526:\tlearn: 0.0037493\ttotal: 15m 7s\tremaining: 13m 34s\n",
      "527:\tlearn: 0.0037407\ttotal: 15m 8s\tremaining: 13m 32s\n",
      "528:\tlearn: 0.0037298\ttotal: 15m 10s\tremaining: 13m 30s\n",
      "529:\tlearn: 0.0037156\ttotal: 15m 12s\tremaining: 13m 29s\n",
      "530:\tlearn: 0.0037016\ttotal: 15m 13s\tremaining: 13m 27s\n",
      "531:\tlearn: 0.0036940\ttotal: 15m 15s\tremaining: 13m 25s\n",
      "532:\tlearn: 0.0036847\ttotal: 15m 16s\tremaining: 13m 23s\n",
      "533:\tlearn: 0.0036773\ttotal: 15m 18s\tremaining: 13m 21s\n",
      "534:\tlearn: 0.0036667\ttotal: 15m 19s\tremaining: 13m 19s\n",
      "535:\tlearn: 0.0036531\ttotal: 15m 21s\tremaining: 13m 17s\n",
      "536:\tlearn: 0.0036397\ttotal: 15m 22s\tremaining: 13m 15s\n",
      "537:\tlearn: 0.0036096\ttotal: 15m 24s\tremaining: 13m 13s\n",
      "538:\tlearn: 0.0035989\ttotal: 15m 26s\tremaining: 13m 12s\n",
      "539:\tlearn: 0.0035856\ttotal: 15m 27s\tremaining: 13m 10s\n",
      "540:\tlearn: 0.0035728\ttotal: 15m 29s\tremaining: 13m 8s\n",
      "541:\tlearn: 0.0035604\ttotal: 15m 30s\tremaining: 13m 6s\n",
      "542:\tlearn: 0.0035510\ttotal: 15m 32s\tremaining: 13m 4s\n",
      "543:\tlearn: 0.0035411\ttotal: 15m 34s\tremaining: 13m 3s\n",
      "544:\tlearn: 0.0035314\ttotal: 15m 36s\tremaining: 13m 1s\n",
      "545:\tlearn: 0.0035214\ttotal: 15m 38s\tremaining: 13m\n",
      "546:\tlearn: 0.0035120\ttotal: 15m 40s\tremaining: 12m 58s\n",
      "547:\tlearn: 0.0035006\ttotal: 15m 41s\tremaining: 12m 56s\n",
      "548:\tlearn: 0.0034903\ttotal: 15m 43s\tremaining: 12m 55s\n",
      "549:\tlearn: 0.0034820\ttotal: 15m 45s\tremaining: 12m 53s\n",
      "550:\tlearn: 0.0034710\ttotal: 15m 46s\tremaining: 12m 51s\n",
      "551:\tlearn: 0.0034588\ttotal: 15m 48s\tremaining: 12m 50s\n",
      "552:\tlearn: 0.0034474\ttotal: 15m 50s\tremaining: 12m 48s\n",
      "553:\tlearn: 0.0034397\ttotal: 15m 52s\tremaining: 12m 46s\n",
      "554:\tlearn: 0.0034326\ttotal: 15m 54s\tremaining: 12m 44s\n",
      "555:\tlearn: 0.0034224\ttotal: 15m 55s\tremaining: 12m 43s\n",
      "556:\tlearn: 0.0034130\ttotal: 15m 57s\tremaining: 12m 41s\n",
      "557:\tlearn: 0.0034022\ttotal: 15m 59s\tremaining: 12m 39s\n",
      "558:\tlearn: 0.0033943\ttotal: 16m\tremaining: 12m 37s\n",
      "559:\tlearn: 0.0033835\ttotal: 16m 2s\tremaining: 12m 36s\n",
      "560:\tlearn: 0.0033719\ttotal: 16m 4s\tremaining: 12m 34s\n",
      "561:\tlearn: 0.0033618\ttotal: 16m 5s\tremaining: 12m 32s\n",
      "562:\tlearn: 0.0033502\ttotal: 16m 7s\tremaining: 12m 30s\n",
      "563:\tlearn: 0.0033299\ttotal: 16m 8s\tremaining: 12m 29s\n",
      "564:\tlearn: 0.0033192\ttotal: 16m 10s\tremaining: 12m 27s\n",
      "565:\tlearn: 0.0033086\ttotal: 16m 12s\tremaining: 12m 25s\n",
      "566:\tlearn: 0.0032972\ttotal: 16m 13s\tremaining: 12m 23s\n",
      "567:\tlearn: 0.0032862\ttotal: 16m 15s\tremaining: 12m 21s\n",
      "568:\tlearn: 0.0032768\ttotal: 16m 16s\tremaining: 12m 19s\n",
      "569:\tlearn: 0.0032678\ttotal: 16m 18s\tremaining: 12m 17s\n",
      "570:\tlearn: 0.0032589\ttotal: 16m 19s\tremaining: 12m 16s\n",
      "571:\tlearn: 0.0032499\ttotal: 16m 21s\tremaining: 12m 14s\n",
      "572:\tlearn: 0.0032391\ttotal: 16m 22s\tremaining: 12m 12s\n",
      "573:\tlearn: 0.0032304\ttotal: 16m 24s\tremaining: 12m 10s\n",
      "574:\tlearn: 0.0032228\ttotal: 16m 25s\tremaining: 12m 8s\n",
      "575:\tlearn: 0.0032151\ttotal: 16m 27s\tremaining: 12m 6s\n",
      "576:\tlearn: 0.0032151\ttotal: 16m 28s\tremaining: 12m 4s\n",
      "577:\tlearn: 0.0032065\ttotal: 16m 30s\tremaining: 12m 2s\n",
      "578:\tlearn: 0.0031994\ttotal: 16m 31s\tremaining: 12m 1s\n",
      "579:\tlearn: 0.0031884\ttotal: 16m 33s\tremaining: 11m 59s\n",
      "580:\tlearn: 0.0031884\ttotal: 16m 34s\tremaining: 11m 57s\n",
      "581:\tlearn: 0.0031884\ttotal: 16m 35s\tremaining: 11m 55s\n",
      "582:\tlearn: 0.0031806\ttotal: 16m 37s\tremaining: 11m 53s\n",
      "583:\tlearn: 0.0031806\ttotal: 16m 38s\tremaining: 11m 51s\n",
      "584:\tlearn: 0.0031708\ttotal: 16m 40s\tremaining: 11m 49s\n",
      "585:\tlearn: 0.0031634\ttotal: 16m 42s\tremaining: 11m 48s\n",
      "586:\tlearn: 0.0031571\ttotal: 16m 44s\tremaining: 11m 46s\n",
      "587:\tlearn: 0.0031491\ttotal: 16m 45s\tremaining: 11m 44s\n",
      "588:\tlearn: 0.0031405\ttotal: 16m 47s\tremaining: 11m 43s\n",
      "589:\tlearn: 0.0031325\ttotal: 16m 49s\tremaining: 11m 41s\n",
      "590:\tlearn: 0.0031227\ttotal: 16m 51s\tremaining: 11m 39s\n",
      "591:\tlearn: 0.0031164\ttotal: 16m 52s\tremaining: 11m 37s\n",
      "592:\tlearn: 0.0031087\ttotal: 16m 54s\tremaining: 11m 36s\n",
      "593:\tlearn: 0.0031087\ttotal: 16m 55s\tremaining: 11m 34s\n",
      "594:\tlearn: 0.0031087\ttotal: 16m 56s\tremaining: 11m 31s\n",
      "595:\tlearn: 0.0031007\ttotal: 16m 58s\tremaining: 11m 30s\n",
      "596:\tlearn: 0.0031007\ttotal: 16m 59s\tremaining: 11m 28s\n",
      "597:\tlearn: 0.0030938\ttotal: 17m 1s\tremaining: 11m 26s\n",
      "598:\tlearn: 0.0030878\ttotal: 17m 2s\tremaining: 11m 24s\n",
      "599:\tlearn: 0.0030790\ttotal: 17m 4s\tremaining: 11m 22s\n",
      "600:\tlearn: 0.0030690\ttotal: 17m 6s\tremaining: 11m 21s\n",
      "601:\tlearn: 0.0030666\ttotal: 17m 7s\tremaining: 11m 19s\n",
      "602:\tlearn: 0.0030588\ttotal: 17m 9s\tremaining: 11m 17s\n",
      "603:\tlearn: 0.0030502\ttotal: 17m 11s\tremaining: 11m 16s\n",
      "604:\tlearn: 0.0030420\ttotal: 17m 12s\tremaining: 11m 14s\n",
      "605:\tlearn: 0.0030331\ttotal: 17m 14s\tremaining: 11m 12s\n",
      "606:\tlearn: 0.0030254\ttotal: 17m 16s\tremaining: 11m 10s\n",
      "607:\tlearn: 0.0030160\ttotal: 17m 17s\tremaining: 11m 8s\n",
      "608:\tlearn: 0.0030066\ttotal: 17m 19s\tremaining: 11m 7s\n",
      "609:\tlearn: 0.0029996\ttotal: 17m 20s\tremaining: 11m 5s\n",
      "610:\tlearn: 0.0029815\ttotal: 17m 22s\tremaining: 11m 3s\n",
      "611:\tlearn: 0.0029734\ttotal: 17m 23s\tremaining: 11m 1s\n",
      "612:\tlearn: 0.0029642\ttotal: 17m 25s\tremaining: 10m 59s\n",
      "613:\tlearn: 0.0029577\ttotal: 17m 26s\tremaining: 10m 58s\n",
      "614:\tlearn: 0.0029496\ttotal: 17m 28s\tremaining: 10m 56s\n",
      "615:\tlearn: 0.0029405\ttotal: 17m 30s\tremaining: 10m 54s\n",
      "616:\tlearn: 0.0029321\ttotal: 17m 31s\tremaining: 10m 52s\n",
      "617:\tlearn: 0.0029321\ttotal: 17m 32s\tremaining: 10m 50s\n",
      "618:\tlearn: 0.0029236\ttotal: 17m 34s\tremaining: 10m 49s\n",
      "619:\tlearn: 0.0029166\ttotal: 17m 36s\tremaining: 10m 47s\n",
      "620:\tlearn: 0.0029080\ttotal: 17m 38s\tremaining: 10m 45s\n",
      "621:\tlearn: 0.0029014\ttotal: 17m 39s\tremaining: 10m 44s\n",
      "622:\tlearn: 0.0028943\ttotal: 17m 41s\tremaining: 10m 42s\n",
      "623:\tlearn: 0.0028943\ttotal: 17m 42s\tremaining: 10m 40s\n",
      "624:\tlearn: 0.0028869\ttotal: 17m 44s\tremaining: 10m 38s\n",
      "625:\tlearn: 0.0028869\ttotal: 17m 45s\tremaining: 10m 36s\n",
      "626:\tlearn: 0.0028867\ttotal: 17m 46s\tremaining: 10m 34s\n",
      "627:\tlearn: 0.0028867\ttotal: 17m 48s\tremaining: 10m 32s\n",
      "628:\tlearn: 0.0028800\ttotal: 17m 49s\tremaining: 10m 30s\n",
      "629:\tlearn: 0.0028799\ttotal: 17m 50s\tremaining: 10m 28s\n",
      "630:\tlearn: 0.0028715\ttotal: 17m 52s\tremaining: 10m 27s\n",
      "631:\tlearn: 0.0028714\ttotal: 17m 53s\tremaining: 10m 25s\n",
      "632:\tlearn: 0.0028646\ttotal: 17m 55s\tremaining: 10m 23s\n",
      "633:\tlearn: 0.0028646\ttotal: 17m 56s\tremaining: 10m 21s\n",
      "634:\tlearn: 0.0028646\ttotal: 17m 58s\tremaining: 10m 19s\n",
      "635:\tlearn: 0.0028646\ttotal: 17m 59s\tremaining: 10m 17s\n",
      "636:\tlearn: 0.0028577\ttotal: 18m\tremaining: 10m 15s\n",
      "637:\tlearn: 0.0028577\ttotal: 18m 2s\tremaining: 10m 13s\n",
      "638:\tlearn: 0.0028577\ttotal: 18m 3s\tremaining: 10m 11s\n",
      "639:\tlearn: 0.0028577\ttotal: 18m 4s\tremaining: 10m 9s\n",
      "640:\tlearn: 0.0028577\ttotal: 18m 5s\tremaining: 10m 7s\n",
      "641:\tlearn: 0.0028577\ttotal: 18m 6s\tremaining: 10m 5s\n",
      "642:\tlearn: 0.0028577\ttotal: 18m 7s\tremaining: 10m 3s\n",
      "643:\tlearn: 0.0028577\ttotal: 18m 8s\tremaining: 10m 1s\n",
      "644:\tlearn: 0.0028577\ttotal: 18m 10s\tremaining: 10m\n",
      "645:\tlearn: 0.0028577\ttotal: 18m 11s\tremaining: 9m 58s\n",
      "646:\tlearn: 0.0028513\ttotal: 18m 13s\tremaining: 9m 56s\n",
      "647:\tlearn: 0.0028513\ttotal: 18m 14s\tremaining: 9m 54s\n",
      "648:\tlearn: 0.0028513\ttotal: 18m 15s\tremaining: 9m 52s\n",
      "649:\tlearn: 0.0028431\ttotal: 18m 16s\tremaining: 9m 50s\n",
      "650:\tlearn: 0.0028431\ttotal: 18m 17s\tremaining: 9m 48s\n",
      "651:\tlearn: 0.0028431\ttotal: 18m 19s\tremaining: 9m 46s\n",
      "652:\tlearn: 0.0028430\ttotal: 18m 20s\tremaining: 9m 44s\n",
      "653:\tlearn: 0.0028430\ttotal: 18m 21s\tremaining: 9m 42s\n",
      "654:\tlearn: 0.0028363\ttotal: 18m 22s\tremaining: 9m 40s\n",
      "655:\tlearn: 0.0028303\ttotal: 18m 24s\tremaining: 9m 39s\n",
      "656:\tlearn: 0.0028303\ttotal: 18m 25s\tremaining: 9m 37s\n",
      "657:\tlearn: 0.0028303\ttotal: 18m 26s\tremaining: 9m 35s\n",
      "658:\tlearn: 0.0028303\ttotal: 18m 28s\tremaining: 9m 33s\n",
      "659:\tlearn: 0.0028245\ttotal: 18m 29s\tremaining: 9m 31s\n",
      "660:\tlearn: 0.0028165\ttotal: 18m 31s\tremaining: 9m 29s\n",
      "661:\tlearn: 0.0028165\ttotal: 18m 32s\tremaining: 9m 27s\n",
      "662:\tlearn: 0.0028041\ttotal: 18m 34s\tremaining: 9m 26s\n",
      "663:\tlearn: 0.0027980\ttotal: 18m 35s\tremaining: 9m 24s\n",
      "664:\tlearn: 0.0027904\ttotal: 18m 37s\tremaining: 9m 22s\n",
      "665:\tlearn: 0.0027828\ttotal: 18m 38s\tremaining: 9m 21s\n",
      "666:\tlearn: 0.0027752\ttotal: 18m 40s\tremaining: 9m 19s\n",
      "667:\tlearn: 0.0027681\ttotal: 18m 41s\tremaining: 9m 17s\n",
      "668:\tlearn: 0.0027611\ttotal: 18m 43s\tremaining: 9m 15s\n",
      "669:\tlearn: 0.0027551\ttotal: 18m 45s\tremaining: 9m 14s\n",
      "670:\tlearn: 0.0027479\ttotal: 18m 46s\tremaining: 9m 12s\n",
      "671:\tlearn: 0.0027405\ttotal: 18m 48s\tremaining: 9m 10s\n",
      "672:\tlearn: 0.0027405\ttotal: 18m 49s\tremaining: 9m 8s\n",
      "673:\tlearn: 0.0027335\ttotal: 18m 51s\tremaining: 9m 7s\n",
      "674:\tlearn: 0.0027335\ttotal: 18m 52s\tremaining: 9m 5s\n",
      "675:\tlearn: 0.0027270\ttotal: 18m 53s\tremaining: 9m 3s\n",
      "676:\tlearn: 0.0027210\ttotal: 18m 55s\tremaining: 9m 1s\n",
      "677:\tlearn: 0.0027210\ttotal: 18m 56s\tremaining: 8m 59s\n",
      "678:\tlearn: 0.0027210\ttotal: 18m 57s\tremaining: 8m 57s\n",
      "679:\tlearn: 0.0027137\ttotal: 18m 59s\tremaining: 8m 56s\n",
      "680:\tlearn: 0.0027064\ttotal: 19m 1s\tremaining: 8m 54s\n",
      "681:\tlearn: 0.0027064\ttotal: 19m 2s\tremaining: 8m 52s\n",
      "682:\tlearn: 0.0027064\ttotal: 19m 3s\tremaining: 8m 50s\n",
      "683:\tlearn: 0.0027064\ttotal: 19m 4s\tremaining: 8m 48s\n",
      "684:\tlearn: 0.0027064\ttotal: 19m 5s\tremaining: 8m 46s\n",
      "685:\tlearn: 0.0027064\ttotal: 19m 6s\tremaining: 8m 44s\n",
      "686:\tlearn: 0.0027063\ttotal: 19m 7s\tremaining: 8m 42s\n",
      "687:\tlearn: 0.0027063\ttotal: 19m 9s\tremaining: 8m 41s\n",
      "688:\tlearn: 0.0026996\ttotal: 19m 10s\tremaining: 8m 39s\n",
      "689:\tlearn: 0.0026996\ttotal: 19m 11s\tremaining: 8m 37s\n",
      "690:\tlearn: 0.0026995\ttotal: 19m 13s\tremaining: 8m 35s\n",
      "691:\tlearn: 0.0026936\ttotal: 19m 14s\tremaining: 8m 33s\n",
      "692:\tlearn: 0.0026936\ttotal: 19m 15s\tremaining: 8m 31s\n",
      "693:\tlearn: 0.0026936\ttotal: 19m 16s\tremaining: 8m 30s\n",
      "694:\tlearn: 0.0026936\ttotal: 19m 17s\tremaining: 8m 28s\n",
      "695:\tlearn: 0.0026936\ttotal: 19m 18s\tremaining: 8m 26s\n",
      "696:\tlearn: 0.0026936\ttotal: 19m 20s\tremaining: 8m 24s\n",
      "697:\tlearn: 0.0026936\ttotal: 19m 21s\tremaining: 8m 22s\n",
      "698:\tlearn: 0.0026935\ttotal: 19m 22s\tremaining: 8m 20s\n",
      "699:\tlearn: 0.0026872\ttotal: 19m 23s\tremaining: 8m 18s\n",
      "700:\tlearn: 0.0026872\ttotal: 19m 24s\tremaining: 8m 16s\n",
      "701:\tlearn: 0.0026872\ttotal: 19m 26s\tremaining: 8m 15s\n",
      "702:\tlearn: 0.0026842\ttotal: 19m 27s\tremaining: 8m 13s\n",
      "703:\tlearn: 0.0026842\ttotal: 19m 28s\tremaining: 8m 11s\n",
      "704:\tlearn: 0.0026842\ttotal: 19m 29s\tremaining: 8m 9s\n",
      "705:\tlearn: 0.0026751\ttotal: 19m 31s\tremaining: 8m 7s\n",
      "706:\tlearn: 0.0026695\ttotal: 19m 32s\tremaining: 8m 6s\n",
      "707:\tlearn: 0.0026695\ttotal: 19m 33s\tremaining: 8m 4s\n",
      "708:\tlearn: 0.0026694\ttotal: 19m 35s\tremaining: 8m 2s\n",
      "709:\tlearn: 0.0026625\ttotal: 19m 36s\tremaining: 8m\n",
      "710:\tlearn: 0.0026570\ttotal: 19m 38s\tremaining: 7m 58s\n",
      "711:\tlearn: 0.0026570\ttotal: 19m 39s\tremaining: 7m 57s\n",
      "712:\tlearn: 0.0026570\ttotal: 19m 40s\tremaining: 7m 55s\n",
      "713:\tlearn: 0.0026570\ttotal: 19m 41s\tremaining: 7m 53s\n",
      "714:\tlearn: 0.0026498\ttotal: 19m 43s\tremaining: 7m 51s\n",
      "715:\tlearn: 0.0026498\ttotal: 19m 44s\tremaining: 7m 49s\n",
      "716:\tlearn: 0.0026498\ttotal: 19m 45s\tremaining: 7m 47s\n",
      "717:\tlearn: 0.0026441\ttotal: 19m 47s\tremaining: 7m 46s\n",
      "718:\tlearn: 0.0026442\ttotal: 19m 48s\tremaining: 7m 44s\n",
      "719:\tlearn: 0.0026441\ttotal: 19m 49s\tremaining: 7m 42s\n",
      "720:\tlearn: 0.0026441\ttotal: 19m 50s\tremaining: 7m 40s\n",
      "721:\tlearn: 0.0026441\ttotal: 19m 51s\tremaining: 7m 38s\n",
      "722:\tlearn: 0.0026372\ttotal: 19m 53s\tremaining: 7m 37s\n",
      "723:\tlearn: 0.0026372\ttotal: 19m 55s\tremaining: 7m 35s\n",
      "724:\tlearn: 0.0026372\ttotal: 19m 56s\tremaining: 7m 33s\n",
      "725:\tlearn: 0.0026372\ttotal: 19m 57s\tremaining: 7m 31s\n",
      "726:\tlearn: 0.0026372\ttotal: 19m 58s\tremaining: 7m 30s\n",
      "727:\tlearn: 0.0026372\ttotal: 19m 59s\tremaining: 7m 28s\n",
      "728:\tlearn: 0.0026372\ttotal: 20m\tremaining: 7m 26s\n",
      "729:\tlearn: 0.0026372\ttotal: 20m 1s\tremaining: 7m 24s\n",
      "730:\tlearn: 0.0026301\ttotal: 20m 3s\tremaining: 7m 22s\n",
      "731:\tlearn: 0.0026301\ttotal: 20m 4s\tremaining: 7m 20s\n",
      "732:\tlearn: 0.0026301\ttotal: 20m 5s\tremaining: 7m 19s\n",
      "733:\tlearn: 0.0026301\ttotal: 20m 6s\tremaining: 7m 17s\n",
      "734:\tlearn: 0.0026301\ttotal: 20m 8s\tremaining: 7m 15s\n",
      "735:\tlearn: 0.0026300\ttotal: 20m 9s\tremaining: 7m 13s\n",
      "736:\tlearn: 0.0026300\ttotal: 20m 10s\tremaining: 7m 12s\n",
      "737:\tlearn: 0.0026300\ttotal: 20m 11s\tremaining: 7m 10s\n",
      "738:\tlearn: 0.0026300\ttotal: 20m 12s\tremaining: 7m 8s\n",
      "739:\tlearn: 0.0026300\ttotal: 20m 14s\tremaining: 7m 6s\n",
      "740:\tlearn: 0.0026300\ttotal: 20m 15s\tremaining: 7m 4s\n",
      "741:\tlearn: 0.0026300\ttotal: 20m 16s\tremaining: 7m 2s\n",
      "742:\tlearn: 0.0026300\ttotal: 20m 17s\tremaining: 7m 1s\n",
      "743:\tlearn: 0.0026300\ttotal: 20m 18s\tremaining: 6m 59s\n",
      "744:\tlearn: 0.0026300\ttotal: 20m 19s\tremaining: 6m 57s\n",
      "745:\tlearn: 0.0026300\ttotal: 20m 20s\tremaining: 6m 55s\n",
      "746:\tlearn: 0.0026300\ttotal: 20m 21s\tremaining: 6m 53s\n",
      "747:\tlearn: 0.0026300\ttotal: 20m 23s\tremaining: 6m 52s\n",
      "748:\tlearn: 0.0026300\ttotal: 20m 24s\tremaining: 6m 50s\n",
      "749:\tlearn: 0.0026300\ttotal: 20m 25s\tremaining: 6m 48s\n",
      "750:\tlearn: 0.0026300\ttotal: 20m 26s\tremaining: 6m 46s\n",
      "751:\tlearn: 0.0026300\ttotal: 20m 27s\tremaining: 6m 44s\n",
      "752:\tlearn: 0.0026300\ttotal: 20m 28s\tremaining: 6m 43s\n",
      "753:\tlearn: 0.0026300\ttotal: 20m 29s\tremaining: 6m 41s\n",
      "754:\tlearn: 0.0026299\ttotal: 20m 31s\tremaining: 6m 39s\n",
      "755:\tlearn: 0.0026299\ttotal: 20m 32s\tremaining: 6m 37s\n",
      "756:\tlearn: 0.0026299\ttotal: 20m 33s\tremaining: 6m 36s\n",
      "757:\tlearn: 0.0026299\ttotal: 20m 34s\tremaining: 6m 34s\n",
      "758:\tlearn: 0.0026299\ttotal: 20m 36s\tremaining: 6m 32s\n",
      "759:\tlearn: 0.0026299\ttotal: 20m 37s\tremaining: 6m 30s\n",
      "760:\tlearn: 0.0026299\ttotal: 20m 38s\tremaining: 6m 28s\n",
      "761:\tlearn: 0.0026299\ttotal: 20m 39s\tremaining: 6m 27s\n",
      "762:\tlearn: 0.0026299\ttotal: 20m 40s\tremaining: 6m 25s\n",
      "763:\tlearn: 0.0026299\ttotal: 20m 42s\tremaining: 6m 23s\n",
      "764:\tlearn: 0.0026299\ttotal: 20m 43s\tremaining: 6m 21s\n",
      "765:\tlearn: 0.0026299\ttotal: 20m 44s\tremaining: 6m 20s\n",
      "766:\tlearn: 0.0026299\ttotal: 20m 45s\tremaining: 6m 18s\n",
      "767:\tlearn: 0.0026299\ttotal: 20m 46s\tremaining: 6m 16s\n",
      "768:\tlearn: 0.0026299\ttotal: 20m 48s\tremaining: 6m 14s\n",
      "769:\tlearn: 0.0026245\ttotal: 20m 49s\tremaining: 6m 13s\n",
      "770:\tlearn: 0.0026245\ttotal: 20m 50s\tremaining: 6m 11s\n",
      "771:\tlearn: 0.0026245\ttotal: 20m 52s\tremaining: 6m 9s\n",
      "772:\tlearn: 0.0026245\ttotal: 20m 53s\tremaining: 6m 7s\n",
      "773:\tlearn: 0.0026195\ttotal: 20m 54s\tremaining: 6m 6s\n",
      "774:\tlearn: 0.0026195\ttotal: 20m 55s\tremaining: 6m 4s\n",
      "775:\tlearn: 0.0026195\ttotal: 20m 57s\tremaining: 6m 2s\n",
      "776:\tlearn: 0.0026195\ttotal: 20m 58s\tremaining: 6m 1s\n",
      "777:\tlearn: 0.0026194\ttotal: 20m 59s\tremaining: 5m 59s\n",
      "778:\tlearn: 0.0026194\ttotal: 21m\tremaining: 5m 57s\n",
      "779:\tlearn: 0.0026194\ttotal: 21m 1s\tremaining: 5m 55s\n",
      "780:\tlearn: 0.0026194\ttotal: 21m 3s\tremaining: 5m 54s\n",
      "781:\tlearn: 0.0026194\ttotal: 21m 4s\tremaining: 5m 52s\n",
      "782:\tlearn: 0.0026194\ttotal: 21m 5s\tremaining: 5m 50s\n",
      "783:\tlearn: 0.0026194\ttotal: 21m 6s\tremaining: 5m 48s\n",
      "784:\tlearn: 0.0026194\ttotal: 21m 7s\tremaining: 5m 47s\n",
      "785:\tlearn: 0.0026194\ttotal: 21m 9s\tremaining: 5m 45s\n",
      "786:\tlearn: 0.0026194\ttotal: 21m 10s\tremaining: 5m 43s\n",
      "787:\tlearn: 0.0026194\ttotal: 21m 11s\tremaining: 5m 42s\n",
      "788:\tlearn: 0.0026194\ttotal: 21m 12s\tremaining: 5m 40s\n",
      "789:\tlearn: 0.0026193\ttotal: 21m 14s\tremaining: 5m 38s\n",
      "790:\tlearn: 0.0026193\ttotal: 21m 15s\tremaining: 5m 36s\n",
      "791:\tlearn: 0.0026193\ttotal: 21m 16s\tremaining: 5m 35s\n",
      "792:\tlearn: 0.0026193\ttotal: 21m 17s\tremaining: 5m 33s\n",
      "793:\tlearn: 0.0026193\ttotal: 21m 18s\tremaining: 5m 31s\n",
      "794:\tlearn: 0.0026193\ttotal: 21m 20s\tremaining: 5m 30s\n",
      "795:\tlearn: 0.0026193\ttotal: 21m 21s\tremaining: 5m 28s\n",
      "796:\tlearn: 0.0026193\ttotal: 21m 22s\tremaining: 5m 26s\n",
      "797:\tlearn: 0.0026193\ttotal: 21m 23s\tremaining: 5m 24s\n",
      "798:\tlearn: 0.0026193\ttotal: 21m 24s\tremaining: 5m 23s\n",
      "799:\tlearn: 0.0026193\ttotal: 21m 25s\tremaining: 5m 21s\n",
      "800:\tlearn: 0.0026193\ttotal: 21m 26s\tremaining: 5m 19s\n",
      "801:\tlearn: 0.0026193\ttotal: 21m 28s\tremaining: 5m 17s\n",
      "802:\tlearn: 0.0026193\ttotal: 21m 29s\tremaining: 5m 16s\n",
      "803:\tlearn: 0.0026193\ttotal: 21m 30s\tremaining: 5m 14s\n",
      "804:\tlearn: 0.0026193\ttotal: 21m 31s\tremaining: 5m 12s\n",
      "805:\tlearn: 0.0026193\ttotal: 21m 32s\tremaining: 5m 11s\n",
      "806:\tlearn: 0.0026193\ttotal: 21m 33s\tremaining: 5m 9s\n",
      "807:\tlearn: 0.0026193\ttotal: 21m 34s\tremaining: 5m 7s\n",
      "808:\tlearn: 0.0026193\ttotal: 21m 36s\tremaining: 5m 6s\n",
      "809:\tlearn: 0.0026192\ttotal: 21m 37s\tremaining: 5m 4s\n",
      "810:\tlearn: 0.0026192\ttotal: 21m 38s\tremaining: 5m 2s\n",
      "811:\tlearn: 0.0026192\ttotal: 21m 39s\tremaining: 5m\n",
      "812:\tlearn: 0.0026192\ttotal: 21m 41s\tremaining: 4m 59s\n",
      "813:\tlearn: 0.0026192\ttotal: 21m 42s\tremaining: 4m 57s\n",
      "814:\tlearn: 0.0026192\ttotal: 21m 43s\tremaining: 4m 55s\n",
      "815:\tlearn: 0.0026192\ttotal: 21m 44s\tremaining: 4m 54s\n",
      "816:\tlearn: 0.0026192\ttotal: 21m 45s\tremaining: 4m 52s\n",
      "817:\tlearn: 0.0026192\ttotal: 21m 47s\tremaining: 4m 50s\n",
      "818:\tlearn: 0.0026192\ttotal: 21m 48s\tremaining: 4m 49s\n",
      "819:\tlearn: 0.0026192\ttotal: 21m 49s\tremaining: 4m 47s\n",
      "820:\tlearn: 0.0026192\ttotal: 21m 50s\tremaining: 4m 45s\n",
      "821:\tlearn: 0.0026125\ttotal: 21m 52s\tremaining: 4m 44s\n",
      "822:\tlearn: 0.0026125\ttotal: 21m 53s\tremaining: 4m 42s\n",
      "823:\tlearn: 0.0026125\ttotal: 21m 54s\tremaining: 4m 40s\n",
      "824:\tlearn: 0.0026125\ttotal: 21m 55s\tremaining: 4m 39s\n",
      "825:\tlearn: 0.0026125\ttotal: 21m 56s\tremaining: 4m 37s\n",
      "826:\tlearn: 0.0026125\ttotal: 21m 58s\tremaining: 4m 35s\n",
      "827:\tlearn: 0.0026125\ttotal: 21m 59s\tremaining: 4m 34s\n",
      "828:\tlearn: 0.0026125\ttotal: 22m\tremaining: 4m 32s\n",
      "829:\tlearn: 0.0026125\ttotal: 22m 1s\tremaining: 4m 30s\n",
      "830:\tlearn: 0.0026125\ttotal: 22m 2s\tremaining: 4m 29s\n",
      "831:\tlearn: 0.0025991\ttotal: 22m 4s\tremaining: 4m 27s\n",
      "832:\tlearn: 0.0025940\ttotal: 22m 5s\tremaining: 4m 25s\n",
      "833:\tlearn: 0.0025870\ttotal: 22m 7s\tremaining: 4m 24s\n",
      "834:\tlearn: 0.0025870\ttotal: 22m 8s\tremaining: 4m 22s\n",
      "835:\tlearn: 0.0025870\ttotal: 22m 9s\tremaining: 4m 20s\n",
      "836:\tlearn: 0.0025870\ttotal: 22m 10s\tremaining: 4m 19s\n",
      "837:\tlearn: 0.0025870\ttotal: 22m 12s\tremaining: 4m 17s\n",
      "838:\tlearn: 0.0025814\ttotal: 22m 13s\tremaining: 4m 15s\n",
      "839:\tlearn: 0.0025814\ttotal: 22m 14s\tremaining: 4m 14s\n",
      "840:\tlearn: 0.0025759\ttotal: 22m 16s\tremaining: 4m 12s\n",
      "841:\tlearn: 0.0025759\ttotal: 22m 17s\tremaining: 4m 10s\n",
      "842:\tlearn: 0.0025758\ttotal: 22m 18s\tremaining: 4m 9s\n",
      "843:\tlearn: 0.0025758\ttotal: 22m 19s\tremaining: 4m 7s\n",
      "844:\tlearn: 0.0025699\ttotal: 22m 21s\tremaining: 4m 6s\n",
      "845:\tlearn: 0.0025672\ttotal: 22m 22s\tremaining: 4m 4s\n",
      "846:\tlearn: 0.0025672\ttotal: 22m 23s\tremaining: 4m 2s\n",
      "847:\tlearn: 0.0025672\ttotal: 22m 24s\tremaining: 4m 1s\n",
      "848:\tlearn: 0.0025672\ttotal: 22m 25s\tremaining: 3m 59s\n",
      "849:\tlearn: 0.0025672\ttotal: 22m 27s\tremaining: 3m 57s\n",
      "850:\tlearn: 0.0025672\ttotal: 22m 28s\tremaining: 3m 56s\n",
      "851:\tlearn: 0.0025672\ttotal: 22m 29s\tremaining: 3m 54s\n",
      "852:\tlearn: 0.0025672\ttotal: 22m 30s\tremaining: 3m 52s\n",
      "853:\tlearn: 0.0025671\ttotal: 22m 31s\tremaining: 3m 51s\n",
      "854:\tlearn: 0.0025613\ttotal: 22m 33s\tremaining: 3m 49s\n",
      "855:\tlearn: 0.0025613\ttotal: 22m 34s\tremaining: 3m 47s\n",
      "856:\tlearn: 0.0025613\ttotal: 22m 35s\tremaining: 3m 46s\n",
      "857:\tlearn: 0.0025613\ttotal: 22m 36s\tremaining: 3m 44s\n",
      "858:\tlearn: 0.0025613\ttotal: 22m 37s\tremaining: 3m 42s\n",
      "859:\tlearn: 0.0025613\ttotal: 22m 39s\tremaining: 3m 41s\n",
      "860:\tlearn: 0.0025612\ttotal: 22m 40s\tremaining: 3m 39s\n",
      "861:\tlearn: 0.0025612\ttotal: 22m 41s\tremaining: 3m 37s\n",
      "862:\tlearn: 0.0025612\ttotal: 22m 42s\tremaining: 3m 36s\n",
      "863:\tlearn: 0.0025612\ttotal: 22m 43s\tremaining: 3m 34s\n",
      "864:\tlearn: 0.0025612\ttotal: 22m 44s\tremaining: 3m 33s\n",
      "865:\tlearn: 0.0025612\ttotal: 22m 45s\tremaining: 3m 31s\n",
      "866:\tlearn: 0.0025612\ttotal: 22m 47s\tremaining: 3m 29s\n",
      "867:\tlearn: 0.0025612\ttotal: 22m 48s\tremaining: 3m 28s\n",
      "868:\tlearn: 0.0025612\ttotal: 22m 49s\tremaining: 3m 26s\n",
      "869:\tlearn: 0.0025612\ttotal: 22m 50s\tremaining: 3m 24s\n",
      "870:\tlearn: 0.0025612\ttotal: 22m 51s\tremaining: 3m 23s\n",
      "871:\tlearn: 0.0025611\ttotal: 22m 53s\tremaining: 3m 21s\n",
      "872:\tlearn: 0.0025611\ttotal: 22m 54s\tremaining: 3m 19s\n",
      "873:\tlearn: 0.0025611\ttotal: 22m 55s\tremaining: 3m 18s\n",
      "874:\tlearn: 0.0025611\ttotal: 22m 56s\tremaining: 3m 16s\n",
      "875:\tlearn: 0.0025611\ttotal: 22m 57s\tremaining: 3m 14s\n",
      "876:\tlearn: 0.0025610\ttotal: 22m 58s\tremaining: 3m 13s\n",
      "877:\tlearn: 0.0025610\ttotal: 22m 59s\tremaining: 3m 11s\n",
      "878:\tlearn: 0.0025610\ttotal: 23m\tremaining: 3m 10s\n",
      "879:\tlearn: 0.0025610\ttotal: 23m 2s\tremaining: 3m 8s\n",
      "880:\tlearn: 0.0025553\ttotal: 23m 3s\tremaining: 3m 6s\n",
      "881:\tlearn: 0.0025553\ttotal: 23m 5s\tremaining: 3m 5s\n",
      "882:\tlearn: 0.0025553\ttotal: 23m 6s\tremaining: 3m 3s\n",
      "883:\tlearn: 0.0025553\ttotal: 23m 7s\tremaining: 3m 2s\n",
      "884:\tlearn: 0.0025553\ttotal: 23m 8s\tremaining: 3m\n",
      "885:\tlearn: 0.0025553\ttotal: 23m 9s\tremaining: 2m 58s\n",
      "886:\tlearn: 0.0025553\ttotal: 23m 11s\tremaining: 2m 57s\n",
      "887:\tlearn: 0.0025553\ttotal: 23m 12s\tremaining: 2m 55s\n",
      "888:\tlearn: 0.0025553\ttotal: 23m 13s\tremaining: 2m 53s\n",
      "889:\tlearn: 0.0025553\ttotal: 23m 14s\tremaining: 2m 52s\n",
      "890:\tlearn: 0.0025553\ttotal: 23m 15s\tremaining: 2m 50s\n",
      "891:\tlearn: 0.0025553\ttotal: 23m 16s\tremaining: 2m 49s\n",
      "892:\tlearn: 0.0025553\ttotal: 23m 17s\tremaining: 2m 47s\n",
      "893:\tlearn: 0.0025553\ttotal: 23m 19s\tremaining: 2m 45s\n",
      "894:\tlearn: 0.0025552\ttotal: 23m 20s\tremaining: 2m 44s\n",
      "895:\tlearn: 0.0025552\ttotal: 23m 21s\tremaining: 2m 42s\n",
      "896:\tlearn: 0.0025552\ttotal: 23m 22s\tremaining: 2m 41s\n",
      "897:\tlearn: 0.0025552\ttotal: 23m 23s\tremaining: 2m 39s\n",
      "898:\tlearn: 0.0025552\ttotal: 23m 24s\tremaining: 2m 37s\n",
      "899:\tlearn: 0.0025552\ttotal: 23m 26s\tremaining: 2m 36s\n",
      "900:\tlearn: 0.0025552\ttotal: 23m 27s\tremaining: 2m 34s\n",
      "901:\tlearn: 0.0025552\ttotal: 23m 28s\tremaining: 2m 33s\n",
      "902:\tlearn: 0.0025552\ttotal: 23m 29s\tremaining: 2m 31s\n",
      "903:\tlearn: 0.0025552\ttotal: 23m 30s\tremaining: 2m 29s\n",
      "904:\tlearn: 0.0025551\ttotal: 23m 31s\tremaining: 2m 28s\n",
      "905:\tlearn: 0.0025551\ttotal: 23m 32s\tremaining: 2m 26s\n",
      "906:\tlearn: 0.0025551\ttotal: 23m 34s\tremaining: 2m 24s\n",
      "907:\tlearn: 0.0025551\ttotal: 23m 35s\tremaining: 2m 23s\n",
      "908:\tlearn: 0.0025551\ttotal: 23m 36s\tremaining: 2m 21s\n",
      "909:\tlearn: 0.0025551\ttotal: 23m 37s\tremaining: 2m 20s\n",
      "910:\tlearn: 0.0025551\ttotal: 23m 38s\tremaining: 2m 18s\n",
      "911:\tlearn: 0.0025551\ttotal: 23m 39s\tremaining: 2m 17s\n",
      "912:\tlearn: 0.0025550\ttotal: 23m 41s\tremaining: 2m 15s\n",
      "913:\tlearn: 0.0025550\ttotal: 23m 42s\tremaining: 2m 13s\n",
      "914:\tlearn: 0.0025522\ttotal: 23m 43s\tremaining: 2m 12s\n",
      "915:\tlearn: 0.0025522\ttotal: 23m 44s\tremaining: 2m 10s\n",
      "916:\tlearn: 0.0025522\ttotal: 23m 45s\tremaining: 2m 9s\n",
      "917:\tlearn: 0.0025521\ttotal: 23m 46s\tremaining: 2m 7s\n",
      "918:\tlearn: 0.0025521\ttotal: 23m 48s\tremaining: 2m 5s\n",
      "919:\tlearn: 0.0025521\ttotal: 23m 49s\tremaining: 2m 4s\n",
      "920:\tlearn: 0.0025521\ttotal: 23m 50s\tremaining: 2m 2s\n",
      "921:\tlearn: 0.0025521\ttotal: 23m 51s\tremaining: 2m 1s\n",
      "922:\tlearn: 0.0025521\ttotal: 23m 52s\tremaining: 1m 59s\n",
      "923:\tlearn: 0.0025521\ttotal: 23m 54s\tremaining: 1m 57s\n",
      "924:\tlearn: 0.0025521\ttotal: 23m 55s\tremaining: 1m 56s\n",
      "925:\tlearn: 0.0025521\ttotal: 23m 56s\tremaining: 1m 54s\n",
      "926:\tlearn: 0.0025521\ttotal: 23m 57s\tremaining: 1m 53s\n",
      "927:\tlearn: 0.0025521\ttotal: 23m 58s\tremaining: 1m 51s\n",
      "928:\tlearn: 0.0025521\ttotal: 23m 59s\tremaining: 1m 50s\n",
      "929:\tlearn: 0.0025521\ttotal: 24m\tremaining: 1m 48s\n",
      "930:\tlearn: 0.0025521\ttotal: 24m 1s\tremaining: 1m 46s\n",
      "931:\tlearn: 0.0025521\ttotal: 24m 2s\tremaining: 1m 45s\n",
      "932:\tlearn: 0.0025521\ttotal: 24m 4s\tremaining: 1m 43s\n",
      "933:\tlearn: 0.0025521\ttotal: 24m 5s\tremaining: 1m 42s\n",
      "934:\tlearn: 0.0025521\ttotal: 24m 6s\tremaining: 1m 40s\n",
      "935:\tlearn: 0.0025521\ttotal: 24m 7s\tremaining: 1m 38s\n",
      "936:\tlearn: 0.0025520\ttotal: 24m 8s\tremaining: 1m 37s\n",
      "937:\tlearn: 0.0025520\ttotal: 24m 10s\tremaining: 1m 35s\n",
      "938:\tlearn: 0.0025520\ttotal: 24m 11s\tremaining: 1m 34s\n",
      "939:\tlearn: 0.0025520\ttotal: 24m 12s\tremaining: 1m 32s\n",
      "940:\tlearn: 0.0025520\ttotal: 24m 13s\tremaining: 1m 31s\n",
      "941:\tlearn: 0.0025520\ttotal: 24m 14s\tremaining: 1m 29s\n",
      "942:\tlearn: 0.0025520\ttotal: 24m 16s\tremaining: 1m 28s\n",
      "943:\tlearn: 0.0025520\ttotal: 24m 17s\tremaining: 1m 26s\n",
      "944:\tlearn: 0.0025520\ttotal: 24m 18s\tremaining: 1m 24s\n",
      "945:\tlearn: 0.0025520\ttotal: 24m 19s\tremaining: 1m 23s\n",
      "946:\tlearn: 0.0025520\ttotal: 24m 20s\tremaining: 1m 21s\n",
      "947:\tlearn: 0.0025505\ttotal: 24m 21s\tremaining: 1m 20s\n",
      "948:\tlearn: 0.0025505\ttotal: 24m 23s\tremaining: 1m 18s\n",
      "949:\tlearn: 0.0025505\ttotal: 24m 24s\tremaining: 1m 17s\n",
      "950:\tlearn: 0.0025505\ttotal: 24m 25s\tremaining: 1m 15s\n",
      "951:\tlearn: 0.0025505\ttotal: 24m 26s\tremaining: 1m 13s\n",
      "952:\tlearn: 0.0025505\ttotal: 24m 27s\tremaining: 1m 12s\n",
      "953:\tlearn: 0.0025505\ttotal: 24m 28s\tremaining: 1m 10s\n",
      "954:\tlearn: 0.0025505\ttotal: 24m 30s\tremaining: 1m 9s\n",
      "955:\tlearn: 0.0025504\ttotal: 24m 32s\tremaining: 1m 7s\n",
      "956:\tlearn: 0.0025503\ttotal: 24m 33s\tremaining: 1m 6s\n",
      "957:\tlearn: 0.0025503\ttotal: 24m 34s\tremaining: 1m 4s\n",
      "958:\tlearn: 0.0025503\ttotal: 24m 35s\tremaining: 1m 3s\n",
      "959:\tlearn: 0.0025503\ttotal: 24m 36s\tremaining: 1m 1s\n",
      "960:\tlearn: 0.0025503\ttotal: 24m 37s\tremaining: 60s\n",
      "961:\tlearn: 0.0025503\ttotal: 24m 39s\tremaining: 58.4s\n",
      "962:\tlearn: 0.0025503\ttotal: 24m 40s\tremaining: 56.9s\n",
      "963:\tlearn: 0.0025503\ttotal: 24m 41s\tremaining: 55.3s\n",
      "964:\tlearn: 0.0025503\ttotal: 24m 42s\tremaining: 53.8s\n",
      "965:\tlearn: 0.0025503\ttotal: 24m 43s\tremaining: 52.2s\n",
      "966:\tlearn: 0.0025503\ttotal: 24m 44s\tremaining: 50.7s\n",
      "967:\tlearn: 0.0025503\ttotal: 24m 45s\tremaining: 49.1s\n",
      "968:\tlearn: 0.0025503\ttotal: 24m 46s\tremaining: 47.6s\n",
      "969:\tlearn: 0.0025503\ttotal: 24m 47s\tremaining: 46s\n",
      "970:\tlearn: 0.0025503\ttotal: 24m 48s\tremaining: 44.5s\n",
      "971:\tlearn: 0.0025503\ttotal: 24m 49s\tremaining: 42.9s\n",
      "972:\tlearn: 0.0025503\ttotal: 24m 50s\tremaining: 41.4s\n",
      "973:\tlearn: 0.0025503\ttotal: 24m 51s\tremaining: 39.8s\n",
      "974:\tlearn: 0.0025502\ttotal: 24m 53s\tremaining: 38.3s\n",
      "975:\tlearn: 0.0025502\ttotal: 24m 54s\tremaining: 36.7s\n",
      "976:\tlearn: 0.0025502\ttotal: 24m 55s\tremaining: 35.2s\n",
      "977:\tlearn: 0.0025502\ttotal: 24m 56s\tremaining: 33.7s\n",
      "978:\tlearn: 0.0025502\ttotal: 24m 57s\tremaining: 32.1s\n",
      "979:\tlearn: 0.0025502\ttotal: 24m 58s\tremaining: 30.6s\n",
      "980:\tlearn: 0.0025502\ttotal: 24m 59s\tremaining: 29s\n",
      "981:\tlearn: 0.0025502\ttotal: 25m 1s\tremaining: 27.5s\n",
      "982:\tlearn: 0.0025502\ttotal: 25m 2s\tremaining: 26s\n",
      "983:\tlearn: 0.0025502\ttotal: 25m 3s\tremaining: 24.4s\n",
      "984:\tlearn: 0.0025502\ttotal: 25m 4s\tremaining: 22.9s\n",
      "985:\tlearn: 0.0025502\ttotal: 25m 5s\tremaining: 21.4s\n",
      "986:\tlearn: 0.0025502\ttotal: 25m 7s\tremaining: 19.9s\n",
      "987:\tlearn: 0.0025454\ttotal: 25m 8s\tremaining: 18.3s\n",
      "988:\tlearn: 0.0025454\ttotal: 25m 9s\tremaining: 16.8s\n",
      "989:\tlearn: 0.0025454\ttotal: 25m 11s\tremaining: 15.3s\n",
      "990:\tlearn: 0.0025454\ttotal: 25m 12s\tremaining: 13.7s\n",
      "991:\tlearn: 0.0025454\ttotal: 25m 13s\tremaining: 12.2s\n",
      "992:\tlearn: 0.0025454\ttotal: 25m 14s\tremaining: 10.7s\n",
      "993:\tlearn: 0.0025454\ttotal: 25m 15s\tremaining: 9.15s\n",
      "994:\tlearn: 0.0025454\ttotal: 25m 17s\tremaining: 7.62s\n",
      "995:\tlearn: 0.0025454\ttotal: 25m 18s\tremaining: 6.1s\n",
      "996:\tlearn: 0.0025454\ttotal: 25m 19s\tremaining: 4.57s\n",
      "997:\tlearn: 0.0025454\ttotal: 25m 20s\tremaining: 3.05s\n",
      "998:\tlearn: 0.0025454\ttotal: 25m 21s\tremaining: 1.52s\n",
      "999:\tlearn: 0.0025454\ttotal: 25m 23s\tremaining: 0us\n",
      "Accuracy CatBoost: 0.9548585931834663\n",
      "Confusion Matrix:\n",
      "[[2616  142]\n",
      " [ 107 2651]]\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "from catboost import CatBoostClassifier #pip install catboost\n",
    "\n",
    "params = OrderedDict([('bagging_temperature', 1.0), ('border_count', 148), ('depth', 13), ('iterations', 976), ('l2_leaf_reg', 30), ('learning_rate', 0.02389354323083735), ('random_strength', 1e-09), ('scale_pos_weight', 0.9510644977326121)])\n",
    "params['iterations'] = 1000\n",
    "\n",
    "params2 = OrderedDict([('bagging_temperature', 1.0), ('border_count', 86), ('depth', 16), ('iterations', 868), ('l2_leaf_reg', 2), ('learning_rate', 0.06598200301644333), ('random_strength', 10.0), ('scale_pos_weight', 0.8384915263866678)])\n",
    "params2['iterations'] = 1000\n",
    "cb = CatBoostClassifier(**params2)\n",
    "cb.fit(X_train_dummy, y_train_dummy['final_result'])\n",
    "\n",
    "y_pred = cb.predict(X_test_dummy)\n",
    "acc = accuracy_score(y_test_dummy['final_result'], y_pred)\n",
    "print('Accuracy CatBoost:', acc)\n",
    "cm = confusion_matrix(y_test_dummy['final_result'], y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Feature  Importance\n",
      "0       highest_education    0.061120\n",
      "1           module_length    0.060531\n",
      "2       date_registration    0.059365\n",
      "3                gender_F    0.058858\n",
      "4                imd_band    0.056869\n",
      "5                gender_M    0.055753\n",
      "6             days_logged    0.052925\n",
      "7  % material interaction    0.040333\n",
      "8  studied_credits_binned    0.038496\n",
      "9          mean_sum_click    0.035681\n"
     ]
    }
   ],
   "source": [
    "# Get feature importance\n",
    "feature_importances = cb.get_feature_importance()\n",
    "\n",
    "# Get feature names\n",
    "feature_names = X_train_dummy.columns\n",
    "\n",
    "# Create a DataFrame for easier visualization\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': feature_importances\n",
    "})\n",
    "\n",
    "# Sort the DataFrame by importance in descending order\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "# print(importance_df)\n",
    "\n",
    "importance_df['Importance'] /= importance_df['Importance'].sum()\n",
    "importance_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Get the top 10 features\n",
    "top_10_features = importance_df.head(10)\n",
    "\n",
    "print(top_10_features.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy CatBoost: 0.9501450326323423\n",
      "Confusion Matrix:\n",
      "[[2556  202]\n",
      " [  73 2685]]\n"
     ]
    }
   ],
   "source": [
    "cb_plain = CatBoostClassifier(verbose=False)\n",
    "cb_plain.fit(X_train_dummy, y_train_dummy['final_result'])\n",
    "\n",
    "y_pred = cb_plain.predict(X_test_dummy)\n",
    "acc = accuracy_score(y_test_dummy['final_result'], y_pred)\n",
    "print('Accuracy CatBoost:', acc)\n",
    "cm = confusion_matrix(y_test_dummy['final_result'], y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_pred = cb_plain.predict(X_test_dummy)\n",
    "cm = confusion_matrix(y_test_dummy['final_result'], y_pred)\n",
    "plt.figure(figsize=(2,1))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9491586108127461\n",
      "Recall: 0.9612037708484409\n",
      "F1 Score: 0.9551432174382994\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "precision = precision_score(y_test_dummy['final_result'], y_pred)\n",
    "print('Precision:', precision)\n",
    "\n",
    "# Recall\n",
    "recall = recall_score(y_test_dummy['final_result'], y_pred)\n",
    "print('Recall:', recall)\n",
    "\n",
    "# F1 Score\n",
    "f1 = f1_score(y_test_dummy['final_result'], y_pred)\n",
    "print('F1 Score:', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Random Forest: 0.9390018484288355\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train_dummy, y_train_dummy['final_result'])\n",
    "\n",
    "y_pred = rf.predict(X_test_dummy)\n",
    "acc = accuracy_score(y_test_dummy['final_result'], y_pred)\n",
    "print('Accuracy Random Forest:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "categories = ['code_module', 'code_presentation', 'gender', 'region']\n",
    "numerical_features = [col for col in X_train_ord.columns if col not in categories]\n",
    "\n",
    "X_train_dummy = scaler.fit_transform(X_train_dummy)\n",
    "X_test_dummy = scaler.fit_transform(X_test_dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>final_result</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19901</th>\n",
       "      <td>0</td>\n",
       "      <td>77.718532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14299</th>\n",
       "      <td>1</td>\n",
       "      <td>84.191919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25453</th>\n",
       "      <td>0</td>\n",
       "      <td>84.567035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6573</th>\n",
       "      <td>1</td>\n",
       "      <td>85.348315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11571</th>\n",
       "      <td>0</td>\n",
       "      <td>67.857143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       final_result      score\n",
       "19901             0  77.718532\n",
       "14299             1  84.191919\n",
       "25453             0  84.567035\n",
       "6573              1  85.348315\n",
       "11571             0  67.857143"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_dummy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "552/552 [==============================] - ETA: 0s - loss: 1537.8672 - accuracy: 5.6664e-05\n",
      "Epoch 1: val_loss improved from inf to 852.74023, saving model to model.h5\n",
      "552/552 [==============================] - 21s 34ms/step - loss: 1537.8672 - accuracy: 5.6664e-05 - val_loss: 852.7402 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/15\n",
      "  1/552 [..............................] - ETA: 37s - loss: 228.1072 - accuracy: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning:\n",
      "\n",
      "You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "552/552 [==============================] - ETA: 0s - loss: 282.1672 - accuracy: 0.0000e+00\n",
      "Epoch 2: val_loss improved from 852.74023 to 546.18390, saving model to model.h5\n",
      "552/552 [==============================] - 19s 34ms/step - loss: 282.1672 - accuracy: 0.0000e+00 - val_loss: 546.1839 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/15\n",
      "552/552 [==============================] - ETA: 0s - loss: 247.5201 - accuracy: 0.0000e+00\n",
      "Epoch 3: val_loss improved from 546.18390 to 252.40540, saving model to model.h5\n",
      "552/552 [==============================] - 18s 33ms/step - loss: 247.5201 - accuracy: 0.0000e+00 - val_loss: 252.4054 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/15\n",
      "552/552 [==============================] - ETA: 0s - loss: 228.3687 - accuracy: 0.0000e+00\n",
      "Epoch 4: val_loss improved from 252.40540 to 227.16821, saving model to model.h5\n",
      "552/552 [==============================] - 18s 33ms/step - loss: 228.3687 - accuracy: 0.0000e+00 - val_loss: 227.1682 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/15\n",
      "552/552 [==============================] - ETA: 0s - loss: 213.5660 - accuracy: 0.0000e+00\n",
      "Epoch 5: val_loss did not improve from 227.16821\n",
      "552/552 [==============================] - 19s 34ms/step - loss: 213.5660 - accuracy: 0.0000e+00 - val_loss: 494.8986 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/15\n",
      "552/552 [==============================] - ETA: 0s - loss: 208.0236 - accuracy: 0.0000e+00\n",
      "Epoch 6: val_loss did not improve from 227.16821\n",
      "552/552 [==============================] - 18s 32ms/step - loss: 208.0236 - accuracy: 0.0000e+00 - val_loss: 315.5139 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/15\n",
      "552/552 [==============================] - ETA: 0s - loss: 198.8213 - accuracy: 0.0000e+00\n",
      "Epoch 7: val_loss did not improve from 227.16821\n",
      "552/552 [==============================] - 18s 32ms/step - loss: 198.8213 - accuracy: 0.0000e+00 - val_loss: 305.9904 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/15\n",
      "551/552 [============================>.] - ETA: 0s - loss: 196.6321 - accuracy: 0.0000e+00\n",
      "Epoch 8: val_loss improved from 227.16821 to 192.71094, saving model to model.h5\n",
      "552/552 [==============================] - 18s 33ms/step - loss: 196.5892 - accuracy: 0.0000e+00 - val_loss: 192.7109 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/15\n",
      "552/552 [==============================] - ETA: 0s - loss: 187.4692 - accuracy: 0.0000e+00\n",
      "Epoch 9: val_loss did not improve from 192.71094\n",
      "552/552 [==============================] - 18s 33ms/step - loss: 187.4692 - accuracy: 0.0000e+00 - val_loss: 276.5421 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/15\n",
      "552/552 [==============================] - ETA: 0s - loss: 185.3883 - accuracy: 0.0000e+00\n",
      "Epoch 10: val_loss improved from 192.71094 to 173.03191, saving model to model.h5\n",
      "552/552 [==============================] - 18s 32ms/step - loss: 185.3883 - accuracy: 0.0000e+00 - val_loss: 173.0319 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/15\n",
      "552/552 [==============================] - ETA: 0s - loss: 183.9128 - accuracy: 0.0000e+00\n",
      "Epoch 11: val_loss did not improve from 173.03191\n",
      "552/552 [==============================] - 18s 33ms/step - loss: 183.9128 - accuracy: 0.0000e+00 - val_loss: 202.3259 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/15\n",
      "551/552 [============================>.] - ETA: 0s - loss: 178.8673 - accuracy: 0.0000e+00\n",
      "Epoch 12: val_loss did not improve from 173.03191\n",
      "552/552 [==============================] - 18s 33ms/step - loss: 178.9994 - accuracy: 0.0000e+00 - val_loss: 200.6029 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/15\n",
      "551/552 [============================>.] - ETA: 0s - loss: 179.5239 - accuracy: 0.0000e+00\n",
      "Epoch 13: val_loss did not improve from 173.03191\n",
      "552/552 [==============================] - 18s 32ms/step - loss: 179.5360 - accuracy: 0.0000e+00 - val_loss: 286.9423 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/15\n",
      "551/552 [============================>.] - ETA: 0s - loss: 177.5132 - accuracy: 0.0000e+00\n",
      "Epoch 14: val_loss did not improve from 173.03191\n",
      "552/552 [==============================] - 18s 33ms/step - loss: 177.4612 - accuracy: 0.0000e+00 - val_loss: 448.7893 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/15\n",
      "552/552 [==============================] - ETA: 0s - loss: 173.0132 - accuracy: 0.0000e+00\n",
      "Epoch 15: val_loss did not improve from 173.03191\n",
      "552/552 [==============================] - 18s 32ms/step - loss: 173.0132 - accuracy: 0.0000e+00 - val_loss: 306.4607 - val_accuracy: 0.0000e+00\n",
      "predicting\n",
      "690/690 [==============================] - 3s 4ms/step\n",
      "misclassifying\n",
      "Epoch 1/30\n",
      "194/195 [============================>.] - ETA: 0s - loss: 218.8950 - accuracy: 0.0000e+00\n",
      "Epoch 1: val_loss improved from inf to 297.63657, saving model to model2.h5\n",
      "195/195 [==============================] - 8s 33ms/step - loss: 218.7919 - accuracy: 0.0000e+00 - val_loss: 297.6366 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/30\n",
      "  3/195 [..............................] - ETA: 6s - loss: 134.3383 - accuracy: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning:\n",
      "\n",
      "You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195/195 [==============================] - ETA: 0s - loss: 215.1295 - accuracy: 0.0000e+00\n",
      "Epoch 2: val_loss improved from 297.63657 to 267.74973, saving model to model2.h5\n",
      "195/195 [==============================] - 6s 32ms/step - loss: 215.1295 - accuracy: 0.0000e+00 - val_loss: 267.7497 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/30\n",
      "195/195 [==============================] - ETA: 0s - loss: 215.3079 - accuracy: 0.0000e+00\n",
      "Epoch 3: val_loss did not improve from 267.74973\n",
      "195/195 [==============================] - 8s 40ms/step - loss: 215.3079 - accuracy: 0.0000e+00 - val_loss: 525.0049 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/30\n",
      "195/195 [==============================] - ETA: 0s - loss: 218.8660 - accuracy: 0.0000e+00\n",
      "Epoch 4: val_loss did not improve from 267.74973\n",
      "195/195 [==============================] - 6s 32ms/step - loss: 218.8660 - accuracy: 0.0000e+00 - val_loss: 649.2940 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/30\n",
      "193/195 [============================>.] - ETA: 0s - loss: 210.4950 - accuracy: 0.0000e+00\n",
      "Epoch 5: val_loss did not improve from 267.74973\n",
      "195/195 [==============================] - 7s 35ms/step - loss: 211.3334 - accuracy: 0.0000e+00 - val_loss: 782.3457 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/30\n",
      "195/195 [==============================] - ETA: 0s - loss: 207.6796 - accuracy: 0.0000e+00\n",
      "Epoch 6: val_loss did not improve from 267.74973\n",
      "195/195 [==============================] - 7s 33ms/step - loss: 207.6796 - accuracy: 0.0000e+00 - val_loss: 340.7982 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/30\n",
      "195/195 [==============================] - ETA: 0s - loss: 208.1652 - accuracy: 0.0000e+00\n",
      "Epoch 7: val_loss did not improve from 267.74973\n",
      "195/195 [==============================] - 6s 33ms/step - loss: 208.1652 - accuracy: 0.0000e+00 - val_loss: 480.9023 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/30\n",
      "195/195 [==============================] - ETA: 0s - loss: 206.2361 - accuracy: 0.0000e+00\n",
      "Epoch 8: val_loss improved from 267.74973 to 179.59695, saving model to model2.h5\n",
      "195/195 [==============================] - 6s 32ms/step - loss: 206.2361 - accuracy: 0.0000e+00 - val_loss: 179.5970 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/30\n",
      "195/195 [==============================] - ETA: 0s - loss: 213.9671 - accuracy: 0.0000e+00\n",
      "Epoch 9: val_loss did not improve from 179.59695\n",
      "195/195 [==============================] - 6s 32ms/step - loss: 213.9671 - accuracy: 0.0000e+00 - val_loss: 728.8027 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/30\n",
      "194/195 [============================>.] - ETA: 0s - loss: 197.7202 - accuracy: 0.0000e+00\n",
      "Epoch 10: val_loss improved from 179.59695 to 174.60555, saving model to model2.h5\n",
      "195/195 [==============================] - 7s 33ms/step - loss: 198.1538 - accuracy: 0.0000e+00 - val_loss: 174.6055 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/30\n",
      "195/195 [==============================] - ETA: 0s - loss: 206.4892 - accuracy: 0.0000e+00\n",
      "Epoch 11: val_loss did not improve from 174.60555\n",
      "195/195 [==============================] - 6s 32ms/step - loss: 206.4892 - accuracy: 0.0000e+00 - val_loss: 309.8476 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/30\n",
      "194/195 [============================>.] - ETA: 0s - loss: 205.5403 - accuracy: 0.0000e+00\n",
      "Epoch 12: val_loss did not improve from 174.60555\n",
      "195/195 [==============================] - 6s 33ms/step - loss: 205.9323 - accuracy: 0.0000e+00 - val_loss: 247.6525 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/30\n",
      "194/195 [============================>.] - ETA: 0s - loss: 207.6921 - accuracy: 0.0000e+00\n",
      "Epoch 13: val_loss did not improve from 174.60555\n",
      "195/195 [==============================] - 6s 31ms/step - loss: 207.8302 - accuracy: 0.0000e+00 - val_loss: 265.6219 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/30\n",
      "195/195 [==============================] - ETA: 0s - loss: 212.6360 - accuracy: 0.0000e+00\n",
      "Epoch 14: val_loss did not improve from 174.60555\n",
      "195/195 [==============================] - 6s 32ms/step - loss: 212.6360 - accuracy: 0.0000e+00 - val_loss: 253.7270 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/30\n",
      "194/195 [============================>.] - ETA: 0s - loss: 204.0479 - accuracy: 0.0000e+00\n",
      "Epoch 15: val_loss did not improve from 174.60555\n",
      "195/195 [==============================] - 6s 30ms/step - loss: 204.2456 - accuracy: 0.0000e+00 - val_loss: 317.4704 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/30\n",
      "195/195 [==============================] - ETA: 0s - loss: 208.2996 - accuracy: 0.0000e+00\n",
      "Epoch 16: val_loss did not improve from 174.60555\n",
      "195/195 [==============================] - 6s 30ms/step - loss: 208.2996 - accuracy: 0.0000e+00 - val_loss: 561.2345 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/30\n",
      "194/195 [============================>.] - ETA: 0s - loss: 209.1407 - accuracy: 0.0000e+00\n",
      "Epoch 17: val_loss did not improve from 174.60555\n",
      "195/195 [==============================] - 6s 30ms/step - loss: 208.7141 - accuracy: 0.0000e+00 - val_loss: 322.2773 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/30\n",
      "193/195 [============================>.] - ETA: 0s - loss: 199.8286 - accuracy: 0.0000e+00\n",
      "Epoch 18: val_loss did not improve from 174.60555\n",
      "195/195 [==============================] - 6s 31ms/step - loss: 199.2792 - accuracy: 0.0000e+00 - val_loss: 291.5620 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/30\n",
      "195/195 [==============================] - ETA: 0s - loss: 204.8348 - accuracy: 0.0000e+00\n",
      "Epoch 19: val_loss did not improve from 174.60555\n",
      "195/195 [==============================] - 6s 31ms/step - loss: 204.8348 - accuracy: 0.0000e+00 - val_loss: 295.8528 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/30\n",
      "195/195 [==============================] - ETA: 0s - loss: 199.0448 - accuracy: 0.0000e+00\n",
      "Epoch 20: val_loss did not improve from 174.60555\n",
      "195/195 [==============================] - 7s 36ms/step - loss: 199.0448 - accuracy: 0.0000e+00 - val_loss: 493.1607 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/30\n",
      "194/195 [============================>.] - ETA: 0s - loss: 210.4128 - accuracy: 0.0000e+00\n",
      "Epoch 21: val_loss did not improve from 174.60555\n",
      "195/195 [==============================] - 7s 34ms/step - loss: 210.3421 - accuracy: 0.0000e+00 - val_loss: 337.7057 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/30\n",
      "195/195 [==============================] - ETA: 0s - loss: 200.9698 - accuracy: 0.0000e+00\n",
      "Epoch 22: val_loss did not improve from 174.60555\n",
      "195/195 [==============================] - 7s 34ms/step - loss: 200.9698 - accuracy: 0.0000e+00 - val_loss: 202.7048 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/30\n",
      "194/195 [============================>.] - ETA: 0s - loss: 202.6864 - accuracy: 0.0000e+00\n",
      "Epoch 23: val_loss did not improve from 174.60555\n",
      "195/195 [==============================] - 7s 37ms/step - loss: 203.0786 - accuracy: 0.0000e+00 - val_loss: 325.2585 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/30\n",
      "194/195 [============================>.] - ETA: 0s - loss: 202.7724 - accuracy: 0.0000e+00\n",
      "Epoch 24: val_loss did not improve from 174.60555\n",
      "195/195 [==============================] - 6s 32ms/step - loss: 203.3357 - accuracy: 0.0000e+00 - val_loss: 435.5493 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/30\n",
      "194/195 [============================>.] - ETA: 0s - loss: 197.0051 - accuracy: 0.0000e+00\n",
      "Epoch 25: val_loss did not improve from 174.60555\n",
      "195/195 [==============================] - 7s 34ms/step - loss: 197.1356 - accuracy: 0.0000e+00 - val_loss: 259.9637 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/30\n",
      "194/195 [============================>.] - ETA: 0s - loss: 203.9934 - accuracy: 0.0000e+00\n",
      "Epoch 26: val_loss did not improve from 174.60555\n",
      "195/195 [==============================] - 6s 31ms/step - loss: 203.6659 - accuracy: 0.0000e+00 - val_loss: 383.2755 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/30\n",
      "194/195 [============================>.] - ETA: 0s - loss: 200.2221 - accuracy: 0.0000e+00\n",
      "Epoch 27: val_loss did not improve from 174.60555\n",
      "195/195 [==============================] - 6s 31ms/step - loss: 200.1658 - accuracy: 0.0000e+00 - val_loss: 188.3948 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/30\n",
      "195/195 [==============================] - ETA: 0s - loss: 198.1328 - accuracy: 0.0000e+00\n",
      "Epoch 28: val_loss did not improve from 174.60555\n",
      "195/195 [==============================] - 6s 32ms/step - loss: 198.1328 - accuracy: 0.0000e+00 - val_loss: 297.0876 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/30\n",
      "193/195 [============================>.] - ETA: 0s - loss: 197.4664 - accuracy: 0.0000e+00\n",
      "Epoch 29: val_loss did not improve from 174.60555\n",
      "195/195 [==============================] - 6s 30ms/step - loss: 197.3876 - accuracy: 0.0000e+00 - val_loss: 370.4499 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/30\n",
      "194/195 [============================>.] - ETA: 0s - loss: 200.1163 - accuracy: 0.0000e+00\n",
      "Epoch 30: val_loss did not improve from 174.60555\n",
      "195/195 [==============================] - 6s 32ms/step - loss: 200.2922 - accuracy: 0.0000e+00 - val_loss: 501.4165 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2b87be490>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dropout, Input, Dense, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import tensorflow as tf\n",
    "\n",
    "X_train_dummy_np = X_train_dummy.astype('float32')\n",
    "y_train_dummy_np = y_train_dummy.drop(columns=['final_result']).astype('float32')\n",
    "\n",
    "input_layer = Input(shape=(X_train_dummy.shape[1],))\n",
    "\n",
    "dense = Dense(128, kernel_initializer=tf.keras.initializers.HeNormal(), kernel_regularizer=l2(0.01))(input_layer)\n",
    "dense = BatchNormalization()(dense)\n",
    "dense = tf.keras.activations.relu(dense)\n",
    "dense = Dropout(0.2)(dense)\n",
    "\n",
    "dense = Dense(128, kernel_initializer=tf.keras.initializers.HeNormal(), kernel_regularizer=l2(0.01))(dense)\n",
    "dense = BatchNormalization()(dense)\n",
    "dense = tf.keras.activations.relu(dense)\n",
    "dense = Dropout(0.2)(dense)\n",
    "\n",
    "dense = Dense(128, kernel_initializer=tf.keras.initializers.HeNormal(), kernel_regularizer=l2(0.01))(dense)\n",
    "dense = BatchNormalization()(dense)\n",
    "dense = tf.keras.activations.relu(dense)\n",
    "dense = Dropout(0.2)(dense)\n",
    "\n",
    "output = Dense(1, activation='linear')(dense)\n",
    "\n",
    "model = tf.keras.models.Model(inputs=input_layer, outputs=output)\n",
    "model2 = tf.keras.models.Model(inputs=input_layer, outputs=output)\n",
    "\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='model.h5',\n",
    "    monitor='val_loss',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    mode='min'\n",
    ")\n",
    "checkpoint2 = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='model2.h5',\n",
    "    monitor='val_loss',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "model2.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "hist = model.fit(X_train_dummy_np, y_train_dummy_np, epochs=15, batch_size=32, validation_split=0.2, callbacks=[checkpoint])\n",
    "\n",
    "#misclassified from the first\n",
    "print(\"predicting\")\n",
    "preds1 = model.predict(X_train_dummy_np)\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_train_dummy['final_result'], preds1)\n",
    "best_threshold = thresholds[np.argmax(precisions + recalls)]\n",
    "print(\"misclassifying\")\n",
    "\n",
    "predictions_classified = [1 if y >= best_threshold else 0 for y in preds1.flatten()]\n",
    "# y_train_dummy_binary = [1 if y >= 50 else 0 for y in y_train_dummy['score']]\n",
    "np.random.seed(0)\n",
    "misclassified = np.array(predictions_classified) != np.array(y_train_dummy['final_result'])\n",
    "misclassified_indices = np.where(misclassified)[0]\n",
    "correct_indices = np.where(~misclassified)[0]\n",
    "random_correct_indices = np.random.choice (correct_indices, size=int(len(misclassified_indices)*2), replace=False)\n",
    "training_indices = np.concatenate([misclassified_indices, random_correct_indices])\n",
    "X_train2 = X_train_dummy_np.iloc[training_indices]\n",
    "y_train2 = y_train_dummy_np.iloc[training_indices]\n",
    "\n",
    "model2.fit(X_train2, y_train2, epochs=30, batch_size=32, validation_split=0.2, callbacks=[checkpoint2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173/173 [==============================] - 1s 4ms/step\n",
      "best threshold 55.03595\n",
      "5516\n",
      "acc1 0.898658448150834\n",
      "Confusion Matrix1:\n",
      "[[2320  438]\n",
      " [ 121 2637]]\n",
      "173/173 [==============================] - 1s 4ms/step\n",
      "Best ratio 0.1 Best score 0.9254894851341552\n",
      "Accuracy 0.9254894851341552\n",
      "Confusion Matrix:\n",
      "[[2443  315]\n",
      " [  96 2662]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_recall_curve\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "best_model1 = load_model('model.h5')\n",
    "best_model2 = load_model('model2.h5')\n",
    "\n",
    "X_test_dummy_np = X_test_dummy.astype('float32')\n",
    "\n",
    "preds1 = best_model1.predict(X_test_dummy_np)\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_test_dummy['final_result'], preds1)\n",
    "best_threshold = thresholds[np.argmax(precisions + recalls)]\n",
    "\n",
    "print('best threshold', best_threshold)\n",
    "\n",
    "predictions_classified1 = []\n",
    "for i, pred in enumerate(preds1):\n",
    "#     print(i, pred)\n",
    "    if (pred >= best_threshold):\n",
    "        predictions_classified1.append(1)\n",
    "    else:\n",
    "        predictions_classified1.append(0)\n",
    "print(len(predictions_classified1))\n",
    "\n",
    "acc = accuracy_score(y_test_dummy['final_result'], predictions_classified1)\n",
    "print(\"acc1\", acc)\n",
    "cm = confusion_matrix(y_test_dummy['final_result'], predictions_classified1)\n",
    "\n",
    "print(\"Confusion Matrix1:\")\n",
    "print(cm)\n",
    "positive_preds = np.array(predictions_classified1) == 1\n",
    "\n",
    "preds2 = best_model2.predict(X_test_dummy_np)\n",
    "\n",
    "best_ratio = 0\n",
    "best_score = 0\n",
    "\n",
    "for i in range(0, 101):\n",
    "    ratio = i/100\n",
    "    average_preds = (preds1 * ratio) + (preds2 * (1 - ratio))\n",
    "    precisions, recalls, thresholds = precision_recall_curve(y_test_dummy['final_result'], average_preds)\n",
    "    best_threshold = thresholds[np.argmax(precisions + recalls)]\n",
    "    final_preds_classified = [1 if y >= best_threshold else 0 for y in average_preds.flatten()]\n",
    "    acc = accuracy_score(y_test_dummy['final_result'], final_preds_classified)\n",
    "    if acc > best_score:\n",
    "        best_score = acc\n",
    "        best_ratio = ratio\n",
    "\n",
    "print(\"Best ratio\", best_ratio, \"Best score\", best_score)\n",
    "\n",
    "average_preds = (preds1 * best_ratio) + (preds2 * (1 - best_ratio))\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_test_dummy['final_result'], average_preds)\n",
    "best_threshold = thresholds[np.argmax(precisions + recalls)]\n",
    "final_preds_classified = [1 if y >= best_threshold else 0 for y in average_preds.flatten()]\n",
    "\n",
    "acc = accuracy_score(y_test_dummy['final_result'], final_preds_classified)\n",
    "print(\"Accuracy\", acc)\n",
    "\n",
    "cm = confusion_matrix(y_test_dummy['final_result'], final_preds_classified)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "690/690 [==============================] - 3s 5ms/step\n",
      "690/690 [==============================] - 3s 4ms/step\n",
      "Accuracy 0.9252946509519492\n",
      "Confusion Matrix:\n",
      "[[ 9694  1336]\n",
      " [  312 10718]]\n"
     ]
    }
   ],
   "source": [
    "preds1_train = best_model1.predict(X_train_dummy_np)\n",
    "preds2_train = best_model2.predict(X_train_dummy_np)\n",
    "\n",
    "average_preds_train = (preds1_train * best_ratio) + (preds2_train * (1 - best_ratio))\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_train_dummy['final_result'], average_preds_train)\n",
    "best_threshold = thresholds[np.argmax(precisions + recalls)]\n",
    "final_preds_classified_train = [1 if y >= best_threshold else 0 for y in average_preds_train.flatten()]\n",
    "\n",
    "acc = accuracy_score(y_train_dummy['final_result'], final_preds_classified_train)\n",
    "print(\"Accuracy\", acc)\n",
    "\n",
    "cm = confusion_matrix(y_train_dummy['final_result'], final_preds_classified_train)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DO NOT RUN, TAKES FOREVER, OPTIMAL PARAMS PRINTED BELOW\n",
    "\n",
    "from skopt import BayesSearchCV #pip install scikit-optimize\n",
    "\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, BatchNormalization, Dropout\n",
    "from joblib import parallel_backend\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "def create_model(neurons, dropout_rate, num_layers, learning_rate):\n",
    "    input_layer = Input(shape=(X_train_dummy.shape[1],))\n",
    "\n",
    "    dense = Dense(neurons, kernel_initializer=tf.keras.initializers.HeNormal())(input_layer)\n",
    "    dense = BatchNormalization()(dense)\n",
    "    dense = tf.keras.activations.relu(dense)\n",
    "    dense = Dropout(dropout_rate)(dense)\n",
    "    \n",
    "    for i in range(num_layers - 1):\n",
    "        dense = Dense(neurons, kernel_initializer=tf.keras.initializers.HeNormal())(dense)\n",
    "        dense = BatchNormalization()(dense)\n",
    "        dense = tf.keras.activations.relu(dense)\n",
    "        dense = Dropout(dropout_rate)(dense)\n",
    "\n",
    "    output = Dense(1, activation='sigmoid')(dense)\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs=input_layer, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "wrapped_create_model = KerasClassifier(build_fn=create_model, verbose=1, epochs=25)\n",
    "\n",
    "param_space = {\n",
    "    'neurons': (8, 512),\n",
    "    'dropout_rate': (0.1, 0.5),\n",
    "    'num_layers': (1, 5),\n",
    "    'learning_rate': (0.0001, 0.1)\n",
    "}\n",
    "\n",
    "opt = BayesSearchCV(\n",
    "    wrapped_create_model,\n",
    "    param_space,\n",
    "    n_iter=50,\n",
    "    cv=3,\n",
    "    n_jobs=1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "opt.fit(X_train_dummy, y_train_dummy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = opt.best_params_\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_parameters = opt.best_params_\n",
    "\n",
    "optimal_model = create_model(\n",
    "    neurons=optimal_parameters['neurons'],\n",
    "    dropout_rate=optimal_parameters['dropout_rate'],\n",
    "    num_layers=optimal_parameters['num_layers'],\n",
    "    learning_rate=optimal_parameters['learning_rate']\n",
    ")\n",
    "\n",
    "history = optimal_model.fit(X_train_dummy, y_train_dummy, epochs=30, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = optimal_model.evaluate(X_test_dummy, y_test_dummy)\n",
    "print(\"Accuracy (tuned model):\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
