{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1z/_j8y7ndj06788g4f84n47dqm0000gn/T/ipykernel_1288/3524870665.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code_module</th>\n",
       "      <th>code_presentation</th>\n",
       "      <th>id_student</th>\n",
       "      <th>gender</th>\n",
       "      <th>region</th>\n",
       "      <th>highest_education</th>\n",
       "      <th>imd_band</th>\n",
       "      <th>age_band</th>\n",
       "      <th>num_of_prev_attempts</th>\n",
       "      <th>studied_credits</th>\n",
       "      <th>disability</th>\n",
       "      <th>final_result</th>\n",
       "      <th>score</th>\n",
       "      <th>grade</th>\n",
       "      <th>studied_credits_binned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAA</td>\n",
       "      <td>2013J</td>\n",
       "      <td>11391</td>\n",
       "      <td>M</td>\n",
       "      <td>East Anglian Region</td>\n",
       "      <td>HE Qualification</td>\n",
       "      <td>90-100%</td>\n",
       "      <td>55&lt;=</td>\n",
       "      <td>0</td>\n",
       "      <td>240</td>\n",
       "      <td>N</td>\n",
       "      <td>Pass</td>\n",
       "      <td>82.4</td>\n",
       "      <td>A-</td>\n",
       "      <td>201+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAA</td>\n",
       "      <td>2013J</td>\n",
       "      <td>28400</td>\n",
       "      <td>F</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>HE Qualification</td>\n",
       "      <td>20-30%</td>\n",
       "      <td>35-55</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>N</td>\n",
       "      <td>Pass</td>\n",
       "      <td>65.4</td>\n",
       "      <td>C</td>\n",
       "      <td>30-60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAA</td>\n",
       "      <td>2013J</td>\n",
       "      <td>31604</td>\n",
       "      <td>F</td>\n",
       "      <td>South East Region</td>\n",
       "      <td>A Level or Equivalent</td>\n",
       "      <td>50-60%</td>\n",
       "      <td>35-55</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>N</td>\n",
       "      <td>Pass</td>\n",
       "      <td>76.3</td>\n",
       "      <td>B</td>\n",
       "      <td>30-60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAA</td>\n",
       "      <td>2013J</td>\n",
       "      <td>32885</td>\n",
       "      <td>F</td>\n",
       "      <td>West Midlands Region</td>\n",
       "      <td>Lower Than A Level</td>\n",
       "      <td>50-60%</td>\n",
       "      <td>0-35</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>N</td>\n",
       "      <td>Pass</td>\n",
       "      <td>55.0</td>\n",
       "      <td>D</td>\n",
       "      <td>30-60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAA</td>\n",
       "      <td>2013J</td>\n",
       "      <td>38053</td>\n",
       "      <td>M</td>\n",
       "      <td>Wales</td>\n",
       "      <td>A Level or Equivalent</td>\n",
       "      <td>80-90%</td>\n",
       "      <td>35-55</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>N</td>\n",
       "      <td>Pass</td>\n",
       "      <td>66.9</td>\n",
       "      <td>C</td>\n",
       "      <td>30-60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  code_module code_presentation  id_student gender                region  \\\n",
       "0         AAA             2013J       11391      M   East Anglian Region   \n",
       "1         AAA             2013J       28400      F              Scotland   \n",
       "2         AAA             2013J       31604      F     South East Region   \n",
       "3         AAA             2013J       32885      F  West Midlands Region   \n",
       "4         AAA             2013J       38053      M                 Wales   \n",
       "\n",
       "       highest_education imd_band age_band  num_of_prev_attempts  \\\n",
       "0       HE Qualification  90-100%     55<=                     0   \n",
       "1       HE Qualification   20-30%    35-55                     0   \n",
       "2  A Level or Equivalent   50-60%    35-55                     0   \n",
       "3     Lower Than A Level   50-60%     0-35                     0   \n",
       "4  A Level or Equivalent   80-90%    35-55                     0   \n",
       "\n",
       "   studied_credits disability final_result  score grade studied_credits_binned  \n",
       "0              240          N         Pass   82.4    A-                   201+  \n",
       "1               60          N         Pass   65.4     C                  30-60  \n",
       "2               60          N         Pass   76.3     B                  30-60  \n",
       "3               60          N         Pass   55.0     D                  30-60  \n",
       "4               60          N         Pass   66.9     C                  30-60  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('data/student_info_cleaned.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23731 entries, 0 to 23730\n",
      "Data columns (total 15 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   code_module             23731 non-null  object \n",
      " 1   code_presentation       23731 non-null  object \n",
      " 2   id_student              23731 non-null  int64  \n",
      " 3   gender                  23731 non-null  object \n",
      " 4   region                  23731 non-null  object \n",
      " 5   highest_education       23731 non-null  object \n",
      " 6   imd_band                22740 non-null  object \n",
      " 7   age_band                23731 non-null  object \n",
      " 8   num_of_prev_attempts    23731 non-null  int64  \n",
      " 9   studied_credits         23731 non-null  int64  \n",
      " 10  disability              23731 non-null  object \n",
      " 11  final_result            23731 non-null  object \n",
      " 12  score                   23731 non-null  float64\n",
      " 13  grade                   23731 non-null  object \n",
      " 14  studied_credits_binned  23731 non-null  object \n",
      "dtypes: float64(1), int64(3), object(11)\n",
      "memory usage: 2.7+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['final_result'].value_counts()\n",
    "#drop withdrawn students\n",
    "data = data[data['final_result'] != 'Withdrawn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#order highest_education, imd_band, age_band, disability, studied_credits_binned, final_result\n",
    "highest_education = {\n",
    "    'No Formal quals': 0,\n",
    "    'Lower Than A Level': 1,\n",
    "    'A Level or Equivalent': 2,\n",
    "    'HE Qualification': 3,\n",
    "    'Post Graduate Qualification': 4\n",
    "}\n",
    "\n",
    "imd_band = {\n",
    "    np.nan: -1,\n",
    "    '0-10%': 0,\n",
    "    '10-20': 1,\n",
    "    '20-30%': 2,\n",
    "    '30-40%': 3,\n",
    "    '40-50%': 4,\n",
    "    '50-60%': 5,\n",
    "    '60-70%': 6,\n",
    "    '70-80%': 7,\n",
    "    '80-90%': 8,\n",
    "    '90-100%': 9\n",
    "}\n",
    "\n",
    "age_band = {\n",
    "    '0-35': 0,\n",
    "    '35-55': 1,\n",
    "    '55<=': 2\n",
    "}\n",
    "\n",
    "disability = {\n",
    "    'N': 0,\n",
    "    'Y': 1\n",
    "}\n",
    "\n",
    "studied_credits_binned = {\n",
    "    '30-60': 0,\n",
    "    '61-100': 1,\n",
    "    '101-200': 2,\n",
    "    '201+': 3\n",
    "}\n",
    "\n",
    "final_result = {\n",
    "    'Fail': 0,\n",
    "    'Pass': 1,\n",
    "    'Distinction': 1,\n",
    "    'Withdrawn': 0\n",
    "}\n",
    "\n",
    "data_dummies = pd.get_dummies(data, columns=['code_module', 'code_presentation', 'gender', 'region'])\n",
    "data_dummies['highest_education'] = data_dummies['highest_education'].map(highest_education)\n",
    "data_dummies['imd_band'] = data_dummies['imd_band'].map(imd_band)\n",
    "data_dummies['age_band'] = data_dummies['age_band'].map(age_band)\n",
    "data_dummies['disability'] = data_dummies['disability'].map(disability)\n",
    "data_dummies['studied_credits_binned'] = data_dummies['studied_credits_binned'].map(studied_credits_binned)\n",
    "data_dummies['final_result'] = data_dummies['final_result'].map(final_result)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "data_ordinal = data.copy()\n",
    "data_ordinal['highest_education'] = data_dummies['highest_education']\n",
    "data_ordinal['imd_band'] = data_dummies['imd_band']\n",
    "data_ordinal['age_band'] = data_dummies['age_band']\n",
    "data_ordinal['disability'] = data_dummies['disability']\n",
    "data_ordinal['studied_credits_binned'] = data_dummies['studied_credits_binned']\n",
    "data_ordinal['final_result'] = data_dummies['final_result']\n",
    "\n",
    "le = LabelEncoder()\n",
    "data_ordinal['code_module'] = le.fit_transform(data_ordinal['code_module'])\n",
    "data_ordinal['code_presentation'] = le.fit_transform(data_ordinal['code_presentation'])\n",
    "data_ordinal['gender'] = le.fit_transform(data_ordinal['gender'])\n",
    "data_ordinal['region'] = le.fit_transform(data_ordinal['region'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "final_result\n",
       "1    13868\n",
       "0     5279\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dummies['final_result'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "\n",
    "X_dummy = data_dummies.drop(['final_result', 'studied_credits', 'id_student', 'score', 'grade'], axis=1)\n",
    "y_dummy = data_dummies['final_result']\n",
    "# X_dummy = scaler.fit_transform(X_dummy)\n",
    "\n",
    "X_ord = data_ordinal.drop(['final_result', 'studied_credits', 'id_student', 'score', 'grade'], axis=1)\n",
    "y_ord = data_ordinal['final_result']\n",
    "# X_ord = scaler.fit_transform(X_ord)\n",
    "\n",
    "smote = SMOTE(sampling_strategy='minority', random_state=42)\n",
    "X_dummy_smote, y_dummy_smote = smote.fit_resample(X_dummy, y_dummy)\n",
    "X_ord_smote, y_ord_smote = smote.fit_resample(X_ord, y_ord)\n",
    "\n",
    "X_train_dummy, X_test_dummy, y_train_dummy, y_test_dummy = train_test_split(X_dummy_smote, y_dummy_smote, test_size=0.2, random_state=42)\n",
    "X_train_ord, X_test_ord, y_train_ord, y_test_ord = train_test_split(X_ord_smote, y_ord_smote, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Logistic Regression: 0.7335976928622927\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(max_iter=10000)\n",
    "logreg.fit(X_train_dummy, y_train_dummy)\n",
    "\n",
    "y_pred = logreg.predict(X_test_dummy)\n",
    "acc = accuracy_score(y_test_dummy, y_pred)\n",
    "print('Accuracy Logistic Regression:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy XGBoost: 0.7519826964671954\n"
     ]
    }
   ],
   "source": [
    "#XGBoost\n",
    "from xgboost import XGBClassifier\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(X_train_dummy, y_train_dummy)\n",
    "\n",
    "y_pred = xgb.predict(X_test_dummy)\n",
    "acc = accuracy_score(y_test_dummy, y_pred)\n",
    "print('Accuracy XGBoost:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Random Forest: 0.7530641672674838\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train_dummy, y_train_dummy)\n",
    "\n",
    "y_pred = rf.predict(X_test_dummy)\n",
    "acc = accuracy_score(y_test_dummy, y_pred)\n",
    "print('Accuracy Random Forest:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_ord = pd.DataFrame(scaler.fit_transform(X_train_ord), columns=X_train_ord.columns, index=X_train_ord.index)\n",
    "X_test_ord = pd.DataFrame(scaler.transform(X_test_ord), columns=X_test_ord.columns, index=X_test_ord.index)\n",
    "\n",
    "categories = ['code_module', 'code_presentation', 'gender', 'region']\n",
    "num_categories = []\n",
    "for category in categories:\n",
    "    num_categories.append(data_ordinal[category].nunique())\n",
    "\n",
    "X_train_ord_num = X_train_ord.drop(categories, axis=1)\n",
    "X_test_ord_num = X_test_ord.drop(categories, axis=1)\n",
    "X_train_ord_cat = X_train_ord[categories]\n",
    "X_test_ord_cat = X_test_ord[categories]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "555/555 [==============================] - 16s 27ms/step - loss: 0.6580 - accuracy: 0.6123 - val_loss: 0.6487 - val_accuracy: 0.6302\n",
      "Epoch 2/10\n",
      "555/555 [==============================] - 15s 26ms/step - loss: 0.6460 - accuracy: 0.6301 - val_loss: 0.6452 - val_accuracy: 0.6264\n",
      "Epoch 3/10\n",
      "555/555 [==============================] - 14s 26ms/step - loss: 0.6415 - accuracy: 0.6334 - val_loss: 0.6459 - val_accuracy: 0.6429\n",
      "Epoch 4/10\n",
      "187/555 [=========>....................] - ETA: 9s - loss: 0.6376 - accuracy: 0.6372"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 57\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# Convert X_train_ord_num to a Numpy array\u001b[39;00m\n\u001b[1;32m     55\u001b[0m X_train_ord_num_np \u001b[38;5;241m=\u001b[39m X_train_ord_num\u001b[38;5;241m.\u001b[39mto_numpy()\n\u001b[0;32m---> 57\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mX_train_ord_cat_np\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_ord_num_np\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_ord\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1805\u001b[0m ):\n\u001b[1;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    867\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 868\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m     args,\n\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1501\u001b[0m   )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Embedding, Flatten, Dense, Concatenate, BatchNormalization\n",
    "\n",
    "\n",
    "# X_train_dummy = X_train_dummy.astype('float32')\n",
    "# y_train_dummy = y_train_dummy.astype('float32')\n",
    "# X_test_dummy = X_test_dummy.astype('float32')\n",
    "# y_test_dummy = y_test_dummy.astype('float32')\n",
    "\n",
    "X_train_ord_num = X_train_ord_num.astype('float32')\n",
    "X_train_ord_cat = X_train_ord_cat.astype('float32')\n",
    "y_train_ord = y_train_ord.astype('float32')\n",
    "X_test_ord_num = X_test_ord_num.astype('float32')\n",
    "X_test_ord_cat = X_test_ord_cat.astype('float32')\n",
    "y_test_ord = y_test_ord.astype('float32')\n",
    "\n",
    "embedding_inputs = []\n",
    "embeddings = []\n",
    "for i in range(len(num_categories)):\n",
    "    input_i = Input(shape=(1,))\n",
    "    embedding_size = min(np.ceil((num_categories[i])/2), 50 )  # embedding size rule of thumb\n",
    "    embedding_size = int(embedding_size)\n",
    "    embedding_i = Embedding(input_dim=num_categories[i], output_dim=embedding_size, input_length=1)(input_i)\n",
    "    embedding_i = Flatten()(embedding_i)\n",
    "    embedding_inputs.append(input_i)\n",
    "    embeddings.append(embedding_i)\n",
    "\n",
    "ordinal_input = Input(shape=(X_train_ord_num.shape[1],))\n",
    "combined = Concatenate()([*embeddings, ordinal_input])\n",
    "\n",
    "dense = Dense(64, kernel_initializer=tf.keras.initializers.HeNormal())(combined)\n",
    "dense = BatchNormalization()(dense)\n",
    "dense = tf.keras.activations.relu(dense)\n",
    "\n",
    "dense = Dense(64, kernel_initializer=tf.keras.initializers.HeNormal())(dense)\n",
    "dense = BatchNormalization()(dense)\n",
    "dense = tf.keras.activations.relu(dense)\n",
    "\n",
    "dense = Dense(64, kernel_initializer=tf.keras.initializers.HeNormal())(dense)\n",
    "dense = BatchNormalization()(dense)\n",
    "dense = tf.keras.activations.relu(dense)\n",
    "\n",
    "output = Dense(1, activation='sigmoid')(dense)\n",
    "\n",
    "model = tf.keras.Model(inputs=[*embedding_inputs, ordinal_input], outputs=output)\n",
    "\n",
    "optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=0.001, clipvalue=1.0)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Convert each column in X_train_ord_cat to a Numpy array\n",
    "X_train_ord_cat_np = [X_train_ord_cat[category].to_numpy() for category in categories]\n",
    "\n",
    "# Convert X_train_ord_num to a Numpy array\n",
    "X_train_ord_num_np = X_train_ord_num.to_numpy()\n",
    "\n",
    "history = model.fit([*X_train_ord_cat_np, X_train_ord_num_np], y_train_ord, epochs=10, batch_size=32, validation_split=0.2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
