{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code_module</th>\n",
       "      <th>code_presentation</th>\n",
       "      <th>id_student</th>\n",
       "      <th>gender</th>\n",
       "      <th>region</th>\n",
       "      <th>highest_education</th>\n",
       "      <th>imd_band</th>\n",
       "      <th>age_band</th>\n",
       "      <th>num_of_prev_attempts</th>\n",
       "      <th>studied_credits</th>\n",
       "      <th>disability</th>\n",
       "      <th>final_result</th>\n",
       "      <th>score</th>\n",
       "      <th>grade</th>\n",
       "      <th>studied_credits_binned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAA</td>\n",
       "      <td>2013J</td>\n",
       "      <td>11391</td>\n",
       "      <td>M</td>\n",
       "      <td>East Anglian Region</td>\n",
       "      <td>HE Qualification</td>\n",
       "      <td>90-100%</td>\n",
       "      <td>55&lt;=</td>\n",
       "      <td>0</td>\n",
       "      <td>240</td>\n",
       "      <td>N</td>\n",
       "      <td>Pass</td>\n",
       "      <td>82.4</td>\n",
       "      <td>A-</td>\n",
       "      <td>201+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAA</td>\n",
       "      <td>2013J</td>\n",
       "      <td>28400</td>\n",
       "      <td>F</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>HE Qualification</td>\n",
       "      <td>20-30%</td>\n",
       "      <td>35-55</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>N</td>\n",
       "      <td>Pass</td>\n",
       "      <td>65.4</td>\n",
       "      <td>C</td>\n",
       "      <td>30-60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAA</td>\n",
       "      <td>2013J</td>\n",
       "      <td>31604</td>\n",
       "      <td>F</td>\n",
       "      <td>South East Region</td>\n",
       "      <td>A Level or Equivalent</td>\n",
       "      <td>50-60%</td>\n",
       "      <td>35-55</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>N</td>\n",
       "      <td>Pass</td>\n",
       "      <td>76.3</td>\n",
       "      <td>B</td>\n",
       "      <td>30-60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAA</td>\n",
       "      <td>2013J</td>\n",
       "      <td>32885</td>\n",
       "      <td>F</td>\n",
       "      <td>West Midlands Region</td>\n",
       "      <td>Lower Than A Level</td>\n",
       "      <td>50-60%</td>\n",
       "      <td>0-35</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>N</td>\n",
       "      <td>Pass</td>\n",
       "      <td>55.0</td>\n",
       "      <td>D</td>\n",
       "      <td>30-60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAA</td>\n",
       "      <td>2013J</td>\n",
       "      <td>38053</td>\n",
       "      <td>M</td>\n",
       "      <td>Wales</td>\n",
       "      <td>A Level or Equivalent</td>\n",
       "      <td>80-90%</td>\n",
       "      <td>35-55</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>N</td>\n",
       "      <td>Pass</td>\n",
       "      <td>66.9</td>\n",
       "      <td>C</td>\n",
       "      <td>30-60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  code_module code_presentation  id_student gender                region  \\\n",
       "0         AAA             2013J       11391      M   East Anglian Region   \n",
       "1         AAA             2013J       28400      F              Scotland   \n",
       "2         AAA             2013J       31604      F     South East Region   \n",
       "3         AAA             2013J       32885      F  West Midlands Region   \n",
       "4         AAA             2013J       38053      M                 Wales   \n",
       "\n",
       "       highest_education imd_band age_band  num_of_prev_attempts  \\\n",
       "0       HE Qualification  90-100%     55<=                     0   \n",
       "1       HE Qualification   20-30%    35-55                     0   \n",
       "2  A Level or Equivalent   50-60%    35-55                     0   \n",
       "3     Lower Than A Level   50-60%     0-35                     0   \n",
       "4  A Level or Equivalent   80-90%    35-55                     0   \n",
       "\n",
       "   studied_credits disability final_result  score grade studied_credits_binned  \n",
       "0              240          N         Pass   82.4    A-                   201+  \n",
       "1               60          N         Pass   65.4     C                  30-60  \n",
       "2               60          N         Pass   76.3     B                  30-60  \n",
       "3               60          N         Pass   55.0     D                  30-60  \n",
       "4               60          N         Pass   66.9     C                  30-60  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('data/student_info_cleaned.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['final_result'].value_counts()\n",
    "#drop withdrawn students\n",
    "data = data[data['final_result'] != 'Withdrawn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#order highest_education, imd_band, age_band, disability, studied_credits_binned, final_result\n",
    "highest_education = {\n",
    "    'No Formal quals': 0,\n",
    "    'Lower Than A Level': 1,\n",
    "    'A Level or Equivalent': 2,\n",
    "    'HE Qualification': 3,\n",
    "    'Post Graduate Qualification': 4\n",
    "}\n",
    "\n",
    "imd_band = {\n",
    "    np.nan: -1,\n",
    "    '0-10%': 0,\n",
    "    '10-20': 1,\n",
    "    '20-30%': 2,\n",
    "    '30-40%': 3,\n",
    "    '40-50%': 4,\n",
    "    '50-60%': 5,\n",
    "    '60-70%': 6,\n",
    "    '70-80%': 7,\n",
    "    '80-90%': 8,\n",
    "    '90-100%': 9\n",
    "}\n",
    "\n",
    "age_band = {\n",
    "    '0-35': 0,\n",
    "    '35-55': 1,\n",
    "    '55<=': 2\n",
    "}\n",
    "\n",
    "disability = {\n",
    "    'N': 0,\n",
    "    'Y': 1\n",
    "}\n",
    "\n",
    "studied_credits_binned = {\n",
    "    '30-60': 0,\n",
    "    '61-100': 1,\n",
    "    '101-200': 2,\n",
    "    '201+': 3\n",
    "}\n",
    "\n",
    "final_result = {\n",
    "    'Fail': 0,\n",
    "    'Pass': 1,\n",
    "    'Distinction': 1,\n",
    "    'Withdrawn': 0\n",
    "}\n",
    "\n",
    "data_dummies = pd.get_dummies(data, columns=['code_module', 'code_presentation', 'gender', 'region'])\n",
    "data_dummies['highest_education'] = data_dummies['highest_education'].map(highest_education)\n",
    "data_dummies['imd_band'] = data_dummies['imd_band'].map(imd_band)\n",
    "data_dummies['age_band'] = data_dummies['age_band'].map(age_band)\n",
    "data_dummies['disability'] = data_dummies['disability'].map(disability)\n",
    "data_dummies['studied_credits_binned'] = data_dummies['studied_credits_binned'].map(studied_credits_binned)\n",
    "data_dummies['final_result'] = data_dummies['final_result'].map(final_result)\n",
    "\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# data_ordinal = data.copy()\n",
    "# data_ordinal['highest_education'] = data_dummies['highest_education']\n",
    "# data_ordinal['imd_band'] = data_dummies['imd_band']\n",
    "# data_ordinal['age_band'] = data_dummies['age_band']\n",
    "# data_ordinal['disability'] = data_dummies['disability']\n",
    "# data_ordinal['studied_credits_binned'] = data_dummies['studied_credits_binned']\n",
    "# data_ordinal['final_result'] = data_dummies['final_result']\n",
    "\n",
    "# le = LabelEncoder()\n",
    "# data_ordinal['code_module'] = le.fit_transform(data_ordinal['code_module'])\n",
    "# data_ordinal['code_presentation'] = le.fit_transform(data_ordinal['code_presentation'])\n",
    "# data_ordinal['gender'] = le.fit_transform(data_ordinal['gender'])\n",
    "# data_ordinal['region'] = le.fit_transform(data_ordinal['region'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70.000000    55\n",
       "66.000000    52\n",
       "60.000000    52\n",
       "80.000000    50\n",
       "56.000000    49\n",
       "             ..\n",
       "63.890000     1\n",
       "55.262626     1\n",
       "52.204082     1\n",
       "54.185930     1\n",
       "54.989637     1\n",
       "Name: score, Length: 11668, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dummies['score'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_40831/2502644455.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y_dummy['score'] = X_dummy_combined['score']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from imblearn.over_sampling import SMOTE#pip install imbalanced-learn\n",
    "\n",
    "\n",
    "\n",
    "X_dummy = data_dummies.drop(['final_result', 'studied_credits', 'id_student', 'score', 'grade'], axis=1)\n",
    "X_dummy_combined = X_dummy.copy()\n",
    "X_dummy_combined['score'] = data_dummies['score']\n",
    "# X_dummy_combined.loc[(X_dummy_combined['score'] < 50) & (y_dummy['final_result'] == 1), 'score'] = 76\n",
    "# X_dummy_combined.loc[y_dummy['final_result'] == 0, 'score'] = 35\n",
    "\n",
    "\n",
    "y_dummy = data_dummies[['final_result']]\n",
    "\n",
    "smote = SMOTE(sampling_strategy='minority', random_state=42)\n",
    "X_dummy_smote, y_dummy_smote = smote.fit_resample(X_dummy_combined, y_dummy)\n",
    "\n",
    "y_dummy_smote['score'] = X_dummy_smote['score']\n",
    "y_dummy['score'] = X_dummy_combined['score']\n",
    "X_dummy_smote = X_dummy_smote.drop(['score'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1z/_j8y7ndj06788g4f84n47dqm0000gn/T/ipykernel_18029/3644116101.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_dummy_smote = pd.read_csv('data/X_dummy_smote.csv')\n",
    "y_dummy_smote = pd.read_csv('data/y_dummy_smote.csv')\n",
    "X_ord_smote = pd.read_csv('data/X_ord_smote.csv')\n",
    "y_ord_smote = pd.read_csv('data/y_ord_smote.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27736, 31)\n",
      "(27736, 2)\n"
     ]
    }
   ],
   "source": [
    "print(X_dummy_smote.shape)\n",
    "print(y_dummy_smote.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_dummy, X_test_dummy, y_train_dummy, y_test_dummy = train_test_split(X_dummy_smote, y_dummy_smote, test_size=0.2, random_state=42, stratify=y_dummy_smote['final_result'])\n",
    "# X_train_ord, X_test_ord, y_train_ord, y_test_ord = train_test_split(X_ord_smote, y_ord_smote, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    11094\n",
      "0    11094\n",
      "Name: final_result, dtype: int64\n",
      "1    2774\n",
      "0    2774\n",
      "Name: final_result, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y_train_dummy['final_result'].value_counts())\n",
    "print(y_test_dummy['final_result'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Logistic Regression: 0.7999279019466474\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(max_iter=10000)\n",
    "logreg.fit(X_train_dummy, y_train_dummy['final_result'])\n",
    "\n",
    "y_pred = logreg.predict(X_test_dummy)\n",
    "acc = accuracy_score(y_test_dummy['final_result'], y_pred)\n",
    "print('Accuracy Logistic Regression:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBoost\n",
    "from xgboost import XGBClassifier #pip install xgboost\n",
    "from skopt import BayesSearchCV\n",
    "\n",
    "# Define the parameter space\n",
    "param_space = {\n",
    "    'learning_rate': (0.01, 1.0, 'log-uniform'),\n",
    "    'min_child_weight': (1, 10),\n",
    "    'max_depth': (3, 50),\n",
    "    'max_delta_step': (1, 20),\n",
    "    'subsample': (0.01, 1.0, 'uniform'),\n",
    "    'colsample_bytree': (0.01, 1.0, 'uniform'),\n",
    "    'colsample_bylevel': (0.01, 1.0, 'uniform'),\n",
    "    'reg_lambda': (1e-9, 1000, 'log-uniform'),\n",
    "    'reg_alpha': (1e-9, 1.0, 'log-uniform'),\n",
    "    'gamma': (1e-9, 0.5, 'log-uniform'),\n",
    "    'n_estimators': (50, 200),\n",
    "    'scale_pos_weight': (1e-6, 500, 'log-uniform')\n",
    "}\n",
    "\n",
    "# Create a BayesSearchCV object\n",
    "opt_xgb = BayesSearchCV(\n",
    "    estimator=XGBClassifier(n_jobs=-1),\n",
    "    search_spaces=param_space,\n",
    "    scoring='roc_auc',\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    n_iter=150,\n",
    "    verbose=1,\n",
    "    refit=True,\n",
    ")\n",
    "\n",
    "# Run the optimization\n",
    "opt_xgb.fit(X_train_dummy, y_train_dummy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier()\n",
    "xgb.fit(X_train_dummy, y_train_dummy)\n",
    "\n",
    "y_pred = xgb.predict(X_test_dummy)\n",
    "acc = accuracy_score(y_test_dummy, y_pred)\n",
    "print(\"Accuracy XGBoost:\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed iteration 1\n",
      "Completed iteration 2\n",
      "Completed iteration 3\n",
      "Completed iteration 4\n",
      "Completed iteration 5\n",
      "Completed iteration 6\n",
      "Completed iteration 7\n",
      "Completed iteration 8\n",
      "Completed iteration 9\n",
      "Completed iteration 10\n",
      "Completed iteration 11\n",
      "Completed iteration 12\n",
      "Completed iteration 13\n",
      "Completed iteration 14\n",
      "Completed iteration 15\n",
      "Completed iteration 16\n",
      "Completed iteration 17\n",
      "Completed iteration 18\n",
      "Completed iteration 19\n",
      "Completed iteration 20\n",
      "Completed iteration 21\n",
      "Completed iteration 22\n",
      "Completed iteration 23\n",
      "Completed iteration 24\n",
      "Completed iteration 25\n",
      "Completed iteration 26\n",
      "Completed iteration 27\n",
      "Completed iteration 28\n",
      "Completed iteration 29\n",
      "Completed iteration 30\n",
      "Completed iteration 31\n",
      "Completed iteration 32\n",
      "Completed iteration 33\n",
      "Completed iteration 34\n",
      "Completed iteration 35\n",
      "Completed iteration 36\n",
      "Completed iteration 37\n",
      "Completed iteration 38\n",
      "Completed iteration 39\n",
      "Completed iteration 40\n",
      "Completed iteration 41\n",
      "Completed iteration 42\n",
      "Completed iteration 43\n",
      "Completed iteration 44\n",
      "Completed iteration 45\n",
      "Completed iteration 46\n",
      "Completed iteration 47\n",
      "Completed iteration 48\n",
      "Completed iteration 49\n",
      "Completed iteration 50\n",
      "Best parameters: OrderedDict([('bagging_temperature', 1.0), ('border_count', 148), ('depth', 13), ('iterations', 976), ('l2_leaf_reg', 30), ('learning_rate', 0.02389354323083735), ('random_strength', 1e-09), ('scale_pos_weight', 0.9510644977326121)])\n",
      "Best score: 0.7638817157088732\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from skopt import BayesSearchCV\n",
    "\n",
    "counter = [0]\n",
    "\n",
    "def on_step(optim_result):\n",
    "    # Increment the counter\n",
    "    counter[0] += 1\n",
    "    print(f\"Completed iteration {counter[0]}\")\n",
    "    \n",
    "cb = CatBoostClassifier(verbose=False)\n",
    "\n",
    "# Define search spaces\n",
    "param_space = {\n",
    "    'iterations': (50, 1000),\n",
    "    'depth': (1, 16),\n",
    "    'learning_rate': (0.01, 1.0, 'log-uniform'),\n",
    "    'random_strength': (1e-9, 10, 'log-uniform'),\n",
    "    'bagging_temperature': (0.0, 1.0),\n",
    "    'border_count': (1, 255),\n",
    "    'l2_leaf_reg': (2, 30),\n",
    "    'scale_pos_weight':(0.01, 1.0, 'uniform')\n",
    "}\n",
    "\n",
    "# Initialize BayesSearchCV\n",
    "opt_cb = BayesSearchCV(\n",
    "    estimator=cb,\n",
    "    search_spaces=param_space,\n",
    "    scoring='accuracy',\n",
    "    n_iter=50,\n",
    "    n_jobs=-1,\n",
    "    return_train_score=False,\n",
    "    refit=True,\n",
    "    optimizer_kwargs={'base_estimator': 'GP'},\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "opt_cb.fit(X_train_dummy, y_train_dummy, callback=on_step)\n",
    "\n",
    "# Print best parameters and score\n",
    "print(f'Best parameters: {opt_cb.best_params_}')\n",
    "print(f'Best score: {opt_cb.best_score_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "params = OrderedDict([('bagging_temperature', 1.0), ('border_count', 148), ('depth', 13), ('iterations', 976), ('l2_leaf_reg', 30), ('learning_rate', 0.02389354323083735), ('random_strength', 1e-09), ('scale_pos_weight', 0.9510644977326121)])\n",
    "params['iterations'] = 10000\n",
    "\n",
    "cb = CatBoostClassifier(**params)\n",
    "cb.fit(X_train_dummy, y_train_dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy CatBoost: 0.7581110310021629\n"
     ]
    }
   ],
   "source": [
    "y_pred = cb.predict(X_test_dummy)\n",
    "acc = accuracy_score(y_test_dummy, y_pred)\n",
    "print('Accuracy CatBoost:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train_dummy, y_train_dummy)\n",
    "\n",
    "y_pred = rf.predict(X_test_dummy)\n",
    "acc = accuracy_score(y_test_dummy, y_pred)\n",
    "print('Accuracy Random Forest:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "categories = ['code_module', 'code_presentation', 'gender', 'region']\n",
    "numerical_features = [col for col in X_train_ord.columns if col not in categories]\n",
    "\n",
    "X_train_dummy = scaler.fit_transform(X_train_dummy)\n",
    "X_test_dummy = scaler.fit_transform(X_test_dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>final_result</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19901</th>\n",
       "      <td>0</td>\n",
       "      <td>77.718532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14299</th>\n",
       "      <td>1</td>\n",
       "      <td>84.191919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25453</th>\n",
       "      <td>0</td>\n",
       "      <td>84.567035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6573</th>\n",
       "      <td>1</td>\n",
       "      <td>85.348315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11571</th>\n",
       "      <td>0</td>\n",
       "      <td>67.857143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       final_result      score\n",
       "19901             0  77.718532\n",
       "14299             1  84.191919\n",
       "25453             0  84.567035\n",
       "6573              1  85.348315\n",
       "11571             0  67.857143"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_dummy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 4.9741 - accuracy: 0.6373 - val_loss: 1.0872 - val_accuracy: 0.7400\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.08724, saving model to model.h5\n",
      "Epoch 2/15\n",
      "555/555 [==============================] - 2s 4ms/step - loss: 0.8940 - accuracy: 0.7493 - val_loss: 0.5518 - val_accuracy: 0.7850\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.08724 to 0.55181, saving model to model.h5\n",
      "Epoch 3/15\n",
      "555/555 [==============================] - 2s 4ms/step - loss: 0.5443 - accuracy: 0.7737 - val_loss: 0.4962 - val_accuracy: 0.7848\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.55181 to 0.49623, saving model to model.h5\n",
      "Epoch 4/15\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 0.5038 - accuracy: 0.7785 - val_loss: 0.4840 - val_accuracy: 0.7873\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.49623 to 0.48403, saving model to model.h5\n",
      "Epoch 5/15\n",
      "555/555 [==============================] - 2s 4ms/step - loss: 0.4925 - accuracy: 0.7828 - val_loss: 0.4803 - val_accuracy: 0.7830\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.48403 to 0.48026, saving model to model.h5\n",
      "Epoch 6/15\n",
      "555/555 [==============================] - 2s 4ms/step - loss: 0.4984 - accuracy: 0.7765 - val_loss: 0.4876 - val_accuracy: 0.7783\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.48026\n",
      "Epoch 7/15\n",
      "555/555 [==============================] - 2s 4ms/step - loss: 0.4945 - accuracy: 0.7829 - val_loss: 0.4624 - val_accuracy: 0.7898\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.48026 to 0.46236, saving model to model.h5\n",
      "Epoch 8/15\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 0.4801 - accuracy: 0.7824 - val_loss: 0.4723 - val_accuracy: 0.7891\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.46236\n",
      "Epoch 9/15\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 0.4782 - accuracy: 0.7787 - val_loss: 0.4520 - val_accuracy: 0.7913\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.46236 to 0.45200, saving model to model.h5\n",
      "Epoch 10/15\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 0.4842 - accuracy: 0.7805 - val_loss: 0.4812 - val_accuracy: 0.7772\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.45200\n",
      "Epoch 11/15\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 0.4747 - accuracy: 0.7824 - val_loss: 0.4838 - val_accuracy: 0.7844\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.45200\n",
      "Epoch 12/15\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 0.4749 - accuracy: 0.7813 - val_loss: 0.4600 - val_accuracy: 0.7891\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.45200\n",
      "Epoch 13/15\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 0.4692 - accuracy: 0.7811 - val_loss: 0.4566 - val_accuracy: 0.7839\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.45200\n",
      "Epoch 14/15\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 0.4664 - accuracy: 0.7829 - val_loss: 0.4540 - val_accuracy: 0.7850\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.45200\n",
      "Epoch 15/15\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 0.4583 - accuracy: 0.7851 - val_loss: 0.4727 - val_accuracy: 0.7733\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.45200\n",
      "predicting\n",
      "misclassifying\n",
      "training\n",
      "Epoch 1/15\n",
      "555/555 [==============================] - 6s 4ms/step - loss: 0.4559 - accuracy: 0.7862 - val_loss: 0.4523 - val_accuracy: 0.7850\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.45232, saving model to model2.h5\n",
      "Epoch 2/15\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 0.4662 - accuracy: 0.7792 - val_loss: 0.4574 - val_accuracy: 0.7844\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.45232\n",
      "Epoch 3/15\n",
      "555/555 [==============================] - 2s 4ms/step - loss: 0.4739 - accuracy: 0.7841 - val_loss: 0.4585 - val_accuracy: 0.7866\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.45232\n",
      "Epoch 4/15\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 0.4659 - accuracy: 0.7815 - val_loss: 0.4485 - val_accuracy: 0.7850\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.45232 to 0.44852, saving model to model2.h5\n",
      "Epoch 5/15\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 0.4516 - accuracy: 0.7854 - val_loss: 0.4553 - val_accuracy: 0.7839\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.44852\n",
      "Epoch 6/15\n",
      "555/555 [==============================] - 2s 4ms/step - loss: 0.4615 - accuracy: 0.7850 - val_loss: 0.4627 - val_accuracy: 0.7850\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.44852\n",
      "Epoch 7/15\n",
      "555/555 [==============================] - 2s 4ms/step - loss: 0.4585 - accuracy: 0.7864 - val_loss: 0.4445 - val_accuracy: 0.7873\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.44852 to 0.44455, saving model to model2.h5\n",
      "Epoch 8/15\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 0.4535 - accuracy: 0.7880 - val_loss: 0.4463 - val_accuracy: 0.7855\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.44455\n",
      "Epoch 9/15\n",
      "555/555 [==============================] - 2s 4ms/step - loss: 0.4598 - accuracy: 0.7913 - val_loss: 0.4500 - val_accuracy: 0.7886\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.44455\n",
      "Epoch 10/15\n",
      "555/555 [==============================] - 2s 4ms/step - loss: 0.4570 - accuracy: 0.7809 - val_loss: 0.4469 - val_accuracy: 0.7850\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.44455\n",
      "Epoch 11/15\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 0.4544 - accuracy: 0.7865 - val_loss: 0.4558 - val_accuracy: 0.7889\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.44455\n",
      "Epoch 12/15\n",
      "555/555 [==============================] - 2s 4ms/step - loss: 0.4637 - accuracy: 0.7824 - val_loss: 0.4410 - val_accuracy: 0.7864\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.44455 to 0.44096, saving model to model2.h5\n",
      "Epoch 13/15\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 0.4520 - accuracy: 0.7871 - val_loss: 0.4460 - val_accuracy: 0.7884\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.44096\n",
      "Epoch 14/15\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 0.4653 - accuracy: 0.7730 - val_loss: 0.4475 - val_accuracy: 0.7864\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.44096\n",
      "Epoch 15/15\n",
      "555/555 [==============================] - 2s 4ms/step - loss: 0.4514 - accuracy: 0.7893 - val_loss: 0.4391 - val_accuracy: 0.7880\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.44096 to 0.43908, saving model to model2.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc1c47b11f0>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dropout, Input, Dense, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import tensorflow as tf\n",
    "\n",
    "X_train_dummy_np = X_train_dummy.astype('float32')\n",
    "y_train_dummy_np = y_train_dummy.drop(columns=['score']).astype('float32')\n",
    "\n",
    "input_layer = Input(shape=(X_train_dummy.shape[1],))\n",
    "\n",
    "dense = Dense(128, kernel_initializer=tf.keras.initializers.HeNormal(), kernel_regularizer=l2(0.01))(input_layer)\n",
    "dense = BatchNormalization()(dense)\n",
    "dense = tf.keras.activations.relu(dense)\n",
    "dense = Dropout(0.2)(dense)\n",
    "\n",
    "dense = Dense(128, kernel_initializer=tf.keras.initializers.HeNormal(), kernel_regularizer=l2(0.01))(dense)\n",
    "dense = BatchNormalization()(dense)\n",
    "dense = tf.keras.activations.relu(dense)\n",
    "dense = Dropout(0.2)(dense)\n",
    "\n",
    "dense = Dense(128, kernel_initializer=tf.keras.initializers.HeNormal(), kernel_regularizer=l2(0.01))(dense)\n",
    "dense = BatchNormalization()(dense)\n",
    "dense = tf.keras.activations.relu(dense)\n",
    "dense = Dropout(0.2)(dense)\n",
    "\n",
    "output = Dense(1, activation='sigmoid')(dense)\n",
    "\n",
    "model = tf.keras.models.Model(inputs=input_layer, outputs=output)\n",
    "model2 = tf.keras.models.Model(inputs=input_layer, outputs=output)\n",
    "\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='model.h5',\n",
    "    monitor='val_loss',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    mode='min'\n",
    ")\n",
    "checkpoint2 = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='model2.h5',\n",
    "    monitor='val_loss',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "hist = model.fit(X_train_dummy_np, y_train_dummy_np, epochs=15, batch_size=32, validation_split=0.2, callbacks=[checkpoint])\n",
    "\n",
    "#misclassified from the first\n",
    "print(\"predicting\")\n",
    "preds1 = model.predict(X_train_dummy_np)\n",
    "print(\"misclassifying\")\n",
    "# predictions_classified = [1 if y >= 50 else 0 for y in preds1.flatten()]\n",
    "# y_train_dummy_binary = [1 if y >= 50 else 0 for y in y_train_dummy['score']]\n",
    "misclassified = np.array(preds1) != np.array(y_train_dummy_np)\n",
    "print(\"training\")\n",
    "\n",
    "model2.fit(X_train_dummy_np[misclassified], y_train_dummy_np[misclassified], epochs=15, batch_size=32, validation_split=0.2, callbacks=[checkpoint2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of 0's: 836\n",
      "Number of 1's: 4712\n",
      "SMOTE\n",
      "Average score where final_result = 1: 76.12141706664993\n",
      "Average score where final_result = 0: 59.681352912263016\n",
      "Number of entries where final_result = 1 and score < 50: 78\n",
      "Number of entries where final_result = 0 and score > 50: 9721\n",
      "REG\n",
      "Average score where final_result = 1: 76.12141706664993\n",
      "Average score where final_result = 0: 59.69574552098805\n",
      "Number of entries where final_result = 1 and score < 50: 78\n",
      "Number of entries where final_result = 0 and score > 50: 3704\n"
     ]
    }
   ],
   "source": [
    "y_test_dummy['final_result'].value_counts()\n",
    "test_classified = [0 if y < 50 else 1 for y in y_test_dummy['score'].astype('float32')]\n",
    "num_zeros = test_classified.count(0)\n",
    "num_ones = test_classified.count(1)\n",
    "\n",
    "print(f\"Number of 0's: {num_zeros}\")\n",
    "print(f\"Number of 1's: {num_ones}\")\n",
    "\n",
    "print('SMOTE')\n",
    "average_score = y_dummy_smote[y_dummy_smote['final_result'] == 1]['score'].mean()\n",
    "print(f\"Average score where final_result = 1: {average_score}\")\n",
    "\n",
    "average_score = y_dummy_smote[y_dummy_smote['final_result'] == 0]['score'].mean()\n",
    "print(f\"Average score where final_result = 0: {average_score}\")\n",
    "\n",
    "num_entries = len(y_dummy_smote[(y_dummy_smote['final_result'] == 1) & (y_dummy_smote['score'] < 50)])\n",
    "print(f\"Number of entries where final_result = 1 and score < 50: {num_entries}\")\n",
    "\n",
    "num_entries = len(y_dummy_smote[(y_dummy_smote['final_result'] == 0) & (y_dummy_smote['score'] > 50)])\n",
    "print(f\"Number of entries where final_result = 0 and score > 50: {num_entries}\")\n",
    "\n",
    "print('REG')\n",
    "average_score = y_dummy[y_dummy['final_result'] == 1]['score'].mean()\n",
    "print(f\"Average score where final_result = 1: {average_score}\")\n",
    "\n",
    "average_score = y_dummy[y_dummy['final_result'] == 0]['score'].mean()\n",
    "print(f\"Average score where final_result = 0: {average_score}\")\n",
    "\n",
    "num_entries = len(y_dummy[(y_dummy['final_result'] == 1) & (y_dummy['score'] < 50)])\n",
    "print(f\"Number of entries where final_result = 1 and score < 50: {num_entries}\")\n",
    "\n",
    "num_entries = len(y_dummy[(y_dummy['final_result'] == 0) & (y_dummy['score'] > 50)])\n",
    "print(f\"Number of entries where final_result = 0 and score > 50: {num_entries}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5548, 1)\n",
      "(5548, 2)\n",
      "best threshold 0.36165768\n",
      "22188\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [5548, 22188]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [97]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(predictions_classified))\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# y_test_dummy_binary = [1 if y >= 60 else 0 for y in y_test_dummy['score']]\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# predictions_classified1 = [1 if y >= 60 else 0 for y in preds1]\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m acc \u001b[38;5;241m=\u001b[39m \u001b[43maccuracy_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test_dummy\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfinal_result\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictions_classified\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124macc1\u001b[39m\u001b[38;5;124m\"\u001b[39m, acc)\n\u001b[1;32m     25\u001b[0m cm \u001b[38;5;241m=\u001b[39m confusion_matrix(y_test_dummy[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinal_result\u001b[39m\u001b[38;5;124m'\u001b[39m], predictions_classified)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/sklearn/utils/_param_validation.py:214\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    210\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    211\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    212\u001b[0m         )\n\u001b[1;32m    213\u001b[0m     ):\n\u001b[0;32m--> 214\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    224\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:220\u001b[0m, in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;124;03m\"\"\"Accuracy classification score.\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \n\u001b[1;32m    156\u001b[0m \u001b[38;5;124;03mIn multilabel classification, this function computes subset accuracy:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;124;03m0.5\u001b[39;00m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;66;03m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[0;32m--> 220\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:84\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_targets\u001b[39m(y_true, y_pred):\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \n\u001b[1;32m     60\u001b[0m \u001b[38;5;124;03m    This converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;124;03m    y_pred : array or indicator matrix\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 84\u001b[0m     \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m     type_true \u001b[38;5;241m=\u001b[39m type_of_target(y_true, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     86\u001b[0m     type_pred \u001b[38;5;241m=\u001b[39m type_of_target(y_pred, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/sklearn/utils/validation.py:407\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    405\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 407\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    408\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    409\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    410\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [5548, 22188]"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_recall_curve\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "best_model1 = load_model('model.h5')\n",
    "best_model2 = load_model('model2.h5')\n",
    "\n",
    "X_test_dummy_np = X_test_dummy.astype('float32')\n",
    "\n",
    "preds1 = best_model1.predict(X_test_dummy_np)\n",
    "print(preds1.shape)\n",
    "print(y_test_dummy.shape)\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_test_dummy['final_result'], preds1)\n",
    "best_threshold = thresholds[np.argmax(precisions + recalls)]\n",
    "\n",
    "print('best threshold', best_threshold)\n",
    "\n",
    "predictions_classified1 = [1 if y >= best_threshold else 0 for y in preds1.flatten()]\n",
    "print(len(predictions_classified))\n",
    "\n",
    "# y_test_dummy_binary = [1 if y >= 60 else 0 for y in y_test_dummy['score']]\n",
    "# predictions_classified1 = [1 if y >= 60 else 0 for y in preds1]\n",
    "\n",
    "acc = accuracy_score(y_test_dummy['final_result'], predictions_classified)\n",
    "print(\"acc1\", acc)\n",
    "cm = confusion_matrix(y_test_dummy['final_result'], predictions_classified)\n",
    "\n",
    "print(\"Confusion Matrix1:\")\n",
    "print(cm)\n",
    "positive_preds = np.array(predictions_classified1) == 1\n",
    "\n",
    "preds2 = best_model2.predict(X_test_dummy_np[positive_preds])\n",
    "# preds2 = best_model2.predict(X_test_dummy_np)\n",
    "average_preds = (preds1[positive_preds]*0.5) + (preds2*0.5)\n",
    "\n",
    "\n",
    "\n",
    "final_preds = np.array(preds1.copy())\n",
    "final_preds[positive_preds] = average_preds\n",
    "# final_preds = np.array(preds.copy())\n",
    "\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_test_dummy_binary, final_preds)\n",
    "best_threshold = thresholds[np.argmax(precisions + recalls)]\n",
    "\n",
    "print('best threshold', best_threshold)\n",
    "final_preds_classified = [1 if y >= best_threshold else 0 for y in final_preds.flatten()]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "acc = accuracy_score(y_test_dummy_binary, final_preds_classified)\n",
    "print(\"Accuracy\", acc)\n",
    "\n",
    "\n",
    "cm = confusion_matrix(y_test_dummy_binary, final_preds_classified)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DO NOT RUN, TAKES FOREVER, OPTIMAL PARAMS PRINTED BELOW\n",
    "\n",
    "from skopt import BayesSearchCV #pip install scikit-optimize\n",
    "\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, BatchNormalization, Dropout\n",
    "from joblib import parallel_backend\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "def create_model(neurons, dropout_rate, num_layers, learning_rate):\n",
    "    input_layer = Input(shape=(X_train_dummy.shape[1],))\n",
    "\n",
    "    dense = Dense(neurons, kernel_initializer=tf.keras.initializers.HeNormal())(input_layer)\n",
    "    dense = BatchNormalization()(dense)\n",
    "    dense = tf.keras.activations.relu(dense)\n",
    "    dense = Dropout(dropout_rate)(dense)\n",
    "    \n",
    "    for i in range(num_layers - 1):\n",
    "        dense = Dense(neurons, kernel_initializer=tf.keras.initializers.HeNormal())(dense)\n",
    "        dense = BatchNormalization()(dense)\n",
    "        dense = tf.keras.activations.relu(dense)\n",
    "        dense = Dropout(dropout_rate)(dense)\n",
    "\n",
    "    output = Dense(1, activation='sigmoid')(dense)\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs=input_layer, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "wrapped_create_model = KerasClassifier(build_fn=create_model, verbose=1, epochs=25)\n",
    "\n",
    "param_space = {\n",
    "    'neurons': (8, 512),\n",
    "    'dropout_rate': (0.1, 0.5),\n",
    "    'num_layers': (1, 5),\n",
    "    'learning_rate': (0.0001, 0.1)\n",
    "}\n",
    "\n",
    "opt = BayesSearchCV(\n",
    "    wrapped_create_model,\n",
    "    param_space,\n",
    "    n_iter=50,\n",
    "    cv=3,\n",
    "    n_jobs=1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "opt.fit(X_train_dummy, y_train_dummy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = opt.best_params_\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_parameters = opt.best_params_\n",
    "\n",
    "optimal_model = create_model(\n",
    "    neurons=optimal_parameters['neurons'],\n",
    "    dropout_rate=optimal_parameters['dropout_rate'],\n",
    "    num_layers=optimal_parameters['num_layers'],\n",
    "    learning_rate=optimal_parameters['learning_rate']\n",
    ")\n",
    "\n",
    "history = optimal_model.fit(X_train_dummy, y_train_dummy, epochs=30, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = optimal_model.evaluate(X_test_dummy, y_test_dummy)\n",
    "print(\"Accuracy (tuned model):\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
