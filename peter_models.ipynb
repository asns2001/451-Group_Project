{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code_module</th>\n",
       "      <th>code_presentation</th>\n",
       "      <th>id_student</th>\n",
       "      <th>gender</th>\n",
       "      <th>region</th>\n",
       "      <th>highest_education</th>\n",
       "      <th>imd_band</th>\n",
       "      <th>age_band</th>\n",
       "      <th>num_of_prev_attempts</th>\n",
       "      <th>studied_credits</th>\n",
       "      <th>disability</th>\n",
       "      <th>final_result</th>\n",
       "      <th>score</th>\n",
       "      <th>grade</th>\n",
       "      <th>studied_credits_binned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAA</td>\n",
       "      <td>2013J</td>\n",
       "      <td>11391</td>\n",
       "      <td>M</td>\n",
       "      <td>East Anglian Region</td>\n",
       "      <td>HE Qualification</td>\n",
       "      <td>90-100%</td>\n",
       "      <td>55&lt;=</td>\n",
       "      <td>0</td>\n",
       "      <td>240</td>\n",
       "      <td>N</td>\n",
       "      <td>Pass</td>\n",
       "      <td>82.4</td>\n",
       "      <td>A-</td>\n",
       "      <td>201+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAA</td>\n",
       "      <td>2013J</td>\n",
       "      <td>28400</td>\n",
       "      <td>F</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>HE Qualification</td>\n",
       "      <td>20-30%</td>\n",
       "      <td>35-55</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>N</td>\n",
       "      <td>Pass</td>\n",
       "      <td>65.4</td>\n",
       "      <td>C</td>\n",
       "      <td>30-60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAA</td>\n",
       "      <td>2013J</td>\n",
       "      <td>31604</td>\n",
       "      <td>F</td>\n",
       "      <td>South East Region</td>\n",
       "      <td>A Level or Equivalent</td>\n",
       "      <td>50-60%</td>\n",
       "      <td>35-55</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>N</td>\n",
       "      <td>Pass</td>\n",
       "      <td>76.3</td>\n",
       "      <td>B</td>\n",
       "      <td>30-60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAA</td>\n",
       "      <td>2013J</td>\n",
       "      <td>32885</td>\n",
       "      <td>F</td>\n",
       "      <td>West Midlands Region</td>\n",
       "      <td>Lower Than A Level</td>\n",
       "      <td>50-60%</td>\n",
       "      <td>0-35</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>N</td>\n",
       "      <td>Pass</td>\n",
       "      <td>55.0</td>\n",
       "      <td>D</td>\n",
       "      <td>30-60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAA</td>\n",
       "      <td>2013J</td>\n",
       "      <td>38053</td>\n",
       "      <td>M</td>\n",
       "      <td>Wales</td>\n",
       "      <td>A Level or Equivalent</td>\n",
       "      <td>80-90%</td>\n",
       "      <td>35-55</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>N</td>\n",
       "      <td>Pass</td>\n",
       "      <td>66.9</td>\n",
       "      <td>C</td>\n",
       "      <td>30-60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  code_module code_presentation  id_student gender                region  \\\n",
       "0         AAA             2013J       11391      M   East Anglian Region   \n",
       "1         AAA             2013J       28400      F              Scotland   \n",
       "2         AAA             2013J       31604      F     South East Region   \n",
       "3         AAA             2013J       32885      F  West Midlands Region   \n",
       "4         AAA             2013J       38053      M                 Wales   \n",
       "\n",
       "       highest_education imd_band age_band  num_of_prev_attempts  \\\n",
       "0       HE Qualification  90-100%     55<=                     0   \n",
       "1       HE Qualification   20-30%    35-55                     0   \n",
       "2  A Level or Equivalent   50-60%    35-55                     0   \n",
       "3     Lower Than A Level   50-60%     0-35                     0   \n",
       "4  A Level or Equivalent   80-90%    35-55                     0   \n",
       "\n",
       "   studied_credits disability final_result  score grade studied_credits_binned  \n",
       "0              240          N         Pass   82.4    A-                   201+  \n",
       "1               60          N         Pass   65.4     C                  30-60  \n",
       "2               60          N         Pass   76.3     B                  30-60  \n",
       "3               60          N         Pass   55.0     D                  30-60  \n",
       "4               60          N         Pass   66.9     C                  30-60  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('data/student_info_cleaned.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23731 entries, 0 to 23730\n",
      "Data columns (total 15 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   code_module             23731 non-null  object \n",
      " 1   code_presentation       23731 non-null  object \n",
      " 2   id_student              23731 non-null  int64  \n",
      " 3   gender                  23731 non-null  object \n",
      " 4   region                  23731 non-null  object \n",
      " 5   highest_education       23731 non-null  object \n",
      " 6   imd_band                22740 non-null  object \n",
      " 7   age_band                23731 non-null  object \n",
      " 8   num_of_prev_attempts    23731 non-null  int64  \n",
      " 9   studied_credits         23731 non-null  int64  \n",
      " 10  disability              23731 non-null  object \n",
      " 11  final_result            23731 non-null  object \n",
      " 12  score                   23731 non-null  float64\n",
      " 13  grade                   23731 non-null  object \n",
      " 14  studied_credits_binned  23731 non-null  object \n",
      "dtypes: float64(1), int64(3), object(11)\n",
      "memory usage: 2.7+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['final_result'].value_counts()\n",
    "#drop withdrawn students\n",
    "data = data[data['final_result'] != 'Withdrawn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#order highest_education, imd_band, age_band, disability, studied_credits_binned, final_result\n",
    "highest_education = {\n",
    "    'No Formal quals': 0,\n",
    "    'Lower Than A Level': 1,\n",
    "    'A Level or Equivalent': 2,\n",
    "    'HE Qualification': 3,\n",
    "    'Post Graduate Qualification': 4\n",
    "}\n",
    "\n",
    "imd_band = {\n",
    "    np.nan: -1,\n",
    "    '0-10%': 0,\n",
    "    '10-20': 1,\n",
    "    '20-30%': 2,\n",
    "    '30-40%': 3,\n",
    "    '40-50%': 4,\n",
    "    '50-60%': 5,\n",
    "    '60-70%': 6,\n",
    "    '70-80%': 7,\n",
    "    '80-90%': 8,\n",
    "    '90-100%': 9\n",
    "}\n",
    "\n",
    "age_band = {\n",
    "    '0-35': 0,\n",
    "    '35-55': 1,\n",
    "    '55<=': 2\n",
    "}\n",
    "\n",
    "disability = {\n",
    "    'N': 0,\n",
    "    'Y': 1\n",
    "}\n",
    "\n",
    "studied_credits_binned = {\n",
    "    '30-60': 0,\n",
    "    '61-100': 1,\n",
    "    '101-200': 2,\n",
    "    '201+': 3\n",
    "}\n",
    "\n",
    "final_result = {\n",
    "    'Fail': 0,\n",
    "    'Pass': 1,\n",
    "    'Distinction': 1,\n",
    "    'Withdrawn': 0\n",
    "}\n",
    "\n",
    "data_dummies = pd.get_dummies(data, columns=['code_module', 'code_presentation', 'gender', 'region'])\n",
    "data_dummies['highest_education'] = data_dummies['highest_education'].map(highest_education)\n",
    "data_dummies['imd_band'] = data_dummies['imd_band'].map(imd_band)\n",
    "data_dummies['age_band'] = data_dummies['age_band'].map(age_band)\n",
    "data_dummies['disability'] = data_dummies['disability'].map(disability)\n",
    "data_dummies['studied_credits_binned'] = data_dummies['studied_credits_binned'].map(studied_credits_binned)\n",
    "data_dummies['final_result'] = data_dummies['final_result'].map(final_result)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "data_ordinal = data.copy()\n",
    "data_ordinal['highest_education'] = data_dummies['highest_education']\n",
    "data_ordinal['imd_band'] = data_dummies['imd_band']\n",
    "data_ordinal['age_band'] = data_dummies['age_band']\n",
    "data_ordinal['disability'] = data_dummies['disability']\n",
    "data_ordinal['studied_credits_binned'] = data_dummies['studied_credits_binned']\n",
    "data_ordinal['final_result'] = data_dummies['final_result']\n",
    "\n",
    "le = LabelEncoder()\n",
    "data_ordinal['code_module'] = le.fit_transform(data_ordinal['code_module'])\n",
    "data_ordinal['code_presentation'] = le.fit_transform(data_ordinal['code_presentation'])\n",
    "data_ordinal['gender'] = le.fit_transform(data_ordinal['gender'])\n",
    "data_ordinal['region'] = le.fit_transform(data_ordinal['region'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    13868\n",
       "0     5279\n",
       "Name: final_result, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dummies['final_result'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from imblearn.over_sampling import SMOTE#pip install imbalanced-learn\n",
    "\n",
    "\n",
    "\n",
    "X_dummy = data_dummies.drop(['final_result', 'studied_credits', 'id_student', 'score', 'grade'], axis=1)\n",
    "y_dummy = data_dummies['final_result']\n",
    "\n",
    "X_ord = data_ordinal.drop(['final_result', 'studied_credits', 'id_student', 'score', 'grade'], axis=1)\n",
    "y_ord = data_ordinal['final_result']\n",
    "\n",
    "smote = SMOTE(sampling_strategy='minority', random_state=42)\n",
    "X_dummy_smote, y_dummy_smote = smote.fit_resample(X_dummy, y_dummy)\n",
    "X_ord_smote, y_ord_smote = smote.fit_resample(X_ord, y_ord)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_dummy_smote = pd.read_csv('data/X_dummy_smote.csv')\n",
    "y_dummy_smote = pd.read_csv('data/y_dummy_smote.csv')\n",
    "X_ord_smote = pd.read_csv('data/X_ord_smote.csv')\n",
    "y_ord_smote = pd.read_csv('data/y_ord_smote.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_dummy, X_test_dummy, y_train_dummy, y_test_dummy = train_test_split(X_dummy_smote, y_dummy_smote, test_size=0.2, random_state=42)\n",
    "X_train_ord, X_test_ord, y_train_ord, y_test_ord = train_test_split(X_ord_smote, y_ord_smote, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Logistic Regression: 0.7339581831290555\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(max_iter=10000)\n",
    "logreg.fit(X_train_dummy, y_train_dummy)\n",
    "\n",
    "y_pred = logreg.predict(X_test_dummy)\n",
    "acc = accuracy_score(y_test_dummy, y_pred)\n",
    "print('Accuracy Logistic Regression:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy XGBoost: 0.7519826964671954\n"
     ]
    }
   ],
   "source": [
    "#XGBoost\n",
    "from xgboost import XGBClassifier #pip install xgboost\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(X_train_dummy, y_train_dummy)\n",
    "\n",
    "y_pred = xgb.predict(X_test_dummy)\n",
    "acc = accuracy_score(y_test_dummy, y_pred)\n",
    "print('Accuracy XGBoost:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Random Forest: 0.7543258832011536\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train_dummy, y_train_dummy)\n",
    "\n",
    "y_pred = rf.predict(X_test_dummy)\n",
    "acc = accuracy_score(y_test_dummy, y_pred)\n",
    "print('Accuracy Random Forest:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "categories = ['code_module', 'code_presentation', 'gender', 'region']\n",
    "numerical_features = [col for col in X_train_ord.columns if col not in categories]\n",
    "\n",
    "X_train_dummy = scaler.fit_transform(X_train_dummy)\n",
    "X_test_dummy = scaler.fit_transform(X_test_dummy)\n",
    "\n",
    "\n",
    "num_categories = []\n",
    "for category in categories:\n",
    "    num_categories.append(data_ordinal[category].nunique())\n",
    "\n",
    "X_train_ord_num = X_train_ord.drop(categories, axis=1)\n",
    "X_test_ord_num = X_test_ord.drop(categories, axis=1)\n",
    "X_train_ord_cat = X_train_ord[categories]\n",
    "X_test_ord_cat = X_test_ord[categories]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "555/555 [==============================] - 4s 6ms/step - loss: 0.6710 - accuracy: 0.6031 - val_loss: 0.6404 - val_accuracy: 0.6381\n",
      "Epoch 2/30\n",
      "555/555 [==============================] - 3s 6ms/step - loss: 0.6380 - accuracy: 0.6379 - val_loss: 0.6327 - val_accuracy: 0.6492\n",
      "Epoch 3/30\n",
      "555/555 [==============================] - 3s 6ms/step - loss: 0.6264 - accuracy: 0.6527 - val_loss: 0.6255 - val_accuracy: 0.6609\n",
      "Epoch 4/30\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 0.6295 - accuracy: 0.6488 - val_loss: 0.6292 - val_accuracy: 0.6575\n",
      "Epoch 5/30\n",
      "555/555 [==============================] - 3s 6ms/step - loss: 0.6236 - accuracy: 0.6551 - val_loss: 0.6268 - val_accuracy: 0.6525\n",
      "Epoch 6/30\n",
      "555/555 [==============================] - 3s 6ms/step - loss: 0.6248 - accuracy: 0.6545 - val_loss: 0.6252 - val_accuracy: 0.6548\n",
      "Epoch 7/30\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 0.6172 - accuracy: 0.6581 - val_loss: 0.6229 - val_accuracy: 0.6667\n",
      "Epoch 8/30\n",
      "555/555 [==============================] - 3s 6ms/step - loss: 0.6191 - accuracy: 0.6591 - val_loss: 0.6226 - val_accuracy: 0.6699\n",
      "Epoch 9/30\n",
      "555/555 [==============================] - 3s 6ms/step - loss: 0.6121 - accuracy: 0.6654 - val_loss: 0.6215 - val_accuracy: 0.6640\n",
      "Epoch 10/30\n",
      "555/555 [==============================] - 3s 6ms/step - loss: 0.6133 - accuracy: 0.6631 - val_loss: 0.6250 - val_accuracy: 0.6584\n",
      "Epoch 11/30\n",
      "555/555 [==============================] - 3s 6ms/step - loss: 0.6097 - accuracy: 0.6698 - val_loss: 0.6281 - val_accuracy: 0.6557\n",
      "Epoch 12/30\n",
      "555/555 [==============================] - 3s 6ms/step - loss: 0.6094 - accuracy: 0.6657 - val_loss: 0.6242 - val_accuracy: 0.6607\n",
      "Epoch 13/30\n",
      "555/555 [==============================] - 3s 6ms/step - loss: 0.6058 - accuracy: 0.6698 - val_loss: 0.6225 - val_accuracy: 0.6731\n",
      "Epoch 14/30\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 0.6091 - accuracy: 0.6687 - val_loss: 0.6203 - val_accuracy: 0.6670\n",
      "Epoch 15/30\n",
      "555/555 [==============================] - 3s 6ms/step - loss: 0.5999 - accuracy: 0.6746 - val_loss: 0.6218 - val_accuracy: 0.6640\n",
      "Epoch 16/30\n",
      "555/555 [==============================] - 3s 6ms/step - loss: 0.6028 - accuracy: 0.6702 - val_loss: 0.6190 - val_accuracy: 0.6685\n",
      "Epoch 17/30\n",
      "555/555 [==============================] - 3s 6ms/step - loss: 0.6013 - accuracy: 0.6746 - val_loss: 0.6276 - val_accuracy: 0.6573\n",
      "Epoch 18/30\n",
      "555/555 [==============================] - 3s 6ms/step - loss: 0.5960 - accuracy: 0.6800 - val_loss: 0.6211 - val_accuracy: 0.6712\n",
      "Epoch 19/30\n",
      "555/555 [==============================] - 3s 6ms/step - loss: 0.5965 - accuracy: 0.6779 - val_loss: 0.6262 - val_accuracy: 0.6564\n",
      "Epoch 20/30\n",
      "555/555 [==============================] - 3s 6ms/step - loss: 0.5911 - accuracy: 0.6867 - val_loss: 0.6206 - val_accuracy: 0.6697\n",
      "Epoch 21/30\n",
      "555/555 [==============================] - 3s 6ms/step - loss: 0.5991 - accuracy: 0.6772 - val_loss: 0.6274 - val_accuracy: 0.6654\n",
      "Epoch 22/30\n",
      "555/555 [==============================] - 3s 6ms/step - loss: 0.5964 - accuracy: 0.6803 - val_loss: 0.6211 - val_accuracy: 0.6697\n",
      "Epoch 23/30\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 0.5938 - accuracy: 0.6829 - val_loss: 0.6231 - val_accuracy: 0.6690\n",
      "Epoch 24/30\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 0.5897 - accuracy: 0.6877 - val_loss: 0.6199 - val_accuracy: 0.6645\n",
      "Epoch 25/30\n",
      "555/555 [==============================] - 3s 6ms/step - loss: 0.5843 - accuracy: 0.6908 - val_loss: 0.6226 - val_accuracy: 0.6749\n",
      "Epoch 26/30\n",
      "555/555 [==============================] - 3s 6ms/step - loss: 0.5841 - accuracy: 0.6908 - val_loss: 0.6226 - val_accuracy: 0.6638\n",
      "Epoch 27/30\n",
      "555/555 [==============================] - 3s 6ms/step - loss: 0.5880 - accuracy: 0.6848 - val_loss: 0.6239 - val_accuracy: 0.6712\n",
      "Epoch 28/30\n",
      "555/555 [==============================] - 3s 6ms/step - loss: 0.5800 - accuracy: 0.6985 - val_loss: 0.6241 - val_accuracy: 0.6726\n",
      "Epoch 29/30\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 0.5815 - accuracy: 0.6929 - val_loss: 0.6220 - val_accuracy: 0.6674\n",
      "Epoch 30/30\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 0.5769 - accuracy: 0.6983 - val_loss: 0.6237 - val_accuracy: 0.6604\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Embedding, Flatten, Dense, Concatenate, BatchNormalization\n",
    "\n",
    "\n",
    "# X_train_dummy = X_train_dummy.astype('float32')\n",
    "# y_train_dummy = y_train_dummy.astype('float32')\n",
    "# X_test_dummy = X_test_dummy.astype('float32')\n",
    "# y_test_dummy = y_test_dummy.astype('float32')\n",
    "\n",
    "X_train_ord_num = X_train_ord_num.astype('float32')\n",
    "X_train_ord_cat = X_train_ord_cat.astype('float32')\n",
    "y_train_ord = y_train_ord.astype('float32')\n",
    "X_test_ord_num = X_test_ord_num.astype('float32')\n",
    "X_test_ord_cat = X_test_ord_cat.astype('float32')\n",
    "y_test_ord = y_test_ord.astype('float32')\n",
    "\n",
    "embedding_inputs = []\n",
    "embeddings = []\n",
    "for i in range(len(num_categories)):\n",
    "    input_i = Input(shape=(1,))\n",
    "    embedding_size = min(np.ceil((num_categories[i])/2), 50 )  # embedding size rule of thumb\n",
    "    embedding_size = int(embedding_size)\n",
    "    embedding_i = Embedding(input_dim=num_categories[i], output_dim=embedding_size, input_length=1)(input_i)\n",
    "    embedding_i = Flatten()(embedding_i)\n",
    "    embedding_inputs.append(input_i)\n",
    "    embeddings.append(embedding_i)\n",
    "\n",
    "ordinal_input = Input(shape=(X_train_ord_num.shape[1],))\n",
    "combined = Concatenate()([*embeddings, ordinal_input])\n",
    "\n",
    "dense = Dense(64, kernel_initializer=tf.keras.initializers.HeNormal())(combined)\n",
    "dense = BatchNormalization()(dense)\n",
    "dense = tf.keras.activations.relu(dense)\n",
    "\n",
    "dense = Dense(64, kernel_initializer=tf.keras.initializers.HeNormal())(dense)\n",
    "dense = BatchNormalization()(dense)\n",
    "dense = tf.keras.activations.relu(dense)\n",
    "\n",
    "dense = Dense(64, kernel_initializer=tf.keras.initializers.HeNormal())(dense)\n",
    "dense = BatchNormalization()(dense)\n",
    "dense = tf.keras.activations.relu(dense)\n",
    "\n",
    "output = Dense(1, activation='sigmoid')(dense)\n",
    "\n",
    "model = tf.keras.Model(inputs=[*embedding_inputs, ordinal_input], outputs=output)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001, clipvalue=1.0)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Convert each column in X_train_ord_cat to a Numpy array\n",
    "X_train_ord_cat_np = [X_train_ord_cat[category].to_numpy() for category in categories]\n",
    "\n",
    "# Convert X_train_ord_num to a Numpy array\n",
    "X_train_ord_num_np = X_train_ord_num.to_numpy()\n",
    "\n",
    "history = model.fit([*X_train_ord_cat_np, X_train_ord_num_np], y_train_ord, epochs=30, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 0.6704 - accuracy: 0.6058 - val_loss: 0.5645 - val_accuracy: 0.7080\n",
      "Epoch 2/30\n",
      "555/555 [==============================] - 2s 4ms/step - loss: 0.5937 - accuracy: 0.6769 - val_loss: 0.5405 - val_accuracy: 0.7186\n",
      "Epoch 3/30\n",
      "555/555 [==============================] - 2s 4ms/step - loss: 0.5637 - accuracy: 0.6941 - val_loss: 0.5251 - val_accuracy: 0.7210\n",
      "Epoch 4/30\n",
      "555/555 [==============================] - 2s 4ms/step - loss: 0.5493 - accuracy: 0.7049 - val_loss: 0.5072 - val_accuracy: 0.7325\n",
      "Epoch 5/30\n",
      "555/555 [==============================] - 2s 4ms/step - loss: 0.5325 - accuracy: 0.7138 - val_loss: 0.5005 - val_accuracy: 0.7409\n",
      "Epoch 6/30\n",
      "555/555 [==============================] - 2s 4ms/step - loss: 0.5236 - accuracy: 0.7176 - val_loss: 0.4952 - val_accuracy: 0.7409\n",
      "Epoch 7/30\n",
      "555/555 [==============================] - 2s 4ms/step - loss: 0.5189 - accuracy: 0.7213 - val_loss: 0.4895 - val_accuracy: 0.7434\n",
      "Epoch 8/30\n",
      "555/555 [==============================] - 2s 4ms/step - loss: 0.5120 - accuracy: 0.7289 - val_loss: 0.4884 - val_accuracy: 0.7375\n",
      "Epoch 9/30\n",
      "555/555 [==============================] - 2s 4ms/step - loss: 0.5034 - accuracy: 0.7303 - val_loss: 0.4862 - val_accuracy: 0.7413\n",
      "Epoch 10/30\n",
      "555/555 [==============================] - 2s 4ms/step - loss: 0.5064 - accuracy: 0.7300 - val_loss: 0.4846 - val_accuracy: 0.7420\n",
      "Epoch 11/30\n",
      "555/555 [==============================] - 2s 4ms/step - loss: 0.5024 - accuracy: 0.7341 - val_loss: 0.4840 - val_accuracy: 0.7427\n",
      "Epoch 12/30\n",
      "555/555 [==============================] - 3s 5ms/step - loss: 0.4930 - accuracy: 0.7366 - val_loss: 0.4831 - val_accuracy: 0.7409\n",
      "Epoch 13/30\n",
      "555/555 [==============================] - 2s 4ms/step - loss: 0.4970 - accuracy: 0.7352 - val_loss: 0.4818 - val_accuracy: 0.7429\n",
      "Epoch 14/30\n",
      "555/555 [==============================] - 2s 4ms/step - loss: 0.4824 - accuracy: 0.7494 - val_loss: 0.4805 - val_accuracy: 0.7445\n",
      "Epoch 15/30\n",
      "555/555 [==============================] - 2s 4ms/step - loss: 0.4896 - accuracy: 0.7425 - val_loss: 0.4819 - val_accuracy: 0.7447\n",
      "Epoch 16/30\n",
      "555/555 [==============================] - 2s 4ms/step - loss: 0.4835 - accuracy: 0.7424 - val_loss: 0.4816 - val_accuracy: 0.7422\n",
      "Epoch 17/30\n",
      "555/555 [==============================] - 2s 4ms/step - loss: 0.4787 - accuracy: 0.7491 - val_loss: 0.4805 - val_accuracy: 0.7431\n",
      "Epoch 18/30\n",
      "555/555 [==============================] - 2s 4ms/step - loss: 0.4896 - accuracy: 0.7341 - val_loss: 0.4790 - val_accuracy: 0.7476\n",
      "Epoch 19/30\n",
      "555/555 [==============================] - 2s 4ms/step - loss: 0.4847 - accuracy: 0.7424 - val_loss: 0.4821 - val_accuracy: 0.7418\n",
      "Epoch 20/30\n",
      "555/555 [==============================] - 2s 4ms/step - loss: 0.4824 - accuracy: 0.7439 - val_loss: 0.4790 - val_accuracy: 0.7449\n",
      "Epoch 21/30\n",
      "555/555 [==============================] - 2s 4ms/step - loss: 0.4829 - accuracy: 0.7465 - val_loss: 0.4785 - val_accuracy: 0.7497\n",
      "Epoch 22/30\n",
      "555/555 [==============================] - 2s 4ms/step - loss: 0.4797 - accuracy: 0.7465 - val_loss: 0.4798 - val_accuracy: 0.7440\n",
      "Epoch 23/30\n",
      "555/555 [==============================] - 2s 4ms/step - loss: 0.4779 - accuracy: 0.7517 - val_loss: 0.4799 - val_accuracy: 0.7485\n",
      "Epoch 24/30\n",
      "555/555 [==============================] - 2s 4ms/step - loss: 0.4832 - accuracy: 0.7445 - val_loss: 0.4790 - val_accuracy: 0.7463\n",
      "Epoch 25/30\n",
      "555/555 [==============================] - 2s 4ms/step - loss: 0.4856 - accuracy: 0.7413 - val_loss: 0.4779 - val_accuracy: 0.7470\n",
      "Epoch 26/30\n",
      "555/555 [==============================] - 2s 4ms/step - loss: 0.4747 - accuracy: 0.7540 - val_loss: 0.4795 - val_accuracy: 0.7481\n",
      "Epoch 27/30\n",
      "555/555 [==============================] - 2s 4ms/step - loss: 0.4819 - accuracy: 0.7478 - val_loss: 0.4791 - val_accuracy: 0.7499\n",
      "Epoch 28/30\n",
      "555/555 [==============================] - 2s 4ms/step - loss: 0.4769 - accuracy: 0.7510 - val_loss: 0.4795 - val_accuracy: 0.7465\n",
      "Epoch 29/30\n",
      "555/555 [==============================] - 2s 4ms/step - loss: 0.4759 - accuracy: 0.7503 - val_loss: 0.4794 - val_accuracy: 0.7481\n",
      "Epoch 30/30\n",
      "555/555 [==============================] - 2s 4ms/step - loss: 0.4845 - accuracy: 0.7470 - val_loss: 0.4779 - val_accuracy: 0.7488\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "input_layer = Input(shape=(X_train_dummy.shape[1],))\n",
    "\n",
    "dense = Dense(128, kernel_initializer=tf.keras.initializers.HeNormal())(input_layer)\n",
    "dense = BatchNormalization()(dense)\n",
    "dense = tf.keras.activations.relu(dense)\n",
    "dense = Dropout(0.2)(dense)\n",
    "\n",
    "dense = Dense(64, kernel_initializer=tf.keras.initializers.HeNormal())(dense)\n",
    "dense = BatchNormalization()(dense)\n",
    "dense = tf.keras.activations.relu(dense)\n",
    "dense = Dropout(0.2)(dense)\n",
    "\n",
    "dense = Dense(64, kernel_initializer=tf.keras.initializers.HeNormal())(dense)\n",
    "dense = BatchNormalization()(dense)\n",
    "dense = tf.keras.activations.relu(dense)\n",
    "dense = Dropout(0.2)(dense)\n",
    "\n",
    "output = Dense(1, activation='sigmoid')(dense)\n",
    "\n",
    "model2 = tf.keras.models.Model(inputs=input_layer, outputs=output)\n",
    "\n",
    "model2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "hist2 = model2.fit(X_train_dummy, y_train_dummy, epochs=30, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(hist2.history['loss'])\n",
    "plt.plot(hist2.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'just_fix_windows_console' from 'colorama' (/opt/conda/lib/python3.8/site-packages/colorama/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[0;32mIn [46]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbayes_opt\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BayesianOptimization\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Adam\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_model\u001b[39m(neurons, dropout_rate, num_layers, learning_rate):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/bayes_opt/__init__.py:1\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbayesian_optimization\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BayesianOptimization, Events\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdomain_reduction\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SequentialDomainReductionTransformer\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m UtilityFunction\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/bayes_opt/bayesian_optimization.py:5\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbayes_opt\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstraint\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ConstraintModel\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtarget_space\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TargetSpace\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevent\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Events, DEFAULT_EVENTS\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlogger\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _get_default_logger\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/bayes_opt/target_space.py:4\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ensure_rng, NotUniqueError\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Colours\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_hashable\u001b[39m(x):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/bayes_opt/util.py:5\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m norm\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimize\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m minimize\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcolorama\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m just_fix_windows_console\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21macq_max\u001b[39m(ac, gp, y_max, bounds, random_state, constraint\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, n_warmup\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10000\u001b[39m, n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m):\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124;03m    A function to find the maximum of the acquisition function\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;124;03m    :return: x_max, The arg max of the acquisition function.\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'just_fix_windows_console' from 'colorama' (/opt/conda/lib/python3.8/site-packages/colorama/__init__.py)"
     ]
    }
   ],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def create_model(neurons, dropout_rate, num_layers, learning_rate):\n",
    "    input_layer = Input(shape=(X_train_dummy.shape[1],))\n",
    "\n",
    "    dense = Dense(neurons, kernel_initializer=tf.keras.initializers.HeNormal())(input_layer)\n",
    "    dense = BatchNormalization()(dense)\n",
    "    dense = tf.keras.activations.relu(dense)\n",
    "    dense = Dropout(dropout_rate)(dense)\n",
    "    \n",
    "    for i in range(num_layers - 1):\n",
    "        dense = Dense(neurons, kernel_initializer=tf.keras.initializers.HeNormal())(dense)\n",
    "        dense = BatchNormalization()(dense)\n",
    "        dense = tf.keras.activations.relu(dense)\n",
    "        dense = Dropout(dropout_rate)(dense)\n",
    "\n",
    "    output = Dense(1, activation='sigmoid')(dense)\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs=input_layer, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def fit_with(neurons, dropout_rate, num_layers, learning_rate):\n",
    "    model = create_model(neurons, dropout_rate, num_layers, learning_rate)\n",
    "    model.fit(X_train_dummy, y_train_dummy, epochs=20, validation_split=0.2, verbose=0)\n",
    "    score = model.evaluate(X_test_dummy, y_test_dummy, verbose=0)\n",
    "    return score[1]\n",
    "\n",
    "pbounds = {\n",
    "    'neurons': (8, 512),\n",
    "    'dropout_rate': (0.1, 0.5),\n",
    "    'num_layers': (1, 5),\n",
    "    'learning_rate': (0.0001, 0.1)\n",
    "}\n",
    "\n",
    "optimizer = BayesianOptimization(\n",
    "    f=fit_with,\n",
    "    pbounds=pbounds,\n",
    "    verbose=2,\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "optimizer.maximize(init_points=10, n_iter=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
