{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>final_result</th>\n",
       "      <th>score</th>\n",
       "      <th>id_student</th>\n",
       "      <th>code_module</th>\n",
       "      <th>code_presentation</th>\n",
       "      <th>mean_sum_click</th>\n",
       "      <th>total_sum_click</th>\n",
       "      <th>days_logged</th>\n",
       "      <th>material_interactions</th>\n",
       "      <th>module_length</th>\n",
       "      <th>...</th>\n",
       "      <th>region</th>\n",
       "      <th>highest_education</th>\n",
       "      <th>imd_band</th>\n",
       "      <th>age_band</th>\n",
       "      <th>num_of_prev_attempts</th>\n",
       "      <th>studied_credits</th>\n",
       "      <th>disability</th>\n",
       "      <th>grade</th>\n",
       "      <th>studied_credits_binned</th>\n",
       "      <th>date_registration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pass</td>\n",
       "      <td>82.4</td>\n",
       "      <td>11391</td>\n",
       "      <td>AAA</td>\n",
       "      <td>2013J</td>\n",
       "      <td>4.765306</td>\n",
       "      <td>934.0</td>\n",
       "      <td>40</td>\n",
       "      <td>55</td>\n",
       "      <td>268</td>\n",
       "      <td>...</td>\n",
       "      <td>East Anglian Region</td>\n",
       "      <td>HE Qualification</td>\n",
       "      <td>90-100%</td>\n",
       "      <td>55&lt;=</td>\n",
       "      <td>0</td>\n",
       "      <td>240</td>\n",
       "      <td>N</td>\n",
       "      <td>A-</td>\n",
       "      <td>201+</td>\n",
       "      <td>-159.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pass</td>\n",
       "      <td>65.4</td>\n",
       "      <td>28400</td>\n",
       "      <td>AAA</td>\n",
       "      <td>2013J</td>\n",
       "      <td>3.337209</td>\n",
       "      <td>1435.0</td>\n",
       "      <td>80</td>\n",
       "      <td>84</td>\n",
       "      <td>268</td>\n",
       "      <td>...</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>HE Qualification</td>\n",
       "      <td>20-30%</td>\n",
       "      <td>35-55</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>N</td>\n",
       "      <td>C</td>\n",
       "      <td>30-60</td>\n",
       "      <td>-53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pass</td>\n",
       "      <td>76.3</td>\n",
       "      <td>31604</td>\n",
       "      <td>AAA</td>\n",
       "      <td>2013J</td>\n",
       "      <td>3.254902</td>\n",
       "      <td>2158.0</td>\n",
       "      <td>123</td>\n",
       "      <td>82</td>\n",
       "      <td>268</td>\n",
       "      <td>...</td>\n",
       "      <td>South East Region</td>\n",
       "      <td>A Level or Equivalent</td>\n",
       "      <td>50-60%</td>\n",
       "      <td>35-55</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>N</td>\n",
       "      <td>B</td>\n",
       "      <td>30-60</td>\n",
       "      <td>-52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pass</td>\n",
       "      <td>55.0</td>\n",
       "      <td>32885</td>\n",
       "      <td>AAA</td>\n",
       "      <td>2013J</td>\n",
       "      <td>2.937500</td>\n",
       "      <td>1034.0</td>\n",
       "      <td>70</td>\n",
       "      <td>66</td>\n",
       "      <td>268</td>\n",
       "      <td>...</td>\n",
       "      <td>West Midlands Region</td>\n",
       "      <td>Lower Than A Level</td>\n",
       "      <td>50-60%</td>\n",
       "      <td>0-35</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>N</td>\n",
       "      <td>D</td>\n",
       "      <td>30-60</td>\n",
       "      <td>-176.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pass</td>\n",
       "      <td>66.9</td>\n",
       "      <td>38053</td>\n",
       "      <td>AAA</td>\n",
       "      <td>2013J</td>\n",
       "      <td>3.381743</td>\n",
       "      <td>2445.0</td>\n",
       "      <td>143</td>\n",
       "      <td>88</td>\n",
       "      <td>268</td>\n",
       "      <td>...</td>\n",
       "      <td>Wales</td>\n",
       "      <td>A Level or Equivalent</td>\n",
       "      <td>80-90%</td>\n",
       "      <td>35-55</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>N</td>\n",
       "      <td>C</td>\n",
       "      <td>30-60</td>\n",
       "      <td>-110.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  final_result  score  id_student code_module code_presentation  \\\n",
       "0         Pass   82.4       11391         AAA             2013J   \n",
       "1         Pass   65.4       28400         AAA             2013J   \n",
       "2         Pass   76.3       31604         AAA             2013J   \n",
       "3         Pass   55.0       32885         AAA             2013J   \n",
       "4         Pass   66.9       38053         AAA             2013J   \n",
       "\n",
       "   mean_sum_click  total_sum_click  days_logged  material_interactions  \\\n",
       "0        4.765306            934.0           40                     55   \n",
       "1        3.337209           1435.0           80                     84   \n",
       "2        3.254902           2158.0          123                     82   \n",
       "3        2.937500           1034.0           70                     66   \n",
       "4        3.381743           2445.0          143                     88   \n",
       "\n",
       "   module_length  ...                region      highest_education  imd_band  \\\n",
       "0            268  ...   East Anglian Region       HE Qualification   90-100%   \n",
       "1            268  ...              Scotland       HE Qualification    20-30%   \n",
       "2            268  ...     South East Region  A Level or Equivalent    50-60%   \n",
       "3            268  ...  West Midlands Region     Lower Than A Level    50-60%   \n",
       "4            268  ...                 Wales  A Level or Equivalent    80-90%   \n",
       "\n",
       "   age_band  num_of_prev_attempts  studied_credits disability grade  \\\n",
       "0      55<=                     0              240          N    A-   \n",
       "1     35-55                     0               60          N     C   \n",
       "2     35-55                     0               60          N     B   \n",
       "3      0-35                     0               60          N     D   \n",
       "4     35-55                     0               60          N     C   \n",
       "\n",
       "  studied_credits_binned date_registration  \n",
       "0                   201+            -159.0  \n",
       "1                  30-60             -53.0  \n",
       "2                  30-60             -52.0  \n",
       "3                  30-60            -176.0  \n",
       "4                  30-60            -110.0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "student_info = pd.read_csv('data/student_info_cleaned.csv')\n",
    "\n",
    "assessments = pd.read_csv('data/assessments.csv')\n",
    "courses = pd.read_csv('data/courses.csv') # DONE\n",
    "student_assessments = pd.read_csv('data/studentAssessment.csv')\n",
    " # IDK how to use???\n",
    "# student_info = pd.read_csv('data/studentInfo.csv')\n",
    "registration = pd.read_csv('data/studentRegistration.csv')\n",
    "student_vle= pd.read_csv('data/studentVle.csv')\n",
    "vle = pd.read_csv('data/vle.csv')\n",
    "\n",
    "datasets = {\n",
    "    'assessments':assessments,\n",
    "    'courses':courses,\n",
    "    'student_assessments':student_assessments,\n",
    "    'student_info':student_info,\n",
    "    'registration':registration,\n",
    "    'student_vle':student_vle,\n",
    "    'vle':vle}\n",
    "\n",
    "student_df = student_info.merge(registration, how='inner', on=[\"code_module\", \"code_presentation\", \"id_student\"])\n",
    "student_df = student_df.drop(columns='date_unregistration')\n",
    "\n",
    "svle = student_vle.groupby(['code_module', 'code_presentation', 'id_student']).agg({'sum_click': ['mean', 'sum'], 'date': 'nunique', 'id_site': 'nunique'}).reset_index()\n",
    "svle.columns = ['code_module', 'code_presentation', 'id_student', 'mean_sum_click', 'total_sum_click', 'unique_date_count', 'unique_id_site_count']\n",
    "\n",
    "svle = pd.merge(svle, courses, on=['code_module', 'code_presentation'], how='left')\n",
    "svle['avg click/day'] =  svle['total_sum_click'] / svle['module_presentation_length']\n",
    "\n",
    "svle = svle.rename(columns={'unique_date_count': 'days_logged', 'unique_id_site_count': 'material_interactions', 'module_presentation_length': 'module_length'})\n",
    "\n",
    "vle_n = vle.groupby(['code_module', 'code_presentation'])['id_site'].nunique().reset_index()\n",
    "svle = pd.merge(svle, vle_n, on=['code_module', 'code_presentation'], how='left')\n",
    "svle['% material interaction'] =  100*svle['material_interactions'] / svle['id_site']\n",
    "\n",
    "assessment_counts = assessments.groupby(['code_module', 'code_presentation'])['assessment_type'].value_counts().reset_index(name='count')\n",
    "assessment_pivot = assessment_counts.pivot_table(index=['code_module', 'code_presentation'], columns='assessment_type', values='count', fill_value=0).reset_index()\n",
    "assessment_pivot.columns.name = None  \n",
    "assessment_pivot.columns = ['code_module', 'code_presentation', 'CMA', 'Exam', 'TMA']\n",
    "svle = pd.merge(svle, assessment_pivot, on=['code_module', 'code_presentation'], how='left')\n",
    "\n",
    "df_all = pd.merge(svle, student_df, on=['code_module', 'code_presentation', 'id_student'], how='inner')\n",
    "columns_to_move = ['final_result', 'score', 'id_student']\n",
    "df_all = df_all[columns_to_move + [col for col in df_all.columns if col not in columns_to_move]]\n",
    "\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13169, 27)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop withdrawn students\n",
    "df_all = df_all[df_all['final_result'] != 'Withdrawn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13169, 47)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "#order highest_education, imd_band, age_band, disability, studied_credits_binned, final_result\n",
    "highest_education = {\n",
    "    'No Formal quals': 0,\n",
    "    'Lower Than A Level': 1,\n",
    "    'A Level or Equivalent': 2,\n",
    "    'HE Qualification': 3,\n",
    "    'Post Graduate Qualification': 4\n",
    "}\n",
    "\n",
    "imd_band = {\n",
    "    np.nan: -1,\n",
    "    '0-10%': 0,\n",
    "    '10-20': 1,\n",
    "    '20-30%': 2,\n",
    "    '30-40%': 3,\n",
    "    '40-50%': 4,\n",
    "    '50-60%': 5,\n",
    "    '60-70%': 6,\n",
    "    '70-80%': 7,\n",
    "    '80-90%': 8,\n",
    "    '90-100%': 9\n",
    "}\n",
    "\n",
    "age_band = {\n",
    "    '0-35': 0,\n",
    "    '35-55': 1,\n",
    "    '55<=': 2\n",
    "}\n",
    "\n",
    "disability = {\n",
    "    'N': 0,\n",
    "    'Y': 1\n",
    "}\n",
    "\n",
    "studied_credits_binned = {\n",
    "    '30-60': 0,\n",
    "    '61-100': 1,\n",
    "    '101-200': 2,\n",
    "    '201+': 3\n",
    "}\n",
    "\n",
    "final_result = {\n",
    "    'Fail': 0,\n",
    "    'Pass': 1,\n",
    "    'Distinction': 1,\n",
    "    'Withdrawn': 0\n",
    "}\n",
    "\n",
    "data_dummies = pd.get_dummies(df_all, columns=['code_module', 'code_presentation', 'gender', 'region'])\n",
    "data_dummies['highest_education'] = data_dummies['highest_education'].map(highest_education)\n",
    "data_dummies['imd_band'] = data_dummies['imd_band'].map(imd_band)\n",
    "data_dummies['age_band'] = data_dummies['age_band'].map(age_band)\n",
    "data_dummies['disability'] = data_dummies['disability'].map(disability)\n",
    "data_dummies['studied_credits_binned'] = data_dummies['studied_credits_binned'].map(studied_credits_binned)\n",
    "data_dummies['final_result'] = data_dummies['final_result'].map(final_result)\n",
    "data_dummies.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dummies = data_dummies[~((data_dummies['score'] > 50) & (data_dummies['final_result'] == 0))]\n",
    "data_dummies = data_dummies[~((data_dummies['score'] < 50) & (data_dummies['final_result'] == 1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10737, 47)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dummies.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_407/2502644455.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y_dummy['score'] = X_dummy_combined['score']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from imblearn.over_sampling import SMOTE#pip install imbalanced-learn\n",
    "\n",
    "\n",
    "\n",
    "X_dummy = data_dummies.drop(['final_result', 'studied_credits', 'id_student', 'score', 'grade'], axis=1)\n",
    "X_dummy_combined = X_dummy.copy()\n",
    "X_dummy_combined['score'] = data_dummies['score']\n",
    "# X_dummy_combined.loc[(X_dummy_combined['score'] < 50) & (y_dummy['final_result'] == 1), 'score'] = 76\n",
    "# X_dummy_combined.loc[y_dummy['final_result'] == 0, 'score'] = 35\n",
    "\n",
    "\n",
    "y_dummy = data_dummies[['final_result']]\n",
    "\n",
    "smote = SMOTE(sampling_strategy='minority', random_state=42)\n",
    "X_dummy_smote, y_dummy_smote = smote.fit_resample(X_dummy_combined, y_dummy)\n",
    "\n",
    "y_dummy_smote['score'] = X_dummy_smote['score']\n",
    "y_dummy['score'] = X_dummy_combined['score']\n",
    "X_dummy_smote = X_dummy_smote.drop(['score'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1z/_j8y7ndj06788g4f84n47dqm0000gn/T/ipykernel_18029/3644116101.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_dummy_smote = pd.read_csv('data/X_dummy_smote.csv')\n",
    "y_dummy_smote = pd.read_csv('data/y_dummy_smote.csv')\n",
    "X_ord_smote = pd.read_csv('data/X_ord_smote.csv')\n",
    "y_ord_smote = pd.read_csv('data/y_ord_smote.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18934, 42)\n",
      "(18934, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    9467\n",
       "0    9467\n",
       "Name: final_result, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_dummy_smote.shape)\n",
    "print(y_dummy_smote.shape)\n",
    "y_dummy_smote['final_result'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_dummy, X_test_dummy, y_train_dummy, y_test_dummy = train_test_split(X_dummy_smote, y_dummy_smote, test_size=0.2, random_state=42, stratify=y_dummy_smote['final_result'])\n",
    "# X_train_ord, X_test_ord, y_train_ord, y_test_ord = train_test_split(X_ord_smote, y_ord_smote, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Logistic Regression: 0.9308159493002377\n",
      "Confusion Matrix:\n",
      "[[1695  199]\n",
      " [  63 1830]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_recall_curve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(max_iter=20000)\n",
    "logreg.fit(X_train_dummy, y_train_dummy['final_result'])\n",
    "\n",
    "y_pred = logreg.predict(X_test_dummy)\n",
    "acc = accuracy_score(y_test_dummy['final_result'], y_pred)\n",
    "print('Accuracy Logistic Regression:', acc)\n",
    "\n",
    "cm = confusion_matrix(y_test_dummy['final_result'], y_pred)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBoost\n",
    "from xgboost import XGBClassifier #pip install xgboost\n",
    "from skopt import BayesSearchCV\n",
    "\n",
    "# Define the parameter space\n",
    "param_space = {\n",
    "    'learning_rate': (0.01, 1.0, 'log-uniform'),\n",
    "    'min_child_weight': (1, 10),\n",
    "    'max_depth': (3, 50),\n",
    "    'max_delta_step': (1, 20),\n",
    "    'subsample': (0.01, 1.0, 'uniform'),\n",
    "    'colsample_bytree': (0.01, 1.0, 'uniform'),\n",
    "    'colsample_bylevel': (0.01, 1.0, 'uniform'),\n",
    "    'reg_lambda': (1e-9, 1000, 'log-uniform'),\n",
    "    'reg_alpha': (1e-9, 1.0, 'log-uniform'),\n",
    "    'gamma': (1e-9, 0.5, 'log-uniform'),\n",
    "    'n_estimators': (50, 200),\n",
    "    'scale_pos_weight': (1e-6, 500, 'log-uniform')\n",
    "}\n",
    "\n",
    "# Create a BayesSearchCV object\n",
    "opt_xgb = BayesSearchCV(\n",
    "    estimator=XGBClassifier(n_jobs=-1),\n",
    "    search_spaces=param_space,\n",
    "    scoring='roc_auc',\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    n_iter=150,\n",
    "    verbose=1,\n",
    "    refit=True,\n",
    ")\n",
    "\n",
    "# Run the optimization\n",
    "opt_xgb.fit(X_train_dummy, y_train_dummy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy XGBoost: 0.9384737259044098\n",
      "Confusion Matrix:\n",
      "[[1738  156]\n",
      " [  77 1816]]\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier #pip install xgboost\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(X_train_dummy, y_train_dummy['final_result'])\n",
    "\n",
    "y_pred = xgb.predict(X_test_dummy)\n",
    "acc = accuracy_score(y_test_dummy['final_result'], y_pred)\n",
    "print(\"Accuracy XGBoost:\", acc)\n",
    "\n",
    "cm = confusion_matrix(y_test_dummy['final_result'], y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from skopt import BayesSearchCV\n",
    "\n",
    "counter = [0]\n",
    "\n",
    "def on_step(optim_result):\n",
    "    # Increment the counter\n",
    "    counter[0] += 1\n",
    "    print(f\"Completed iteration {counter[0]}\")\n",
    "    \n",
    "cb = CatBoostClassifier(verbose=False)\n",
    "\n",
    "# Define search spaces\n",
    "param_space = {\n",
    "    'iterations': (50, 1000),\n",
    "    'depth': (1, 16),\n",
    "    'learning_rate': (0.01, 1.0, 'log-uniform'),\n",
    "    'random_strength': (1e-9, 10, 'log-uniform'),\n",
    "    'bagging_temperature': (0.0, 1.0),\n",
    "    'border_count': (1, 255),\n",
    "    'l2_leaf_reg': (2, 30),\n",
    "    'scale_pos_weight':(0.01, 1.0, 'uniform')\n",
    "}\n",
    "\n",
    "# Initialize BayesSearchCV\n",
    "opt_cb = BayesSearchCV(\n",
    "    estimator=cb,\n",
    "    search_spaces=param_space,\n",
    "    scoring='accuracy',\n",
    "    n_iter=50,\n",
    "    n_jobs=-1,\n",
    "    return_train_score=False,\n",
    "    refit=True,\n",
    "    optimizer_kwargs={'base_estimator': 'GP'},\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "opt_cb.fit(X_train_dummy, y_train_dummy, callback=on_step)\n",
    "\n",
    "# Print best parameters and score\n",
    "print(f'Best parameters: {opt_cb.best_params_}')\n",
    "print(f'Best score: {opt_cb.best_score_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy CatBoost: 0.9437549511486665\n",
      "Confusion Matrix:\n",
      "[[1748  146]\n",
      " [  67 1826]]\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "from catboost import CatBoostClassifier #pip install catboost\n",
    "\n",
    "params = OrderedDict([('bagging_temperature', 1.0), ('border_count', 148), ('depth', 13), ('iterations', 976), ('l2_leaf_reg', 30), ('learning_rate', 0.02389354323083735), ('random_strength', 1e-09), ('scale_pos_weight', 0.9510644977326121)])\n",
    "params['iterations'] = 1000\n",
    "\n",
    "cb = CatBoostClassifier(**params, verbose=False)\n",
    "cb.fit(X_train_dummy, y_train_dummy['final_result'])\n",
    "\n",
    "y_pred = cb.predict(X_test_dummy)\n",
    "acc = accuracy_score(y_test_dummy['final_result'], y_pred)\n",
    "print('Accuracy CatBoost:', acc)\n",
    "cm = confusion_matrix(y_test_dummy['final_result'], y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Random Forest: 0.9390018484288355\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train_dummy, y_train_dummy['final_result'])\n",
    "\n",
    "y_pred = rf.predict(X_test_dummy)\n",
    "acc = accuracy_score(y_test_dummy['final_result'], y_pred)\n",
    "print('Accuracy Random Forest:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "categories = ['code_module', 'code_presentation', 'gender', 'region']\n",
    "numerical_features = [col for col in X_train_ord.columns if col not in categories]\n",
    "\n",
    "X_train_dummy = scaler.fit_transform(X_train_dummy)\n",
    "X_test_dummy = scaler.fit_transform(X_test_dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>final_result</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19901</th>\n",
       "      <td>0</td>\n",
       "      <td>77.718532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14299</th>\n",
       "      <td>1</td>\n",
       "      <td>84.191919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25453</th>\n",
       "      <td>0</td>\n",
       "      <td>84.567035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6573</th>\n",
       "      <td>1</td>\n",
       "      <td>85.348315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11571</th>\n",
       "      <td>0</td>\n",
       "      <td>67.857143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       final_result      score\n",
       "19901             0  77.718532\n",
       "14299             1  84.191919\n",
       "25453             0  84.567035\n",
       "6573              1  85.348315\n",
       "11571             0  67.857143"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_dummy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-26 20:43:50.365305: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2024-03-26 20:43:51.439909: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2024-03-26 20:43:51.439995: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2024-03-26 20:43:51.443593: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:ca:00.0 name: NVIDIA A40 computeCapability: 8.6\n",
      "coreClock: 1.74GHz coreCount: 84 deviceMemorySize: 44.38GiB deviceMemoryBandwidth: 648.29GiB/s\n",
      "2024-03-26 20:43:51.443622: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2024-03-26 20:43:51.446057: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2024-03-26 20:43:51.446116: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2024-03-26 20:43:51.447162: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2024-03-26 20:43:51.447431: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2024-03-26 20:43:51.450003: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2024-03-26 20:43:51.450613: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2024-03-26 20:43:51.450768: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2024-03-26 20:43:51.455450: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2024-03-26 20:43:51.456464: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-26 20:43:51.463731: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2024-03-26 20:43:51.466778: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:ca:00.0 name: NVIDIA A40 computeCapability: 8.6\n",
      "coreClock: 1.74GHz coreCount: 84 deviceMemorySize: 44.38GiB deviceMemoryBandwidth: 648.29GiB/s\n",
      "2024-03-26 20:43:51.466878: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2024-03-26 20:43:51.466945: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2024-03-26 20:43:51.466999: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2024-03-26 20:43:51.467052: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2024-03-26 20:43:51.467105: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2024-03-26 20:43:51.467157: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2024-03-26 20:43:51.467209: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2024-03-26 20:43:51.467262: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2024-03-26 20:43:51.472009: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2024-03-26 20:43:51.472057: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2024-03-26 20:43:51.979286: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2024-03-26 20:43:51.979330: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2024-03-26 20:43:51.979339: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2024-03-26 20:43:51.981809: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 42329 MB memory) -> physical GPU (device: 0, name: NVIDIA A40, pci bus id: 0000:ca:00.0, compute capability: 8.6)\n",
      "2024-03-26 20:43:52.687757: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2024-03-26 20:43:52.705781: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2000000000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-26 20:43:53.458900: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 38/379 [==>...........................] - ETA: 1s - loss: 3592.8462 - accuracy: 9.2491e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-26 20:43:54.126222: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2024-03-26 20:43:54.132094: I tensorflow/stream_executor/cuda/cuda_blas.cc:1838] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "379/379 [==============================] - 4s 6ms/step - loss: 2901.7570 - accuracy: 3.8874e-04 - val_loss: 893.8521 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 893.85205, saving model to model.h5\n",
      "Epoch 2/15\n",
      "379/379 [==============================] - 2s 5ms/step - loss: 511.0065 - accuracy: 0.0000e+00 - val_loss: 295.4466 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00002: val_loss improved from 893.85205 to 295.44662, saving model to model.h5\n",
      "Epoch 3/15\n",
      "379/379 [==============================] - 2s 5ms/step - loss: 307.8645 - accuracy: 0.0000e+00 - val_loss: 276.8907 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00003: val_loss improved from 295.44662 to 276.89072, saving model to model.h5\n",
      "Epoch 4/15\n",
      "379/379 [==============================] - 2s 5ms/step - loss: 280.9080 - accuracy: 0.0000e+00 - val_loss: 239.7257 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00004: val_loss improved from 276.89072 to 239.72572, saving model to model.h5\n",
      "Epoch 5/15\n",
      "379/379 [==============================] - 2s 5ms/step - loss: 262.6265 - accuracy: 0.0000e+00 - val_loss: 231.3505 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00005: val_loss improved from 239.72572 to 231.35051, saving model to model.h5\n",
      "Epoch 6/15\n",
      "379/379 [==============================] - 2s 5ms/step - loss: 253.4206 - accuracy: 0.0000e+00 - val_loss: 283.3188 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 231.35051\n",
      "Epoch 7/15\n",
      "379/379 [==============================] - 2s 4ms/step - loss: 240.2484 - accuracy: 0.0000e+00 - val_loss: 236.3077 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 231.35051\n",
      "Epoch 8/15\n",
      "379/379 [==============================] - 2s 4ms/step - loss: 235.6435 - accuracy: 0.0000e+00 - val_loss: 210.5917 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00008: val_loss improved from 231.35051 to 210.59174, saving model to model.h5\n",
      "Epoch 9/15\n",
      "379/379 [==============================] - 2s 4ms/step - loss: 222.2418 - accuracy: 0.0000e+00 - val_loss: 216.7896 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 210.59174\n",
      "Epoch 10/15\n",
      "379/379 [==============================] - 2s 4ms/step - loss: 230.9379 - accuracy: 0.0000e+00 - val_loss: 205.4115 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00010: val_loss improved from 210.59174 to 205.41153, saving model to model.h5\n",
      "Epoch 11/15\n",
      "379/379 [==============================] - 2s 5ms/step - loss: 219.1708 - accuracy: 0.0000e+00 - val_loss: 237.7905 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 205.41153\n",
      "Epoch 12/15\n",
      "379/379 [==============================] - 2s 4ms/step - loss: 221.9532 - accuracy: 0.0000e+00 - val_loss: 205.5180 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 205.41153\n",
      "Epoch 13/15\n",
      "379/379 [==============================] - 2s 5ms/step - loss: 214.6097 - accuracy: 0.0000e+00 - val_loss: 188.6598 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00013: val_loss improved from 205.41153 to 188.65977, saving model to model.h5\n",
      "Epoch 14/15\n",
      "379/379 [==============================] - 2s 5ms/step - loss: 206.9584 - accuracy: 0.0000e+00 - val_loss: 190.2295 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 188.65977\n",
      "Epoch 15/15\n",
      "379/379 [==============================] - 2s 5ms/step - loss: 206.5772 - accuracy: 0.0000e+00 - val_loss: 263.2967 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 188.65977\n",
      "predicting\n",
      "misclassifying\n",
      "Epoch 1/30\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 284.5562 - accuracy: 0.0000e+00 - val_loss: 173.2914 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 173.29143, saving model to model2.h5\n",
      "Epoch 2/30\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 278.9064 - accuracy: 0.0000e+00 - val_loss: 207.9815 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 173.29143\n",
      "Epoch 3/30\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 281.0049 - accuracy: 0.0000e+00 - val_loss: 177.0601 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 173.29143\n",
      "Epoch 4/30\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 262.3549 - accuracy: 0.0000e+00 - val_loss: 181.1154 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 173.29143\n",
      "Epoch 5/30\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 263.5966 - accuracy: 0.0000e+00 - val_loss: 214.5796 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 173.29143\n",
      "Epoch 6/30\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 263.5634 - accuracy: 0.0000e+00 - val_loss: 158.7956 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00006: val_loss improved from 173.29143 to 158.79561, saving model to model2.h5\n",
      "Epoch 7/30\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 263.4543 - accuracy: 0.0000e+00 - val_loss: 184.8713 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 158.79561\n",
      "Epoch 8/30\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 261.2303 - accuracy: 0.0000e+00 - val_loss: 170.3486 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 158.79561\n",
      "Epoch 9/30\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 264.0577 - accuracy: 0.0000e+00 - val_loss: 153.2989 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00009: val_loss improved from 158.79561 to 153.29889, saving model to model2.h5\n",
      "Epoch 10/30\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 251.2418 - accuracy: 0.0000e+00 - val_loss: 229.8128 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 153.29889\n",
      "Epoch 11/30\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 246.9354 - accuracy: 0.0000e+00 - val_loss: 339.1785 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 153.29889\n",
      "Epoch 12/30\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 257.2326 - accuracy: 0.0000e+00 - val_loss: 194.0614 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 153.29889\n",
      "Epoch 13/30\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 245.3489 - accuracy: 0.0000e+00 - val_loss: 202.6293 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 153.29889\n",
      "Epoch 14/30\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 249.4195 - accuracy: 0.0000e+00 - val_loss: 262.8705 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 153.29889\n",
      "Epoch 15/30\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 246.6704 - accuracy: 0.0000e+00 - val_loss: 305.9364 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 153.29889\n",
      "Epoch 16/30\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 245.8507 - accuracy: 0.0000e+00 - val_loss: 243.0269 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 153.29889\n",
      "Epoch 17/30\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 252.6163 - accuracy: 0.0000e+00 - val_loss: 255.9965 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 153.29889\n",
      "Epoch 18/30\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 242.8769 - accuracy: 0.0000e+00 - val_loss: 191.2562 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 153.29889\n",
      "Epoch 19/30\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 239.6790 - accuracy: 0.0000e+00 - val_loss: 194.4855 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 153.29889\n",
      "Epoch 20/30\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 246.7408 - accuracy: 0.0000e+00 - val_loss: 372.1851 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 153.29889\n",
      "Epoch 21/30\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 255.8775 - accuracy: 0.0000e+00 - val_loss: 251.3860 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 153.29889\n",
      "Epoch 22/30\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 239.7829 - accuracy: 0.0000e+00 - val_loss: 154.9549 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 153.29889\n",
      "Epoch 23/30\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 240.3920 - accuracy: 0.0000e+00 - val_loss: 174.6939 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 153.29889\n",
      "Epoch 24/30\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 239.9181 - accuracy: 0.0000e+00 - val_loss: 282.1877 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 153.29889\n",
      "Epoch 25/30\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 254.7216 - accuracy: 0.0000e+00 - val_loss: 221.1675 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 153.29889\n",
      "Epoch 26/30\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 241.0690 - accuracy: 0.0000e+00 - val_loss: 137.1689 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00026: val_loss improved from 153.29889 to 137.16888, saving model to model2.h5\n",
      "Epoch 27/30\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 246.5137 - accuracy: 0.0000e+00 - val_loss: 202.0037 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 137.16888\n",
      "Epoch 28/30\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 255.3139 - accuracy: 0.0000e+00 - val_loss: 253.0789 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 137.16888\n",
      "Epoch 29/30\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 238.5589 - accuracy: 0.0000e+00 - val_loss: 195.9720 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 137.16888\n",
      "Epoch 30/30\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 248.4754 - accuracy: 0.0000e+00 - val_loss: 215.5795 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 137.16888\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f1694460a30>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dropout, Input, Dense, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import tensorflow as tf\n",
    "\n",
    "X_train_dummy_np = X_train_dummy.astype('float32')\n",
    "y_train_dummy_np = y_train_dummy.drop(columns=['final_result']).astype('float32')\n",
    "\n",
    "input_layer = Input(shape=(X_train_dummy.shape[1],))\n",
    "\n",
    "dense = Dense(128, kernel_initializer=tf.keras.initializers.HeNormal(), kernel_regularizer=l2(0.01))(input_layer)\n",
    "dense = BatchNormalization()(dense)\n",
    "dense = tf.keras.activations.relu(dense)\n",
    "dense = Dropout(0.2)(dense)\n",
    "\n",
    "dense = Dense(128, kernel_initializer=tf.keras.initializers.HeNormal(), kernel_regularizer=l2(0.01))(dense)\n",
    "dense = BatchNormalization()(dense)\n",
    "dense = tf.keras.activations.relu(dense)\n",
    "dense = Dropout(0.2)(dense)\n",
    "\n",
    "dense = Dense(128, kernel_initializer=tf.keras.initializers.HeNormal(), kernel_regularizer=l2(0.01))(dense)\n",
    "dense = BatchNormalization()(dense)\n",
    "dense = tf.keras.activations.relu(dense)\n",
    "dense = Dropout(0.2)(dense)\n",
    "\n",
    "output = Dense(1, activation='linear')(dense)\n",
    "\n",
    "model = tf.keras.models.Model(inputs=input_layer, outputs=output)\n",
    "model2 = tf.keras.models.Model(inputs=input_layer, outputs=output)\n",
    "\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='model.h5',\n",
    "    monitor='val_loss',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    mode='min'\n",
    ")\n",
    "checkpoint2 = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='model2.h5',\n",
    "    monitor='val_loss',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "model2.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "hist = model.fit(X_train_dummy_np, y_train_dummy_np, epochs=15, batch_size=32, validation_split=0.2, callbacks=[checkpoint])\n",
    "\n",
    "#misclassified from the first\n",
    "print(\"predicting\")\n",
    "preds1 = model.predict(X_train_dummy_np)\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_train_dummy['final_result'], preds1)\n",
    "best_threshold = thresholds[np.argmax(precisions + recalls)]\n",
    "print(\"misclassifying\")\n",
    "\n",
    "predictions_classified = [1 if y >= best_threshold else 0 for y in preds1.flatten()]\n",
    "# y_train_dummy_binary = [1 if y >= 50 else 0 for y in y_train_dummy['score']]\n",
    "np.random.seed(0)\n",
    "misclassified = np.array(predictions_classified) != np.array(y_train_dummy['final_result'])\n",
    "misclassified_indices = np.where(misclassified)[0]\n",
    "correct_indices = np.where(~misclassified)[0]\n",
    "random_correct_indices = np.random.choice (correct_indices, size=int(len(misclassified_indices)*2), replace=False)\n",
    "training_indices = np.concatenate([misclassified_indices, random_correct_indices])\n",
    "X_train2 = X_train_dummy_np.iloc[training_indices]\n",
    "y_train2 = y_train_dummy_np.iloc[training_indices]\n",
    "\n",
    "model2.fit(X_train2, y_train2, epochs=30, batch_size=32, validation_split=0.2, callbacks=[checkpoint2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of 0's: 1888\n",
      "Number of 1's: 1899\n",
      "SMOTE\n",
      "Average score where final_result = 1: 74.90150212396232\n",
      "Average score where final_result = 0: 39.049781113585574\n",
      "Number of entries where final_result = 1 and score < 50: 0\n",
      "Number of entries where final_result = 0 and score > 50: 0\n",
      "REG\n",
      "Average score where final_result = 1: 74.90150212396232\n",
      "Average score where final_result = 0: 38.80145189638934\n",
      "Number of entries where final_result = 1 and score < 50: 0\n",
      "Number of entries where final_result = 0 and score > 50: 0\n"
     ]
    }
   ],
   "source": [
    "y_test_dummy['final_result'].value_counts()\n",
    "test_classified = [0 if y < 50 else 1 for y in y_test_dummy['score'].astype('float32')]\n",
    "num_zeros = test_classified.count(0)\n",
    "num_ones = test_classified.count(1)\n",
    "\n",
    "print(f\"Number of 0's: {num_zeros}\")\n",
    "print(f\"Number of 1's: {num_ones}\")\n",
    "\n",
    "print('SMOTE')\n",
    "average_score = y_dummy_smote[y_dummy_smote['final_result'] == 1]['score'].mean()\n",
    "print(f\"Average score where final_result = 1: {average_score}\")\n",
    "\n",
    "average_score = y_dummy_smote[y_dummy_smote['final_result'] == 0]['score'].mean()\n",
    "print(f\"Average score where final_result = 0: {average_score}\")\n",
    "\n",
    "num_entries = len(y_dummy_smote[(y_dummy_smote['final_result'] == 1) & (y_dummy_smote['score'] < 50)])\n",
    "print(f\"Number of entries where final_result = 1 and score < 50: {num_entries}\")\n",
    "\n",
    "num_entries = len(y_dummy_smote[(y_dummy_smote['final_result'] == 0) & (y_dummy_smote['score'] > 50)])\n",
    "print(f\"Number of entries where final_result = 0 and score > 50: {num_entries}\")\n",
    "\n",
    "print('REG')\n",
    "average_score = y_dummy[y_dummy['final_result'] == 1]['score'].mean()\n",
    "print(f\"Average score where final_result = 1: {average_score}\")\n",
    "\n",
    "average_score = y_dummy[y_dummy['final_result'] == 0]['score'].mean()\n",
    "print(f\"Average score where final_result = 0: {average_score}\")\n",
    "\n",
    "num_entries = len(y_dummy[(y_dummy['final_result'] == 1) & (y_dummy['score'] < 50)])\n",
    "print(f\"Number of entries where final_result = 1 and score < 50: {num_entries}\")\n",
    "\n",
    "num_entries = len(y_dummy[(y_dummy['final_result'] == 0) & (y_dummy['score'] > 50)])\n",
    "print(f\"Number of entries where final_result = 0 and score > 50: {num_entries}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best threshold 55.72512\n",
      "3787\n",
      "acc1 0.8803802482175864\n",
      "Confusion Matrix1:\n",
      "[[1527  367]\n",
      " [  86 1807]]\n",
      "best threshold 55.455837\n",
      "Accuracy 0.9094269870609981\n",
      "Confusion Matrix:\n",
      "[[1607  287]\n",
      " [  56 1837]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_recall_curve\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "best_model1 = load_model('model.h5')\n",
    "best_model2 = load_model('model2.h5')\n",
    "\n",
    "X_test_dummy_np = X_test_dummy.astype('float32')\n",
    "\n",
    "preds1 = best_model1.predict(X_test_dummy_np)\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_test_dummy['final_result'], preds1)\n",
    "best_threshold = thresholds[np.argmax(precisions + recalls)]\n",
    "\n",
    "print('best threshold', best_threshold)\n",
    "\n",
    "predictions_classified1 = []\n",
    "for i, pred in enumerate(preds1):\n",
    "#     print(i, pred)\n",
    "    if (pred >= best_threshold):\n",
    "        predictions_classified1.append(1)\n",
    "    else:\n",
    "        predictions_classified1.append(0)\n",
    "print(len(predictions_classified1))\n",
    "\n",
    "# y_test_dummy_binary = [1 if y >= 60 else 0 for y in y_test_dummy['score']]\n",
    "# predictions_classified1 = [1 if y >= 60 else 0 for y in preds1]\n",
    "\n",
    "acc = accuracy_score(y_test_dummy['final_result'], predictions_classified1)\n",
    "print(\"acc1\", acc)\n",
    "cm = confusion_matrix(y_test_dummy['final_result'], predictions_classified1)\n",
    "\n",
    "print(\"Confusion Matrix1:\")\n",
    "print(cm)\n",
    "positive_preds = np.array(predictions_classified1) == 1\n",
    "\n",
    "preds2 = best_model2.predict(X_test_dummy_np)#[positive_preds])\n",
    "# preds2 = best_model2.predict(X_test_dummy_np)\n",
    "average_preds = (preds1*0.45) + (preds2*0.55)\n",
    "\n",
    "\n",
    "\n",
    "final_preds = np.array(preds1.copy())\n",
    "final_preds = average_preds#[positive_preds] = average_preds\n",
    "# final_preds = np.array(preds.copy())\n",
    "\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_test_dummy['final_result'], final_preds)\n",
    "best_threshold = thresholds[np.argmax(precisions + recalls)]\n",
    "\n",
    "print('best threshold', best_threshold)\n",
    "final_preds_classified = [1 if y >= best_threshold else 0 for y in final_preds.flatten()]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "acc = accuracy_score(y_test_dummy['final_result'], final_preds_classified)\n",
    "print(\"Accuracy\", acc)\n",
    "\n",
    "\n",
    "cm = confusion_matrix(y_test_dummy['final_result'], final_preds_classified)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DO NOT RUN, TAKES FOREVER, OPTIMAL PARAMS PRINTED BELOW\n",
    "\n",
    "from skopt import BayesSearchCV #pip install scikit-optimize\n",
    "\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, BatchNormalization, Dropout\n",
    "from joblib import parallel_backend\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "def create_model(neurons, dropout_rate, num_layers, learning_rate):\n",
    "    input_layer = Input(shape=(X_train_dummy.shape[1],))\n",
    "\n",
    "    dense = Dense(neurons, kernel_initializer=tf.keras.initializers.HeNormal())(input_layer)\n",
    "    dense = BatchNormalization()(dense)\n",
    "    dense = tf.keras.activations.relu(dense)\n",
    "    dense = Dropout(dropout_rate)(dense)\n",
    "    \n",
    "    for i in range(num_layers - 1):\n",
    "        dense = Dense(neurons, kernel_initializer=tf.keras.initializers.HeNormal())(dense)\n",
    "        dense = BatchNormalization()(dense)\n",
    "        dense = tf.keras.activations.relu(dense)\n",
    "        dense = Dropout(dropout_rate)(dense)\n",
    "\n",
    "    output = Dense(1, activation='sigmoid')(dense)\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs=input_layer, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "wrapped_create_model = KerasClassifier(build_fn=create_model, verbose=1, epochs=25)\n",
    "\n",
    "param_space = {\n",
    "    'neurons': (8, 512),\n",
    "    'dropout_rate': (0.1, 0.5),\n",
    "    'num_layers': (1, 5),\n",
    "    'learning_rate': (0.0001, 0.1)\n",
    "}\n",
    "\n",
    "opt = BayesSearchCV(\n",
    "    wrapped_create_model,\n",
    "    param_space,\n",
    "    n_iter=50,\n",
    "    cv=3,\n",
    "    n_jobs=1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "opt.fit(X_train_dummy, y_train_dummy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = opt.best_params_\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_parameters = opt.best_params_\n",
    "\n",
    "optimal_model = create_model(\n",
    "    neurons=optimal_parameters['neurons'],\n",
    "    dropout_rate=optimal_parameters['dropout_rate'],\n",
    "    num_layers=optimal_parameters['num_layers'],\n",
    "    learning_rate=optimal_parameters['learning_rate']\n",
    ")\n",
    "\n",
    "history = optimal_model.fit(X_train_dummy, y_train_dummy, epochs=30, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = optimal_model.evaluate(X_test_dummy, y_test_dummy)\n",
    "print(\"Accuracy (tuned model):\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
